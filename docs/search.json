[
  {
    "objectID": "index.html#à-propos-de-ce-document",
    "href": "index.html#à-propos-de-ce-document",
    "title": "Introduction à la statistique bivariée avec R",
    "section": "À propos de ce document",
    "text": "À propos de ce document\nCe document est une introduction aux méthodes statistiques d’analyse bivariée et aux représentations graphiques avec le logicielR\nIl est basé sur R version 4.3.1 (2023-06-16).\nCe document est régulièrement corrigé et mis à jour. La version de référence est disponible en ligne à l’adresse :\n\nhttps://github.com/ClaudeGrasland/bivaR2023\n\nLe code source est disponible sur GitHub.\nPour toute suggestion ou correction, il est possible de me contacter par mail"
  },
  {
    "objectID": "index.html#remerciements",
    "href": "index.html#remerciements",
    "title": "Introduction à la statistique bivariée avec R",
    "section": "Remerciements",
    "text": "Remerciements\nCe document est rédigé en quarto à partir du modèle proposé par Julien Barnier dans son Introduction à R et au Tidyverse"
  },
  {
    "objectID": "index.html#licence",
    "href": "index.html#licence",
    "title": "Introduction à la statistique bivariée avec R",
    "section": "Licence",
    "text": "Licence\nCe document est mis à disposition selon les termes de la Licence Creative Commons Attribution - Pas d’Utilisation Commerciale - Partage dans les Mêmes Conditions 4.0 International.\n\n\n\nLicence Creative Commons"
  },
  {
    "objectID": "01-PremierPas.html#opérations-arithmétiques",
    "href": "01-PremierPas.html#opérations-arithmétiques",
    "title": "1  Premier pas",
    "section": "1.1 Opérations arithmétiques",
    "text": "1.1 Opérations arithmétiques\nNous allons commencer par passer quelques commandes arithmétiques simples. Il suffit de les taper dans la console de R pour qu’elles s’executent automatiquement.\n\n8+2\n#&gt; [1] 10\n\n8-2\n#&gt; [1] 6\n\n8*2\n#&gt; [1] 16\n\n8/2\n#&gt; [1] 4\n\n8**2\n#&gt; [1] 64\n\n8**(1/2)\n#&gt; [1] 2.828427\n\nlog(10)\n#&gt; [1] 2.302585\n\nlog10(10)\n#&gt; [1] 1\n\nsqrt(10)\n#&gt; [1] 3.162278\n\nsin(pi)\n#&gt; [1] 0.0000000000000001224647\n\ncos(pi)\n#&gt; [1] -1\n\ntan(pi)\n#&gt; [1] -0.0000000000000001224647"
  },
  {
    "objectID": "01-PremierPas.html#les-objets-de-base-valeur-vecteur-matrice",
    "href": "01-PremierPas.html#les-objets-de-base-valeur-vecteur-matrice",
    "title": "1  Premier pas",
    "section": "1.2 Les objets de base : valeur, vecteur, matrice",
    "text": "1.2 Les objets de base : valeur, vecteur, matrice\nLes objets élémentéires de R apparaissent dans la fenêtre environnement sous la rubrique Values\n\n1.2.1 Eléments\nUn élément est unique et constitue la brique de base de tous les objets suivants. On peut aussi l’interpréter comme un vecteur de longueur 1 ou une matrice de dimension 1x1.\n\nx&lt;-8\ny&lt;-2\n\nx+y\n#&gt; [1] 10\nx*y\n#&gt; [1] 16\nx**y\n#&gt; [1] 64\n\nLes éléments se combinent différemment selon leur type. Par exemple, des éléments de type caractère (character) peuvent être assemblés avec l’instruction paste() ou découpez avec l’instruction substr() :\n\nx&lt;-\"Bonjour\"\ny&lt;- \"tout le monde\"\nz&lt;- \"!\"\npaste(x,y,z)\n#&gt; [1] \"Bonjour tout le monde !\"\nsubstr(x,1,3)\n#&gt; [1] \"Bon\"\n\nQuant aux éléments logiques (logical) nous verrons qu’ils peuvent se combiner avec des opérateurs comme & quii signifie ET ou bien | qui signifie OU.\n\nx&lt;-TRUE\ny&lt;-FALSE\n\nx & y\n#&gt; [1] FALSE\nx | y \n#&gt; [1] TRUE\n\n\n\n1.2.2 vecteurs (vectors)\nUn vecteur est un ensemble d’éléments de même type que l’on a concaténés à l’aide de l’instruction c(). On peut ensuite les aditionner, les multiplier ou les combiner avec des éléments.\n\nx &lt;- c(1,2,4,8,16)\ny &lt;- 4\nx+y\n#&gt; [1]  5  6  8 12 20\nx*y\n#&gt; [1]  4  8 16 32 64\nx**y\n#&gt; [1]     1    16   256  4096 65536\n\nOn remarque dans l’exemple ci-dessus que R n’a pas de problème pour combiner des vecteurs de tailles différentes.\n\n\n1.2.3 Matrices (matrix)\nUne matrice est un ensemble de vecteurs de même longueur et de même type. On peut donc construire une matrice en concaténant des vecteurs verticalement avec cbind()ou horizontalement avec rbind().\n\n\n# deux vecteurs\nx1 &lt;- c(1,2,4,8,16)\nx2 &lt;- c(5,10,15,20,25)\n\n# matrice en colonnes\nm1 &lt;- cbind(x1,x2)\nm1\n#&gt;      x1 x2\n#&gt; [1,]  1  5\n#&gt; [2,]  2 10\n#&gt; [3,]  4 15\n#&gt; [4,]  8 20\n#&gt; [5,] 16 25\n\n# matrice en lignes\nm2 &lt;- rbind(x1,x2)\nm2\n#&gt;    [,1] [,2] [,3] [,4] [,5]\n#&gt; x1    1    2    4    8   16\n#&gt; x2    5   10   15   20   25\n\n# piège !\nm3 &lt;- c(x1,x2)\nm3\n#&gt;  [1]  1  2  4  8 16  5 10 15 20 25\nis.matrix(m3)\n#&gt; [1] FALSE\n\n\n\n\nSi on assemble deux vecteurs à l’aide de la commande c()on obtient un vecteur et pas une matrice."
  },
  {
    "objectID": "01-PremierPas.html#ne-pas-confondre-listes-et-vecteurs",
    "href": "01-PremierPas.html#ne-pas-confondre-listes-et-vecteurs",
    "title": "1  Premier pas",
    "section": "1.3 Ne pas confondre listes et vecteurs !",
    "text": "1.3 Ne pas confondre listes et vecteurs !\nR utilise des types plus complexes d’objets qui lui sont propres et qui sont en général des listes ou des listes de listes.\n\nliste simple\nliste de liste\nlistes de vecteur = data.frame\n…\n\n\n\n\nLes vecteurs regroupent des éléments de même type tandis que les listes regroupent des éléments ou des objets de type quelconque. Le type liste est donc beaucoup plus général, mais aussi plus difficile d’emploi.\n\n\nOn peut comparer une liste à un panier de course dans lequel on mélange des choux, des carottes, des navets, une boîte de douze oeufs, un paquet de croquettes pour chiens, etc…\n\n\n\n\n# Format vecteur\nprenom &lt;- c(\"Ali\", \"Amine\",\n    \"Anne\",\"Marc\",\"Zayneb\")\nsexe &lt;- c(\"H\",\"H\",\"F\",\"H\",\"F\")\nage  &lt;- c(21,22,24,18,25)\n\n\n# Format liste\nAli &lt;- list(\"H\",21)\nAmine &lt;- list(\"F\",22)\nAnne &lt;- list(\"F\",28)\nMarc &lt;- list (\"H\",18)\nZayneb &lt;- list(\"F\",25)\n\n# Ne pas confondre !\nAli &lt;- c(\"H\",21)\nAli\n#&gt; [1] \"H\"  \"21\"\nAli &lt;- list(\"H\",21)\nAli\n#&gt; [[1]]\n#&gt; [1] \"H\"\n#&gt; \n#&gt; [[2]]\n#&gt; [1] 21"
  },
  {
    "objectID": "01-PremierPas.html#attention-aux-types-de-variables",
    "href": "01-PremierPas.html#attention-aux-types-de-variables",
    "title": "1  Premier pas",
    "section": "1.4 Attention aux types de variables …",
    "text": "1.4 Attention aux types de variables …\nChaque valeur, vecteur ou matrice appartient à un seul type de données. Il est important de ne pas les confondre, sous peine d’obtenir des résultats … douteux. On se limitera ici aux principaux types, d’autres étant vus ultérieurement dans l’année :\n\nnumeric : type général (entier, réels, …)\nlogique : type booleen (TRUE/FALSE)\ndate : année, mois, jour,n heure, minutes, secondes, …\ncharacter : texte quelconque\nfactor : variable catégorielle (codage d’enquêtes …)\n\nLa commande str() permet de vérifier le type d’un vecteur (ou d’une matrice) et d’en afficher la dimension.\n\n# Format charactère\nprenom &lt;- c(\"Ali\", \"Amine\",\"Anne\",\n            \"Marc\",\"Zayneb\")\nstr(prenom)\n#&gt;  chr [1:5] \"Ali\" \"Amine\" \"Anne\" \"Marc\" \"Zayneb\"\n\n# Format logique\nlikeR &lt;- c(TRUE,FALSE, TRUE,\n           FALSE, FALSE)\nstr(likeR)\n#&gt;  logi [1:5] TRUE FALSE TRUE FALSE FALSE\n# Format Factor\nsexe &lt;- c(1,1,2,1,2)\nsexe&lt;-as.factor(sexe)\nlevels(sexe) &lt;-c(\"Homme\",\"Femme\")\nstr(sexe)\n#&gt;  Factor w/ 2 levels \"Homme\",\"Femme\": 1 1 2 1 2\n\n# Format numerique\nage  &lt;- c(21,22,24,18,25)\nstr(age)\n#&gt;  num [1:5] 21 22 24 18 25\n\n# Format date\nnais&lt;-c(\"1999-10-28\",\"1998-10-13\",\n \"1996-10-15\",\"2002-02-07\",\"1995-06-18\")\nnais&lt;-as.Date(nais)\nstr(nais)\n#&gt;  Date[1:5], format: \"1999-10-28\" \"1998-10-13\" \"1996-10-15\" \"2002-02-07\" \"1995-06-18\""
  },
  {
    "objectID": "01-PremierPas.html#types-de-tableaux-et-guerres-de-religion.",
    "href": "01-PremierPas.html#types-de-tableaux-et-guerres-de-religion.",
    "title": "1  Premier pas",
    "section": "1.5 Types de tableaux et guerres de religion.",
    "text": "1.5 Types de tableaux et guerres de religion.\nR est un langage qui a beaucouop évolué au cours du temps, suscitant l’apparition de nouveaux types d’objets mieux adapéts à certaines fonctions. Du coup, il existe plusieurs format de tableaux de données, plus ou moins compatibles entre eux.\nOn notera que dans la fenêtre environnement, les tableaux apparaissent dans la sous-fenêtre data et non plus dans la sous-fenêtre values comme c’était le cas pour les éléments, vecteurs ou matrices.\n\n1.5.1 Le type data.frame :\nC’est le type d’origine correspondant à ce qu’on appelle le langage R-Base. Il se présente en pratique comme une liste de vecteurs qui peuvent être de types différents mais qui sont de même longueur.\n\n# Création d'un data.frame\ntab1&lt;-data.frame(prenom,nais,\n                age,sexe,likeR)\nstr(tab1)\n#&gt; 'data.frame':    5 obs. of  5 variables:\n#&gt;  $ prenom: chr  \"Ali\" \"Amine\" \"Anne\" \"Marc\" ...\n#&gt;  $ nais  : Date, format: \"1999-10-28\" \"1998-10-13\" ...\n#&gt;  $ age   : num  21 22 24 18 25\n#&gt;  $ sexe  : Factor w/ 2 levels \"Homme\",\"Femme\": 1 1 2 1 2\n#&gt;  $ likeR : logi  TRUE FALSE TRUE FALSE FALSE\n\n\n\n1.5.2 Le type tibble\nc’est un type créé par Hadley Wickham pour développer la suite de fonctions Tidyverse ou ggplot\n\n# Création d'un tibble\nlibrary(tidyr, quiet=T)\ntab2&lt;-tibble(prenom,nais,\n            age,sexe,likeR)\nstr(tab2)\n#&gt; tibble [5 × 5] (S3: tbl_df/tbl/data.frame)\n#&gt;  $ prenom: chr [1:5] \"Ali\" \"Amine\" \"Anne\" \"Marc\" ...\n#&gt;  $ nais  : Date[1:5], format: \"1999-10-28\" \"1998-10-13\" ...\n#&gt;  $ age   : num [1:5] 21 22 24 18 25\n#&gt;  $ sexe  : Factor w/ 2 levels \"Homme\",\"Femme\": 1 1 2 1 2\n#&gt;  $ likeR : logi [1:5] TRUE FALSE TRUE FALSE FALSE\n\n\n\n1.5.3 Le type data.table\nC’est un type récent créé pour traiter les tableaux de très grande taille à l’aide du package … data.table\n\n\n# Création d'un data.table\nlibrary(data.table, quiet=T)\n#&gt; \n#&gt; Attaching package: 'data.table'\n#&gt; The following objects are masked from 'package:lubridate':\n#&gt; \n#&gt;     hour, isoweek, mday, minute, month, quarter, second, wday, week,\n#&gt;     yday, year\n#&gt; The following objects are masked from 'package:dplyr':\n#&gt; \n#&gt;     between, first, last\n#&gt; The following object is masked from 'package:purrr':\n#&gt; \n#&gt;     transpose\ntab3&lt;-data.table(prenom,nais,\n                age,sexe,likeR)\nstr(tab3)\n#&gt; Classes 'data.table' and 'data.frame':   5 obs. of  5 variables:\n#&gt;  $ prenom: chr  \"Ali\" \"Amine\" \"Anne\" \"Marc\" ...\n#&gt;  $ nais  : Date, format: \"1999-10-28\" \"1998-10-13\" ...\n#&gt;  $ age   : num  21 22 24 18 25\n#&gt;  $ sexe  : Factor w/ 2 levels \"Homme\",\"Femme\": 1 1 2 1 2\n#&gt;  $ likeR : logi  TRUE FALSE TRUE FALSE FALSE\n#&gt;  - attr(*, \".internal.selfref\")=&lt;externalptr&gt;"
  },
  {
    "objectID": "01-PremierPas.html#en-résumé",
    "href": "01-PremierPas.html#en-résumé",
    "title": "1  Premier pas",
    "section": "1.6 En résumé",
    "text": "1.6 En résumé\n\n\n\nR est un langage de programmation multifonction qui évolue depuis maintenant plus de 30 ans et auquel s’ajoutent continuellement de nouveaux packages. A la différence de SPSS, il n’est pas spécialisé uniquement en statistique, même si le coeur du logiciel est bien centré sur la statistique. Pour progresser rapidement en R il est indispensable :\n\n\n\nde prêter une grande attention aux types de variables et de tableaux.\n\n\nde ne pas chercher à utiliser trop vite de nouveaux packages tant que l’on n’a pas acquis une pratique suffisante du R-Base.\n\n\nde consulter la documentation et les forums de discussion en cas de difficulté."
  },
  {
    "objectID": "01-PremierPas.html#exercices",
    "href": "01-PremierPas.html#exercices",
    "title": "1  Premier pas",
    "section": "1.7 Exercices",
    "text": "1.7 Exercices\nExercice 1\nConstruire le vecteur x suivant :\n\n#&gt; [1] \"Paris\"    \"Londres\"  \"Tokyo\"    \"New York\"\n\n\n\nx &lt;- c(\"Paris\", \"Londres\",\"Tokyo\",\"New York\")\n\n\nConstruire le vecteur y suivant :\n\n#&gt; [1] \"France\"      \"Royaume-Uni\" \"Japon\"       \"USA\"\n\n\n\ny &lt;- c(\"France\", \"Royaume-Uni\",\"Japon\",\"USA\")\n\n\nConstruire le vecteur z suivant :\n\n#&gt; [1] 10.2 14.6 42.8 23.9\n\n\n\nz &lt;- c(10.2, 14.6,42.8,23.9)\n\n\nConstruire la matrice m1\n\n#&gt;   [,1]     [,2]          [,3]    [,4]      \n#&gt; x \"Paris\"  \"Londres\"     \"Tokyo\" \"New York\"\n#&gt; y \"France\" \"Royaume-Uni\" \"Japon\" \"USA\"\n\n\n\nm1&lt;-rbind(x,y)\n\n\nConstruire le data.frame df\n\n#&gt;             y        x    z\n#&gt; 1      France    Paris 10.2\n#&gt; 2 Royaume-Uni  Londres 14.6\n#&gt; 3       Japon    Tokyo 42.8\n#&gt; 4         USA New York 23.9\n\n\n\ndf&lt;-data.frame(y,x,z)\n\n\nExercice 2 (d’après J.Barnier)\nOn a demandé à 4 ménages le revenu des deux conjoints, et le nombre de personnes du ménage :\n\nconjoint1 &lt;- c(1200, 1180, 1750, 2100)\nconjoint2 &lt;- c(1450, 1870, 1690, 0)\nnb_personnes &lt;- c(4, 2, 3, 2)\n\nCalculer le revenu total de chaque ménage, puis diviser par le nombre de personnes pour obtenir le revenu par personne de chaque ménage.\n\n\nrevenu_total &lt;- conjoint1 + conjoint2\nrevenu_total / nb_personnes"
  },
  {
    "objectID": "02-OfficeKiller.html#rstudio-et-les-projets-r",
    "href": "02-OfficeKiller.html#rstudio-et-les-projets-r",
    "title": "2  Office Killer",
    "section": "2.1 Rstudio et les projets R",
    "text": "2.1 Rstudio et les projets R\n\n\nAu commencement, les dieux de la statistique créèrent le langage R.\nMais l’interface était vide et vague,\nles ténèbres couvraient les lignes de code\nR-Studio dit : Que le projet soit et le projet fut.\n\n\nSi l’on veut s’épargner bien des désagréments dans l’apprentissage de R, il faut prendre dès le départ de bonnes habitudes. Parmi celles-ci, l’une des plus importantes est le fait d’inscrire toujours son travail dans le cadre d’un projet R c’est-à-dire - en simplifiant beaucoup - un répertoire de travail contenant l’ensemble des données, programmes, résultats… que l’on pourra par la suite compresser, archiver et transmettre à quelqu’un d’autre.\n\n2.1.1 Lancement de R studio\nSauf à être complètement masochiste, on n’utilise jamais R directement mais on lance d’abord l’interface R-Studio qui facilite conisdérablement l’ensemble des opérations et offre une gamme considérable de services. Il ne faut toutefois pas confondre les deux et il serait par exemple ridicule d’indiquer sur un CV en vue d’un emploi de statisticien que l’on sait utiliser R-studio en oubliant de préciser que l’on maîtrise R.\n\n\n2.1.2 Création d’un projet\nPour créer un projet on utilise le menus déroulant File/new project/ … et on définit un dossier de notre ordinateur (existant ou à créer) qui contiendra le projet. Une fois l’opération effectuée, on pourra constater que ce dossier contient un fichier xxx.Rproj ou xxx est en principe le nom du dossier dans lequel vous avez stocké le projet.\nCe fichier contient toute une série d’informations dont nous ne parlerons pas dans ce cours d’initiation mais qui, pour faire simple, définissent un ensemble de réglages du logiciel et de préférences de l’utilisateur.\nSi vous fermez Rstudio (faites-le !) il vous suffira pour reprendre votre travail là où vous vous étiez arrêté :\n\nde lancer R-studio et de cliquer sur File/open project/… suivi du nom du fichier xxx.Rproj\nou plus simplement encore de double cliquer sur le fichier xxx.Rproj ce qui lancera automatiquement Rstudio\n\nLe dossier contenant votre projet R peut être organisé à votre convenance. Certains mettent tout les fichier pêle-mêle dans le dossier. D’autres préfèrent créer des sous-dossiers contenant des données, des programmes, des résultats, des figures. Vous déciderez à l’usage de ce qui vous convient le mieux, mais le point important est que tout ce qui entre ou sort de vos programmes R doit être de préférence stocké dans le répertoire du projet."
  },
  {
    "objectID": "02-OfficeKiller.html#programme-r-excel-killer",
    "href": "02-OfficeKiller.html#programme-r-excel-killer",
    "title": "2  Office Killer",
    "section": "2.2 Programme R : Excel killer ?",
    "text": "2.2 Programme R : Excel killer ?\n\n\nC’est pourquoi tu quittera Word et Excel, et t’attachera à R studio,\net vous deviendrez une seule chair.\n\n\nLa fonction initiale d’un langage de programmation comme R est … de créer des programmes c’est-à-dire des ensembles d’instruction permettant d’accomplir une tâche à l’intérieur d’une chaîne de production. Dans le cas d’un logiciel spécialisé dans l’analyse statistique, il s’agira donc de partir de données (statistiques, géographiques, textuelles, …) pour aboutir à des résultats prenant la forme de tableaux, cartes ou graphiques. Il ne s’agit donc en somme que d’une étape du travail de recherche où le principal avantage de R est d’automatiser une tâche et de faciliter sa reproduction ultérieure avec en arrière plan un objectif de productivité puisque l’ordinateur réalise en quelques millisecondes des tâches qui prendraient des heures avec un logiciel click-bouton de type Excel.\n\n\n\n\n\nPrenons un exemple simple de problème facile à résoudre avec R mais plus compliqué avec des logiciels click-boutons. Il s’agit d’un exemple pédagogique tiré d’un très vieux cours d’analyse spatiale portant sur les semis de point et les localisations optimales.\nOn considère une carte papier permettant de localiser 5 station services à l’intérieur d’une ville à plan en damier. Chaque station livre chacune la même quantité de carburant par semaine aux clients. On souhaite répondre aux questions suivantes :\n\nComment saisir les données dans une fichier numérique ?\nComment reproduire la carte papier sous forme d’un graphique ?\nComment calculer la dsitance à vol d’oiseau entre toutes les stations ?\nComment calculer la dsitance routière entre toutes les stations ?\nOù localiser un dépôt de carburant permettant d’alimenter les cinq stations en minimisant la distance moyenne de livraison (critère d’efficacite)\nOù localiser une caserne de pompier qui doit pouvoir intervenir rapidement sur toute les stations et qui doit minimiser la distance maximale à la station la plus éloignée (critère d’équité).\nComment visualiser ces deux localisations sur la carte des stations ?\nComment reproduire ces tâches rapidement s’il y a des ajouts ou suppressions de stations\n\n\n\n\n\n\nOn constitue deux équipes d’étudiants, certains utilisant un programme R et d’autres Excel. On se propose de voir qui ira le plus vite sur chacune des 8 tâches proposées.\n\n2.2.1 Round 1. Saisie des données et affichage du tableau\nOn crée un programme R avec File/New File/R Script puis on l’enregistre avec File/Save/ … suivi du nom du programme.\n\n# Saisie des variables\nCODE &lt;- c(\"A\",\"B\",\"C\",\"D\",\"E\")\nX &lt;- c(10,20,40,50,180)\nY &lt;- c(40,60,40,60,50)\n\n# Regroupement dans un tableau\ncoo &lt;- data.frame(X,Y)\n\n# Ajout du nom des lignes\nrow.names(coo) &lt;- CODE\n\n# Affichage du tableau\ncoo\n#&gt;     X  Y\n#&gt; A  10 40\n#&gt; B  20 60\n#&gt; C  40 40\n#&gt; D  50 60\n#&gt; E 180 50\n\nNormalement, les étudiants qui utilisent un tableur ont du aller plus vite et Excel mène sur R par 1-0\n\n\n2.2.2 Round 2. Affichage de la carte\nVous devez essayez de reproduire l’image correspondant au problème posé\n\nplot(X,Y, \n     col=\"red\", \n     pch=20, \n     xlim=c(0,180),\n     ylim=c(0,90),\n     asp = 1)\ntext(X,Y,\n     labels = CODE, \n     pos = 2)\n\n\n\n\nLa création d’un graphique est à première vue plus facile avec un logiciel click-bouton. L’avantage est très clairement pour Excel qui mène désormais 2 à 0.\n\n\n2.2.3 Round 3. Calcul de la station la plus accessible à vol d’oiseau (distance euclidienne)\nVous devez calculer une matrice de distance euclidienne entre toutes les stations et trouver la plus accessible.\n\n\n# calcul la matrice de distance euclidienne\nmat&lt;-dist(coo, upper = T, method = \"euclidean\")\nmat\n#&gt;           A         B         C         D         E\n#&gt; A            22.36068  30.00000  44.72136 170.29386\n#&gt; B  22.36068            28.28427  30.00000 160.31220\n#&gt; C  30.00000  28.28427            22.36068 140.35669\n#&gt; D  44.72136  30.00000  22.36068           130.38405\n#&gt; E 170.29386 160.31220 140.35669 130.38405\n\n# distance moyenne\napply(as.matrix(mat),1,mean)\n#&gt;         A         B         C         D         E \n#&gt;  53.47518  48.19143  44.20033  45.49322 120.26936\n\nLà, je parie que les utilisateurs d’Excel ont eu un peu plus de mal … En tous les cas, Excel ne mèneplus que par 2 à 1\n\n\n2.2.4 Round 4. Calcul de la station la plus accessible par la route (distance de Manhattan)\nVous devez calculer une matrice de distance de Manhattan entre toutes les stations et trouver la plus accessible.\n\n\n# calcul la matrice de distance de Manhattan\nmat&lt;-dist(coo,upper = T, method = \"manhattan\")\nmat\n#&gt;     A   B   C   D   E\n#&gt; A      30  30  60 180\n#&gt; B  30      40  30 170\n#&gt; C  30  40      30 150\n#&gt; D  60  30  30     140\n#&gt; E 180 170 150 140\n\n# distance moyenne de Manhattan\napply(as.matrix(mat),1,mean)\n#&gt;   A   B   C   D   E \n#&gt;  60  54  50  52 128\n\nJe reconnais que c’est unpeu facile, mais à nouveau R l’emporte ce qui fait désormais match nul 2-2\n\n\n2.2.5 Round 5. Localisation du dépôt de carburant\nDans le cas particulier de la distance de Manhattan, le calcul du point le plus proche de tous les autres s’obtient facilement en calculant le point médian dont les coordonnées correspondent à la médiane de X et la médiane de Y.\n\nmedX &lt;- median(X)\nmedX\n#&gt; [1] 40\nmedY &lt;- median(Y)\nmedY\n#&gt; [1] 50\n\nA priori, le calcul est aussi facile dans R et dans Excel : match nul 3-3\n\n\n2.2.6 Round 6. Localisation de la caserne de pompiers\nDans le cas particulier de la distance de Manhattan, le calcul du point minimisant la distance maximale s’obtient en trouvant le centre du diamètre minimal en X et en Y. Il s’agit de la localisation la plus équitable où le plus défavorisé est le moins défavorisé possible.\n\nequX &lt;- (max(X)+min(X))/2\nequX\n#&gt; [1] 95\nequY &lt;- (max(Y)+min(Y))/2\nequY\n#&gt; [1] 50\n\nA priori, le calcul est toujours aussi facile dans R et dans Excel : match nul 4-4\n\n\n2.2.7 Round 7. Visualisation des deux points sur la carte\nOn va placer en bleu le point médian et en vert le point le plus équitable. Dans le cas de R on peut recopier les lignes de code du graphique du round n°2 ce qui gagne désormais du temps :\n\n# Programme antérieur\nplot(X,Y, \n     col=\"red\", \n     pch=20, \n     xlim=c(0,180),\n     ylim=c(0,90),\n     asp = 1)\ntext(X,Y,\n     labels = CODE, \n     pos = 2)\n\n# Ajout du dépôt de carburant\npoints(medX, medY, col=\"blue\", pch=3)\ntext(medX,medY, \"dépot\",pos=1)\n\n# Ajout du point médian\npoints(equX, equY, col=\"green\", pch=3)\ntext(equX,equY, \"caserne\",pos=1)\n\n\n\n\nLe résultat du match est incertain mais R n’est plus désavantagé puisqu’on peut recycler les lignes de code précédentes pour le graphique de base. Disons 5-5 même s’il y a de fortes chances que R l’emporte.\n\n\n2.2.8 Dernier round. Refaire toute l’analyse avec une station de plus\nDeux stations F(100,20) et G(150,30) ont été ajoutées. Il faut refaire la carte finale. Cela ne pose aucun problème dans R puisqu’il suffit de modifier l’entrée des données et récupérer des bouts de programme\n\n# (1) Saisie des variables\nCODE &lt;- c(\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\")\nX &lt;- c(10,20,40,50,180,100,150)\nY &lt;- c(40,60,40,60,50,20,30)\ncoo &lt;- data.frame(X,Y)\nrow.names(coo) &lt;- CODE\n\n\n# (2) calcul des points centraux\nmedX &lt;- median(X)\nmedY &lt;- median(Y)\nequX &lt;- (max(X)+min(X))/2\nequY &lt;- (max(Y)+min(Y))/2\n\n\n# (3) Graphique\nplot(X,Y, \n     col=\"red\", \n     pch=20, \n     xlim=c(0,180),\n     ylim=c(0,90),\n     asp = 1)\ntext(X,Y,\n     labels = CODE, \n     pos = 2)\n\n# Ajout du dépôt de carburant\npoints(medX, medY, col=\"blue\", pch=3)\ntext(medX,medY, \"Dépôt\",pos=1)\n\n# Ajout du point médian\npoints(equX, equY, col=\"green\", pch=3)\ntext(equX,equY, \"Caserne\",pos=1)\n\n\n\n\nExcel n’a aucune chance d’aller plus vite et R remporte le match par KO !"
  },
  {
    "objectID": "02-OfficeKiller.html#document-rmd-word-killer",
    "href": "02-OfficeKiller.html#document-rmd-word-killer",
    "title": "2  Office Killer",
    "section": "2.3 Document Rmd : Word killer ?",
    "text": "2.3 Document Rmd : Word killer ?\n\n\nR-Studio dit : « Faisons une interface de rédaction adaptée à notre travail,\nQue l’utilisateur puissent y insérer les tableaux, les graphiques, les cartes, les références bibliographiques, et tous les écrits qui les commentent. »\n\n\nNous venons de voir comment une bonne pratique de R peut conduire progressivement à abandonner l’usage des tableurs (Excel, Open Office) sauf peut-être pour l’étape de saisie des données. Dès lors qu’il s’agit de réaliser des graphiques ou des calculs statistiques complexes, la rédaction d’un programme se révèle beaucoup plus intéressante même si elle impose un coût initial d’apprentissage.\nMais une bonne pratique de R ou plus précisément des documents R markdown peut vous conduire beaucoup plus loin et vous amener à abandonner également votre logiciel de traitement de texte (Word) et votre outil de présentation (Power Point). Le coût d’apprentissage est naturellement un peu plus élevé mais les bénéfices sont à la mesure de l’investissement.\nComme le montre la figure ci-dessous, un document R markdown est en quelques sorte un mélange entre des lignes de code R qui executent des tâches et des lignes de texte où sont expliqués les calculs et commentés les résultats obtenus. En d’autres termes, un document R markdown vous permet de rédiger un article de recherche complet, une présentation à une conférence, un syllabus de cours, dans un seul environnement logiciel (R studio).\nNul besoin de ciseau et de colle pour aller chercher tel tableau ici, tel figure là-bas ou telle carte ailleurs. Tous ces éléments sont intégrs au fur et à mesure de la rédaction ce qui facilite considérablement la concentration. Et surtout - on l’a déjà vu pour le programme R - le document peut facilement être reproduit ou mise à jour sans être obligé de réplique des dizaines de click de souris.\n\n\n\n\n\nNous allons illustrer l’usage de R markdown en rédigeant une courte note sur la distribution de la population et de certains commerces et services à Rennes. L’exemple est repris du Manuel d’analyse spatiale publié par l’INSEE en 2018 et plus précisement de son chapitre 4. Les configurations de points\nComme nous avons pris la perspective de n’employer aucun package R au cours de cette formation initiale, les données ont été légèrement modifiées, notamment pour le tracé de la carte des contours de la ville de Rennes.\n\n2.3.1 Chargement des données\nNous disposons de trois fichiers qui comportent chacun des coordonnées de localisation utilisant la même projection Lambert et que l’on pourra de ce fait superposer. Après les avoir chargés et décrits, on en propose une première visualisation à l’aide des fonctions graphiques de base de R.\n\n\n2.3.2 Contour de Rennes\nOn charge le fichier avec read.table() puis on affiche ses premières lignes avec head()et on regarde sa taille avec dim()\n\nmap &lt;- read.table(file = \"resources/data/rennes/map.csv\",\n                  header = T,\n                  sep = \";\")\nhead(map,2)\n#&gt;          x       y\n#&gt; 1 346382.1 6786334\n#&gt; 2 346460.0 6786704\ndim(map)\n#&gt; [1] 37  2\n\nOn affiche le contour avec les instructions plot() et lines(). On doit impérativement ajouter le paramètre asp = 1 dans plot() pour imposer une échelle identique sur l’axe vertical et l’axe horizontal.\n\nplot(map$x,map$y, col=\"red\", asp = 1)\nlines(map$x,map$y, col=\"blue\")\n\n\n\n\n\n\n2.3.3 Distribution de la population\nOn charge le fichier de population de la même manière et on constate qu’il comporte une troisième colonne indiquant la population localisée en chaque point. En fait, il s’agit d’une grille de population qui localise les habitants sur une maille de ??? m\n\npop &lt;- read.table(file = \"resources/data/rennes/popu.csv\",\n                  header = T,\n                  sep = \";\")\nhead(pop,2)\n#&gt;          x       y pop\n#&gt; 1 346202.1 6790631  20\n#&gt; 2 346203.4 6792843   5\ndim(pop)\n#&gt; [1] 24916     3\n\nOn procède à une première cartographie qui ne tient pas compte de l’effectif de population mais indique juste les cases occupées et inoccupées, ce qui permet de donner une vision générale de l’occuparion du sol et du peuplement de Rennes et de l’espace environnant.\n\nplot(pop$x,pop$y, col=\"red\", asp = 1,pch=22, cex=0.01)\nlines(map$x,map$y, col=\"black\")\n\n\n\n\n\n\n2.3.4 Distribution des équipements\nL’INSEE a extrait du fichier de la Base Publique des Equipements quatre types de localisations correspondant aux écoles, aux médecins, aux pharmacies et aux commerces de vêtements. On notera l’ajout du paramètre encoding=“UTF-8” qui permet de lire sans erreur les caractères accentués et d’éviter par exemple que “Vêtements” devienne “VÃªtements”.\n\nbpe &lt;- read.table(file = \"resources/data/rennes/bpe.csv\",\n                  header = T,\n                  sep = \";\",\n                  encoding=\"UTF-8\")\nhead(bpe,2)\n#&gt;            x       y    equ\n#&gt; 286 349156.2 6790525 Ecoles\n#&gt; 287 351800.4 6786774 Ecoles\ndim(bpe)\n#&gt; [1] 767   3\n\nOn utilise l’instruction table()pour dénombrer l’effectif de chaque équipement :\n\ntable(bpe$equ)\n#&gt; \n#&gt;     Ecoles   Médecins Pharmacies  Vêtements \n#&gt;         59        268         70        370\n\nPuis on visualise après avoir attribué une couleur à chaque équipement. On crée pour cela une nouvelle variable :\n\nbpe$couleur&lt;-as.factor(bpe$equ)\nlevels(bpe$couleur)\n#&gt; [1] \"Ecoles\"     \"Médecins\"   \"Pharmacies\" \"Vêtements\"\nlevels(bpe$couleur)&lt;-c(\"blue\",\"green\",\"orange\",\"red\")\nbpe$couleur&lt;-as.character(bpe$couleur)\ntable(bpe$couleur)\n#&gt; \n#&gt;   blue  green orange    red \n#&gt;     59    268     70    370\n\n\n\n2.3.5 Synthèse\nOn peut désormais assembler nos trois couches :\n\nplot(pop$x,pop$y, col=\"gray\", asp = 1,pch=22, cex=0.01)\nlines(map$x,map$y, col=\"black\")\npoints(bpe$x,bpe$y,bg=bpe$couleur, pch=21, cex=0.8)\n\n\n\n\nIl est facile de procéder à un zoom en ajoutant des paramètres xlim et ylim dans la fonction plot() qui précise l’espace d’étude.\n\nplot(pop$x,\n     pop$y, \n     col=\"gray\", \n     asp = 1,\n     pch=22, \n     cex=0.1,\n     xlim = c(351000,353000),\n     ylim = c(6788500,6790500))\n\nlines(map$x,\n      map$y, \n      col=\"black\")\n\npoints(bpe$x,\n       bpe$y,\n       bg=bpe$couleur, \n       pch=21, \n       cex=0.8)\n\n\n\n\nOK, notre carte n’a pas de légende (c’est possible mais vraiment compliqué en R-Base) mais on appréciera le fait d’avoir pu la réaliser en ne se servant que de quelques fonctions élémentaires de R comme"
  },
  {
    "objectID": "02-OfficeKiller.html#diapos-rmd-power-point-killer",
    "href": "02-OfficeKiller.html#diapos-rmd-power-point-killer",
    "title": "2  Office Killer",
    "section": "2.4 Diapos Rmd : Power Point killer",
    "text": "2.4 Diapos Rmd : Power Point killer\nLorsque l’on crée un fichier Markdown, on peut décider qu’il ne s’agit pas d’un document mais d’une présentation et opter pour l’un des deux modes par défaut appelés slidy et ioslides.\n\n\n\n\n\nOn peut ensuite créer un diaporama en donnant un titre général et en séparant chaque diapo par un titre de niveau 2 correspondant à des lignes débutant par ## comme dans l’exemple ci-dessous :\n\n\n\n\n\nIl ne reste plus qu’à compiler le programme avec l’icône Knit (pelotte de laine) pour générer un document .html en forme de dipositives."
  },
  {
    "objectID": "02-OfficeKiller.html#en-résumé",
    "href": "02-OfficeKiller.html#en-résumé",
    "title": "2  Office Killer",
    "section": "2.5 En résumé",
    "text": "2.5 En résumé\n\n\n\nR est un Excel killer mais aussi un Word killer voire un Power point killer… Adopter R peut nuire gravement à vos habitudes antérieures de travail."
  },
  {
    "objectID": "03-Base.html#tableaux",
    "href": "03-Base.html#tableaux",
    "title": "3  R-Base",
    "section": "3.1 Tableaux",
    "text": "3.1 Tableaux\n\n3.1.1 Importation\n\n3.1.1.1 Localisation des fichiers\n\nLa commande getwd() permet de connaître la position du répertoire courant. Si vous avez ouvert un projet (ce qui est vivement recommandé) la localisation est l’emplacement du fichier .Rproj.\n\n\ngetwd() \n#&gt; [1] \"/Users/claudegrasland1/git/bivar2023\"\n\n\nLa commande list.files() permet d’examiner le contenu du répertoire courant\n\n\nlist.files()\n#&gt;  [1] \"_extensions\"           \"_freeze\"               \"_quarto.yml\"          \n#&gt;  [4] \"_setup.qmd\"            \"01-PremierPas.html\"    \"01-PremierPas.qmd\"    \n#&gt;  [7] \"02-OfficeKiller_files\" \"02-OfficeKiller.html\"  \"02-OfficeKiller.qmd\"  \n#&gt; [10] \"03-Base_files\"         \"03-Base.qmd\"           \"03-Base.rmarkdown\"    \n#&gt; [13] \"11-Corrélation.qmd\"    \"12-Régression.qmd\"     \"13-Anova.qmd\"         \n#&gt; [16] \"22-ressources.qmd\"     \"bivar2023.Rproj\"       \"css\"                  \n#&gt; [19] \"DESCRIPTION\"           \"docs\"                  \"index.html\"           \n#&gt; [22] \"index.pdf\"             \"index.qmd\"             \"js\"                   \n#&gt; [25] \"latex\"                 \"LICENSE\"               \"README.md\"            \n#&gt; [28] \"resources\"             \"site_libs\"\n\n\n\n3.1.1.2 Chargement d’un fichier texte\n\nAvec la souris\n\nCliquer sur les menus déroulants File/Import Dataset/From text (base) puis suivre le menu\n\n\n\n\n\n\nAvec des lignes de code\n\nOn utilise par exemple la fonction read.table() en précisant les paramètres utiles :\n\neuro1988 &lt;- read.table(file = \"resources/data/europe88/euro1988.csv\", # nom du fichier et chemin d'accès\n                  sep = \";\",                     # séparateur (ici, des points-virgule)\n                  header = TRUE,                 # ligne d'en-tête avec le nom des variables\n                  encoding=\"UTF-8\")              # encodage adapté au français\n\n\n\n3.1.1.3 Dimensions d’un tableau\n\nLa fonction dim() fournit les dimensions d’un tableau\n\n\ndim(euro1988)\n#&gt; [1] 25 15\n\n\nLa fonction class() fournit le type d’un tableau\n\n\nclass(euro1988)\n#&gt; [1] \"data.frame\"\n\n\n\n3.1.1.4 Visualisation du contenu d’un tableau\n\nPremières lignes avec head()\n\n\nhead(euro1988)         # Affiche par défaut les 6 premières lignes\n#&gt;   PAYS BLOC   PNB  TMI ESP URB NAT MOR FEC JEU VIE SUP  POP       X       Y\n#&gt; 1  ALB  Soc   600 43.0  71  34  27   6 3.3  35   5  29  3.1 4825115 1684833\n#&gt; 2  AUT  Cap 10000 10.3  75  55  12  12 1.4  18  14  84  7.6 4299715 2335579\n#&gt; 3  BEL  Cap  9200  9.7  75  95  12  11 1.5  19  14  31  9.9 3636312 2667243\n#&gt; 4  BGR  Soc  2000 14.5  72  65  13  11 2.0  21  11 111  9.0 5206070 1930219\n#&gt; 5  CHE  Cap 17800  6.8  77  61  12   9 1.5  17  14  41  6.6 3869378 2243130\n#&gt; 6  CSK  Soc  3200 13.9  71  74  14  12 2.0  24  11 128 15.6 4487005 2540281\n\n\nDernières lignes avec tail()\n\n\ntail(euro1988,2)         # Affiche les 2 dernières lignes\n#&gt;    PAYS BLOC   PNB  TMI ESP URB NAT MOR FEC JEU VIE SUP  POP       X       Y\n#&gt; 24  SWE  Cap 13200  5.9  77  83  12  11 1.8  18  18 450  8.4 4321587 3961396\n#&gt; 25  YUG  Soc  2300 27.1  70  47  15   8 2.1  24   8 256 23.6 4686147 1996737\n\n\n\n3.1.1.5 Verification des variables\n\nVérifie le type avec str()\n\n\nstr(euro1988)\n#&gt; 'data.frame':    25 obs. of  15 variables:\n#&gt;  $ PAYS: chr  \"ALB\" \"AUT\" \"BEL\" \"BGR\" ...\n#&gt;  $ BLOC: chr  \"Soc\" \"Cap\" \"Cap\" \"Soc\" ...\n#&gt;  $ PNB : int  600 10000 9200 2000 17800 3200 3700 12000 12600 4800 ...\n#&gt;  $ TMI : num  43 10.3 9.7 14.5 6.8 13.9 9.2 8.6 8.4 9 ...\n#&gt;  $ ESP : int  71 75 75 72 77 71 72 75 75 76 ...\n#&gt;  $ URB : int  34 55 95 65 61 74 77 94 84 91 ...\n#&gt;  $ NAT : int  27 12 12 13 12 14 13 10 11 12 ...\n#&gt;  $ MOR : int  6 12 11 11 9 12 13 11 11 8 ...\n#&gt;  $ FEC : num  3.3 1.4 1.5 2 1.5 2 1.7 1.4 1.5 1.7 ...\n#&gt;  $ JEU : int  35 18 19 21 17 24 19 15 18 23 ...\n#&gt;  $ VIE : int  5 14 14 11 14 11 14 15 15 12 ...\n#&gt;  $ SUP : int  29 84 31 111 41 128 108 248 43 505 ...\n#&gt;  $ POP : num  3.1 7.6 9.9 9 6.6 15.6 16.6 61.2 5.1 39 ...\n#&gt;  $ X   : num  4825115 4299715 3636312 5206070 3869378 ...\n#&gt;  $ Y   : num  1684833 2335579 2667243 1930219 2243130 ...\n\n\nRecode avec les fonctions as.xxx()\n\n\neuro1988$BLOC&lt;-as.factor(euro1988$PAYS)\nstr(euro1988)\n#&gt; 'data.frame':    25 obs. of  15 variables:\n#&gt;  $ PAYS: chr  \"ALB\" \"AUT\" \"BEL\" \"BGR\" ...\n#&gt;  $ BLOC: Factor w/ 25 levels \"ALB\",\"AUT\",\"BEL\",..: 1 2 3 4 5 6 7 8 9 10 ...\n#&gt;  $ PNB : int  600 10000 9200 2000 17800 3200 3700 12000 12600 4800 ...\n#&gt;  $ TMI : num  43 10.3 9.7 14.5 6.8 13.9 9.2 8.6 8.4 9 ...\n#&gt;  $ ESP : int  71 75 75 72 77 71 72 75 75 76 ...\n#&gt;  $ URB : int  34 55 95 65 61 74 77 94 84 91 ...\n#&gt;  $ NAT : int  27 12 12 13 12 14 13 10 11 12 ...\n#&gt;  $ MOR : int  6 12 11 11 9 12 13 11 11 8 ...\n#&gt;  $ FEC : num  3.3 1.4 1.5 2 1.5 2 1.7 1.4 1.5 1.7 ...\n#&gt;  $ JEU : int  35 18 19 21 17 24 19 15 18 23 ...\n#&gt;  $ VIE : int  5 14 14 11 14 11 14 15 15 12 ...\n#&gt;  $ SUP : int  29 84 31 111 41 128 108 248 43 505 ...\n#&gt;  $ POP : num  3.1 7.6 9.9 9 6.6 15.6 16.6 61.2 5.1 39 ...\n#&gt;  $ X   : num  4825115 4299715 3636312 5206070 3869378 ...\n#&gt;  $ Y   : num  1684833 2335579 2667243 1930219 2243130 ...\n\n\n\n3.1.1.6 Résume du tableau\nLa fonction summary() donne un aperçu général des variables\n\nsummary(euro1988)\n#&gt;      PAYS                BLOC         PNB             TMI       \n#&gt;  Length:25          ALB    : 1   Min.   :  600   Min.   : 5.80  \n#&gt;  Class :character   AUT    : 1   1st Qu.: 2300   1st Qu.: 8.50  \n#&gt;  Mode  :character   BEL    : 1   Median : 8600   Median : 9.70  \n#&gt;                     BGR    : 1   Mean   : 7580   Mean   :12.99  \n#&gt;                     CHE    : 1   3rd Qu.:12000   3rd Qu.:14.50  \n#&gt;                     CSK    : 1   Max.   :17800   Max.   :43.00  \n#&gt;                     (Other):19                                  \n#&gt;       ESP             URB             NAT            MOR             FEC       \n#&gt;  Min.   :70.00   Min.   :30.00   Min.   :10.0   Min.   : 6.00   Min.   :1.400  \n#&gt;  1st Qu.:72.00   1st Qu.:58.00   1st Qu.:12.0   1st Qu.: 9.00   1st Qu.:1.500  \n#&gt;  Median :75.00   Median :71.00   Median :12.0   Median :11.00   Median :1.700  \n#&gt;  Mean   :73.72   Mean   :68.44   Mean   :13.4   Mean   :10.36   Mean   :1.816  \n#&gt;  3rd Qu.:75.00   3rd Qu.:83.00   3rd Qu.:14.0   3rd Qu.:11.00   3rd Qu.:2.000  \n#&gt;  Max.   :77.00   Max.   :95.00   Max.   :27.0   Max.   :14.00   Max.   :3.300  \n#&gt;                                                                                \n#&gt;       JEU             VIE             SUP             POP       \n#&gt;  Min.   :15.00   Min.   : 5.00   Min.   :  3.0   Min.   : 0.40  \n#&gt;  1st Qu.:19.00   1st Qu.:11.00   1st Qu.: 70.0   1st Qu.: 6.60  \n#&gt;  Median :19.00   Median :13.00   Median :128.0   Median :10.30  \n#&gt;  Mean   :21.16   Mean   :12.52   Mean   :190.7   Mean   :19.83  \n#&gt;  3rd Qu.:23.00   3rd Qu.:14.00   3rd Qu.:301.0   3rd Qu.:23.60  \n#&gt;  Max.   :35.00   Max.   :18.00   Max.   :551.0   Max.   :61.20  \n#&gt;                                                                 \n#&gt;        X                 Y          \n#&gt;  Min.   :2498763   Min.   :1535337  \n#&gt;  1st Qu.:3713871   1st Qu.:1996737  \n#&gt;  Median :4166231   Median :2540281  \n#&gt;  Mean   :4091984   Mean   :2572739  \n#&gt;  3rd Qu.:4686147   3rd Qu.:2851709  \n#&gt;  Max.   :5206070   Max.   :4230412  \n#&gt; \n\n\n\n\n3.1.2 Transformations\n\n3.1.2.1 Copie intégrale\nElle s’effectue avec l’opérateur &lt;-\n\ntab&lt;-euro1988\ndim(tab)\n#&gt; [1] 25 15\nhead(tab,2)\n#&gt;   PAYS BLOC   PNB  TMI ESP URB NAT MOR FEC JEU VIE SUP POP       X       Y\n#&gt; 1  ALB  ALB   600 43.0  71  34  27   6 3.3  35   5  29 3.1 4825115 1684833\n#&gt; 2  AUT  AUT 10000 10.3  75  55  12  12 1.4  18  14  84 7.6 4299715 2335579\ntail(tab,2)\n#&gt;    PAYS BLOC   PNB  TMI ESP URB NAT MOR FEC JEU VIE SUP  POP       X       Y\n#&gt; 24  SWE  SWE 13200  5.9  77  83  12  11 1.8  18  18 450  8.4 4321587 3961396\n#&gt; 25  YUG  YUG  2300 27.1  70  47  15   8 2.1  24   8 256 23.6 4686147 1996737\n\n\n\n3.1.2.2 Sélection de lignes\nOn utilise la syntaxe tab2&lt;-tab[conditions , ] avec les opérateurs logiques suivants\n\n== : est égal à\n!= : est différent de\n&gt;  : est strictement supérieur à\n&lt;  : est strictement inférieur à\n&gt;= : est supérieur ou égal à\n&lt;= : est inférieur ou égal à\n\n& : ET (vrai si les deux conditions sont vérifiées)\n| : OU inclusif (vrai si l’une des conditions est vérifiée)\nxor : OU exclusif (vrai si une seule des conditions est vérifiée)\nExemple de sélection des pays socialistes\n\n\ntabsoc&lt;-euro1988[euro1988$BLOC==\"Soc\",]\ntabsoc\n#&gt;  [1] PAYS BLOC PNB  TMI  ESP  URB  NAT  MOR  FEC  JEU  VIE  SUP  POP  X    Y   \n#&gt; &lt;0 rows&gt; (or 0-length row.names)\n\n\nExemple de sélection des pays non socialistes\n\n\ntabcap&lt;-euro1988[euro1988$BLOC!=\"Soc\",]\ntabcap\n#&gt;    PAYS BLOC   PNB  TMI ESP URB NAT MOR FEC JEU VIE SUP  POP       X       Y\n#&gt; 1   ALB  ALB   600 43.0  71  34  27   6 3.3  35   5  29  3.1 4825115 1684833\n#&gt; 2   AUT  AUT 10000 10.3  75  55  12  12 1.4  18  14  84  7.6 4299715 2335579\n#&gt; 3   BEL  BEL  9200  9.7  75  95  12  11 1.5  19  14  31  9.9 3636312 2667243\n#&gt; 4   BGR  BGR  2000 14.5  72  65  13  11 2.0  21  11 111  9.0 5206070 1930219\n#&gt; 5   CHE  CHE 17800  6.8  77  61  12   9 1.5  17  14  41  6.6 3869378 2243130\n#&gt; 6   CSK  CSK  3200 13.9  71  74  14  12 2.0  24  11 128 15.6 4487005 2540281\n#&gt; 7   DDR  DDR  3700  9.2  72  77  13  13 1.7  19  14 108 16.6 4166231 2825762\n#&gt; 8   DEU  DEU 12000  8.6  75  94  10  11 1.4  15  15 248 61.2 3962835 2640209\n#&gt; 9   DNK  DNK 12600  8.4  75  84  11  11 1.5  18  15  43  5.1 3958433 3234283\n#&gt; 10  ESP  ESP  4800  9.0  76  91  12   8 1.7  23  12 505 39.0 2875285 1646307\n#&gt; 11  FIN  FIN 12200  5.8  74  62  12  10 1.6  19  13 337  4.9 4774974 4230412\n#&gt; 12  FRA  FRA 10100  8.0  75  73  14  10 1.8  21  13 551 55.9 3441707 2245325\n#&gt; 13  GBR  GBR  8900  9.5  75  91  13  12 1.8  19  15 245 57.1 3212580 3065463\n#&gt;  [ reached 'max' / getOption(\"max.print\") -- omitted 12 rows ]\n\n\nExemple de sélection des pays de plus 10 millions d’habitant\n\n\ntabbig&lt;-euro1988[euro1988$POP&gt;20,]\ntabbig\n#&gt;    PAYS BLOC   PNB  TMI ESP URB NAT MOR FEC JEU VIE SUP  POP       X       Y\n#&gt; 8   DEU  DEU 12000  8.6  75  94  10  11 1.4  15  15 248 61.2 3962835 2640209\n#&gt; 10  ESP  ESP  4800  9.0  76  91  12   8 1.7  23  12 505 39.0 2875285 1646307\n#&gt; 12  FRA  FRA 10100  8.0  75  73  14  10 1.8  21  13 551 55.9 3441707 2245325\n#&gt; 13  GBR  GBR  8900  9.5  75  91  13  12 1.8  19  15 245 57.1 3212580 3065463\n#&gt; 17  ITA  ITA  8600 10.1  75  72  10  10 1.4  19  13 301 57.3 4184347 1884241\n#&gt; 21  POL  POL  2100 17.5  71  61  17  10 2.2  26   9 313 38.0 4622269 2851709\n#&gt; 23  ROU  ROU  1200 25.6  70  49  16  11 2.3  25   9 238 23.0 5120263 2251425\n#&gt; 25  YUG  YUG  2300 27.1  70  47  15   8 2.1  24   8 256 23.6 4686147 1996737\n\n\nExemple de sélection des pays socialistes de plus 20 millions d’habitant (on mélange deux conditions avec l’opérateur &)\n\n\ntabsocbig&lt;-euro1988[euro1988$BLOC==\"Soc\" & euro1988$POP&gt;20,]\ntabsocbig\n#&gt;  [1] PAYS BLOC PNB  TMI  ESP  URB  NAT  MOR  FEC  JEU  VIE  SUP  POP  X    Y   \n#&gt; &lt;0 rows&gt; (or 0-length row.names)\n\n\n\n3.1.2.3 Sélection de colonnes\nOn utilise la syntaxe tab2&lt;-tab[  ,  liste ] avec différentes syntaxes pour les listes de variables :\n\nSélection nominale\n\n\ntab&lt;-euro1988[,c(\"PAYS\", \"BLOC\", \"PNB\", \"TMI\",\"POP\")]\nhead(tab,2)\n#&gt;   PAYS BLOC   PNB  TMI POP\n#&gt; 1  ALB  ALB   600 43.0 3.1\n#&gt; 2  AUT  AUT 10000 10.3 7.6\n\n\nSélection de positions\n\n\ntab&lt;-euro1988[,c(1:4, 13)]\nhead(tab,2)\n#&gt;   PAYS BLOC   PNB  TMI POP\n#&gt; 1  ALB  ALB   600 43.0 3.1\n#&gt; 2  AUT  AUT 10000 10.3 7.6\n\n\n\n3.1.2.4 Sélection simultanée de lignes et colonnes\nOn utilise la syntaxe tab2&lt;-tab[ conditions ,  liste]\n\nExemple : PNB et BLOC des pays de moins de 5 millions d’habitant\n\n\ntab&lt;-euro1988[euro1988$POP&lt;5, c(\"PAYS\",\"BLOC\",\"POP\",\"PNB\")]\ntab\n#&gt;    PAYS BLOC POP   PNB\n#&gt; 1   ALB  ALB 3.1   600\n#&gt; 11  FIN  FIN 4.9 12200\n#&gt; 16  IRL  IRL 3.5  5100\n#&gt; 18  LUX  LUX 0.4 16500\n#&gt; 20  NOR  NOR 4.2 15500\n\n\n\n\n3.1.3 Extractions\n\n3.1.3.1 Extraction d’une Variable = Vecteur\n\nSolution n°1 : utilisation de l’opérateur $\n\n\nmyvar&lt;-euro1988$POP\nstr(myvar)\n#&gt;  num [1:25] 3.1 7.6 9.9 9 6.6 15.6 16.6 61.2 5.1 39 ...\nmean(myvar)\n#&gt; [1] 19.828\n\n-Solution n°2 : utilisation de [ , ]\n\nmyvar&lt;-euro1988[,13]\nstr(myvar)\n#&gt;  num [1:25] 3.1 7.6 9.9 9 6.6 15.6 16.6 61.2 5.1 39 ...\nmean(myvar)\n#&gt; [1] 19.828\n\n\n\n3.1.3.2 Création d’une matrice\nOn sélectionne les lignes et les colonnes puis on convertit en matrice avec l’instruction as.matrix(). Attention, les variables doivent être de même type (toutes numériques ou toutes caractère ou …), sinon R effectue une conversion forcée.\n\nExemple 1 : création d’une matrice de corrélation\n\nOn commence par extraire trois variables du tableau pour en faire une matrice :\n\nmymat&lt;-euro1988[,c(\"PNB\",\"TMI\",\"FEC\")]\nrow.names(mymat)&lt;-euro1988$PAYS  # facultatif : donne le nom des lignes\nstr(mymat)\n#&gt; 'data.frame':    25 obs. of  3 variables:\n#&gt;  $ PNB: int  600 10000 9200 2000 17800 3200 3700 12000 12600 4800 ...\n#&gt;  $ TMI: num  43 10.3 9.7 14.5 6.8 13.9 9.2 8.6 8.4 9 ...\n#&gt;  $ FEC: num  3.3 1.4 1.5 2 1.5 2 1.7 1.4 1.5 1.7 ...\nmymat&lt;-as.matrix(mymat)\nstr(mymat)\n#&gt;  num [1:25, 1:3] 600 10000 9200 2000 17800 3200 3700 12000 12600 4800 ...\n#&gt;  - attr(*, \"dimnames\")=List of 2\n#&gt;   ..$ : chr [1:25] \"ALB\" \"AUT\" \"BEL\" \"BGR\" ...\n#&gt;   ..$ : chr [1:3] \"PNB\" \"TMI\" \"FEC\"\n\nPuis on applique la fonction cor() à cette matrice pour en faire une matrice de corrélation ;\n\nmycor&lt;-cor(mymat)\nmycor\n#&gt;            PNB        TMI        FEC\n#&gt; PNB  1.0000000 -0.6584308 -0.6144008\n#&gt; TMI -0.6584308  1.0000000  0.8136871\n#&gt; FEC -0.6144008  0.8136871  1.0000000\nstr(mycor)\n#&gt;  num [1:3, 1:3] 1 -0.658 -0.614 -0.658 1 ...\n#&gt;  - attr(*, \"dimnames\")=List of 2\n#&gt;   ..$ : chr [1:3] \"PNB\" \"TMI\" \"FEC\"\n#&gt;   ..$ : chr [1:3] \"PNB\" \"TMI\" \"FEC\"\n\n\nExemple 2 : Création d’une matrice de distance\n\nOn commence par extraire les coordonnées (X,Y) sous forme de matrice\n\nmatcoo&lt;-as.matrix(euro1988[,c(\"X\",\"Y\")])\nrow.names(matcoo)&lt;-euro1988$PAYS  # facultatif : donne le nom des lignes\nstr(matcoo)\n#&gt;  num [1:25, 1:2] 4825115 4299715 3636312 5206070 3869378 ...\n#&gt;  - attr(*, \"dimnames\")=List of 2\n#&gt;   ..$ : chr [1:25] \"ALB\" \"AUT\" \"BEL\" \"BGR\" ...\n#&gt;   ..$ : chr [1:2] \"X\" \"Y\"\nhead(matcoo)\n#&gt;           X       Y\n#&gt; ALB 4825115 1684833\n#&gt; AUT 4299715 2335579\n#&gt; BEL 3636312 2667243\n#&gt; BGR 5206070 1930219\n#&gt; CHE 3869378 2243130\n#&gt; CSK 4487005 2540281\n\nPuis on transforme ces coordonnées en distance à l’aide de la fonction dist()\n\nmatdis&lt;-as.matrix(dist(matcoo))\nstr(matdis)\n#&gt;  num [1:25, 1:25] 0 836370 1542200 453145 1106855 ...\n#&gt;  - attr(*, \"dimnames\")=List of 2\n#&gt;   ..$ : chr [1:25] \"ALB\" \"AUT\" \"BEL\" \"BGR\" ...\n#&gt;   ..$ : chr [1:25] \"ALB\" \"AUT\" \"BEL\" \"BGR\" ...\nmatdis[1:10,1:5]\n#&gt;           ALB       AUT       BEL       BGR       CHE\n#&gt; ALB       0.0  836370.2 1542200.5  453144.9 1106855.4\n#&gt; AUT  836370.2       0.0  741690.6  992872.1  440155.5\n#&gt; BEL 1542200.5  741690.6       0.0 1734169.4  483933.6\n#&gt; BGR  453144.9  992872.1 1734169.4       0.0 1372828.3\n#&gt; CHE 1106855.4  440155.5  483933.6 1372828.3       0.0\n#&gt; CSK  919842.9  277453.7  860114.5  942990.5  685391.6\n#&gt; DDR 1317515.9  508033.5  553120.4 1372320.3  653897.6\n#&gt; DEU 1286962.2  454189.8  327639.9 1431684.2  407929.4\n#&gt; DNK 1775368.8  961323.9  652147.5 1804766.4  995146.1\n#&gt; ESP 1950211.4 1582434.4 1273370.9 2348013.0 1159491.1\n\nEt on calcule le pays le plus proche de tous les autres à l’aide de la fonction apply() (qu’on verra ultérieurement dans un autre chapitre)\n\nmean(matdis)\n#&gt; [1] 1262347\naccess&lt;-apply(matdis, FUN=mean,1)\naccess&lt;-access[order(access)]\nround(access,0)\n#&gt;     DEU     AUT     DDR     LUX     CSK     CHE     BEL     NLD     HUN     POL \n#&gt;  898957  926937  932604  944407  954421  966312  981428  984509 1043514 1062733 \n#&gt;     ITA     DNK     FRA     YUG     GBR     ROU     ALB     BGR     GRC     IRL \n#&gt; 1095500 1105659 1125130 1133254 1301552 1309032 1348834 1450710 1558508 1559733 \n#&gt;     SWE     NOR     ESP     FIN     PRT \n#&gt; 1592972 1692199 1701144 1923979 1964658"
  },
  {
    "objectID": "03-Base.html#exploration-i-var.-quali.",
    "href": "03-Base.html#exploration-i-var.-quali.",
    "title": "3  R-Base",
    "section": "3.2 Exploration I (var. quali.)",
    "text": "3.2 Exploration I (var. quali.)\n\n3.2.1 Sélection et recodage\nLes variables qualitatives nominales ou factor sont des objets composés d’une liste de numéros et d’une liste d’étiquettes.\n\n# Chargement du tableau de données\ndon &lt;- read.table(file = \"resources/data/europe88/euro1988.csv\", # nom du fichier et chemin d'accès\n                  sep = \";\",                     # séparateur (ici, des points-virgule)\n                  header = TRUE,                 # ligne d'en-tête avec le nom des variables\n                  encoding=\"UTF-8\")              # encodage adapté au français\n\n# Extraction de la variable\nX&lt;-don$BLOC\nX\n#&gt;  [1] \"Soc\" \"Cap\" \"Cap\" \"Soc\" \"Cap\" \"Soc\" \"Soc\" \"Cap\" \"Cap\" \"Cap\" \"Cap\" \"Cap\"\n#&gt; [13] \"Cap\" \"Cap\" \"Soc\" \"Cap\" \"Cap\" \"Cap\" \"Cap\" \"Cap\" \"Soc\" \"Cap\" \"Soc\" \"Cap\"\n#&gt; [25] \"Soc\"\n\n# Vérification du type\nstr(X)\n#&gt;  chr [1:25] \"Soc\" \"Cap\" \"Cap\" \"Soc\" \"Cap\" \"Soc\" \"Soc\" \"Cap\" \"Cap\" \"Cap\" ...\n\nSi la variable chargée est de type character il faut la transformer avec as.factor() et repérer les niveaux disponibles avec levels()\n\nX&lt;-as.factor(X)\nclass(X)\n#&gt; [1] \"factor\"\nlevels(X)\n#&gt; [1] \"Cap\" \"Soc\"\n\nOn peut remplacer les niveaux en utilisant l’instruction levels()à nouveau, mais suivie d’un vecteur de charactères indiquant les changements de nom.\n\n\nlevels(X)&lt;-c(\"Capitaliste\",\n             \"Socialiste\")\nX\n#&gt;  [1] Socialiste  Capitaliste Capitaliste Socialiste  Capitaliste Socialiste \n#&gt;  [7] Socialiste  Capitaliste Capitaliste Capitaliste Capitaliste Capitaliste\n#&gt; [13] Capitaliste Capitaliste Socialiste  Capitaliste Capitaliste Capitaliste\n#&gt; [19] Capitaliste Capitaliste Socialiste  Capitaliste Socialiste  Capitaliste\n#&gt; [25] Socialiste \n#&gt; Levels: Capitaliste Socialiste\nstr(X)\n#&gt;  Factor w/ 2 levels \"Capitaliste\",..: 2 1 1 2 1 2 2 1 1 1 ...\n\nOn peut transformer une variable quantitative en facteur avec la fonction cut()\n\nY&lt;-cut(don$POP, breaks=c(0,10,30,100))\nY\n#&gt;  [1] (0,10]   (0,10]   (0,10]   (0,10]   (0,10]   (10,30]  (10,30]  (30,100]\n#&gt;  [9] (0,10]   (30,100] (0,10]   (30,100] (30,100] (10,30]  (10,30]  (0,10]  \n#&gt; [17] (30,100] (0,10]   (10,30]  (0,10]   (30,100] (10,30]  (10,30]  (0,10]  \n#&gt; [25] (10,30] \n#&gt; Levels: (0,10] (10,30] (30,100]\nstr(Y)\n#&gt;  Factor w/ 3 levels \"(0,10]\",\"(10,30]\",..: 1 1 1 1 1 2 2 3 1 3 ...\n\nOn peut ensuite recoder les classes avec levels()\n\nlevels(Y)&lt;-c(\"Petit\",\"Moyen\",\"Grand\")\nY\n#&gt;  [1] Petit Petit Petit Petit Petit Moyen Moyen Grand Petit Grand Petit Grand\n#&gt; [13] Grand Moyen Moyen Petit Grand Petit Moyen Petit Grand Moyen Moyen Petit\n#&gt; [25] Moyen\n#&gt; Levels: Petit Moyen Grand\nstr(Y)\n#&gt;  Factor w/ 3 levels \"Petit\",\"Moyen\",..: 1 1 1 1 1 2 2 3 1 3 ...\n\n\n\n3.2.2 Table de dénombrement\nPour dénomber une variable qualitative, on utilise l’instruction table() qui crée un objet particulier qui n’est ni un data.frame, ni une matrix.\n\ntab&lt;-table(X)\ntab\n#&gt; X\n#&gt; Capitaliste  Socialiste \n#&gt;          17           8\nstr(tab)\n#&gt;  'table' int [1:2(1d)] 17 8\n#&gt;  - attr(*, \"dimnames\")=List of 1\n#&gt;   ..$ X: chr [1:2] \"Capitaliste\" \"Socialiste\"\n\nOn peut créer des tables à 2, 3 ou 4 dimensions\n\ntab2&lt;-table(X,Y)\ntab2\n#&gt;              Y\n#&gt; X             Petit Moyen Grand\n#&gt;   Capitaliste     9     3     5\n#&gt;   Socialiste      2     5     1\nstr(tab2)\n#&gt;  'table' int [1:2, 1:3] 9 2 3 5 5 1\n#&gt;  - attr(*, \"dimnames\")=List of 2\n#&gt;   ..$ X: chr [1:2] \"Capitaliste\" \"Socialiste\"\n#&gt;   ..$ Y: chr [1:3] \"Petit\" \"Moyen\" \"Grand\"\n\nUn objet de type table peut être manipulé par des fonctions spéciales comme addmargins() quii rajoute des sommes en ligne (et en colonne si la table est de dimension 2)\n\naddmargins(tab)\n#&gt; X\n#&gt; Capitaliste  Socialiste         Sum \n#&gt;          17           8          25\naddmargins(tab2)\n#&gt;              Y\n#&gt; X             Petit Moyen Grand Sum\n#&gt;   Capitaliste     9     3     5  17\n#&gt;   Socialiste      2     5     1   8\n#&gt;   Sum            11     8     6  25\n\n\n\n\n\n\n\nNote\n\n\n\nLes objets de type table sont souvent la source de crises de nerf de la part des étudiants qui les confondent avec des objets de type vecteur, matrice ou data.frame. Il existe des fonctions de conversion d’un type vers un autre mais leur emploi n’est pas très simple.\nOn retiendra donc dans l’immédiat que les résultats de l’instruction tablesont des objets transitoires qui servent uniquement à afficher des résultats ou produire des graphiques à l’aide des instructions plot() ou barplot().\n\n\n\n\n3.2.3 Graphique avec plot()\nLa fonction plot() s’applique à la plupart de objets R. Elle produit des résultats différents selon le type d’objet qu’elle a identifié. Si on l’applique à un vecteur de type factor on obtient un diagramme en bâtons (à ne pas confondre avec un histogramme)\n\nplot(X)\n\n\n\n\nOn peut améliorer le graphique en lui ajoutant des paramètres c’est-à-dire des instructions séparées par des virgules. Le retour à la ligne après chaque paramètre n’est pas obligatoire mais il est recommandé car il rend le code plus clair.\n\nplot(X,\n     col=c(\"blue\",\"red\"), \n     main= \"Europe en 1988\",\n     xlab = \"Type politique\", \n     ylab = \"Nombre de pays\")"
  },
  {
    "objectID": "03-Base.html#exploration-ii-var.-quanti",
    "href": "03-Base.html#exploration-ii-var.-quanti",
    "title": "3  R-Base",
    "section": "3.3 Exploration II (var. quanti)",
    "text": "3.3 Exploration II (var. quanti)\n\n3.3.1 Résumés numériques\nUne variable numérique peut faire l’objet d’un ensemble de résumés statistiques à l’aide de fonctions élémentaires\n\nmin() : minimum\nmax() : maximum\nmean() : moyenne\nsd() : écart-type (en anglais : standard deviation, soit sd en abrégé)\nsum() : somme\n\n\nX &lt;- don$FEC\nmin(X)\n#&gt; [1] 1.4\nmax(X)\n#&gt; [1] 3.3\nmean(X)\n#&gt; [1] 1.816\nsd(X)\n#&gt; [1] 0.4160128\n\nPour calculer les quantiles on peut utiliser la fonction quantile() en paramétrant la valeur de fréquence cumulée ascendante\n\nquantile(X,0) : minimum\nquantile(X,0.10) : D1 (premier décile)\nquantile(X,0.25) : Q1 (premier quartile)\nquantile(X,0.5) : Q2 (médiane)\nquantile(X,0.75) : Q3 (troisième quartile)\nquantile(X,0.90) : D9 (dernier décile)\nquantile(X,1) : maximum\n\n\nX&lt;-don$FEC\nquantile(X,0.5)\n#&gt; 50% \n#&gt; 1.7\nsel&lt;-c(0,0.25,0.5,0.75,1)\nquantile(X,sel)\n#&gt;   0%  25%  50%  75% 100% \n#&gt;  1.4  1.5  1.7  2.0  3.3\nsel&lt;-c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1)\nquantile(X,sel)\n#&gt;   0%  10%  20%  30%  40%  50%  60%  70%  80%  90% 100% \n#&gt; 1.40 1.44 1.50 1.60 1.70 1.70 1.80 1.80 2.02 2.26 3.30\n\nIl peut arriver qu’une fonction soit manquante dans R, comme par exemple le coefficient de variation. Dans ce cas, on peut faire le calcul par des lignes de code ou créer sa propre fonction avec l’instruction function(). La fonction qui est stockée en mémoire apparaît dans la fenêtre Environnement. Lorsqu’on a créé plusieurs fonctions, on peut en faire un programme R qu’on charge en mémoire au début de chaque session. A plus long terme, on peut en faire un package qu’on partagera avec les autres utilisateurs de R.\nA titre d’exemple, nous créons une fonction cv() qui calcule le rapport entre l’écart-type et la moyenne d’une distribution :\n\n# lignes de code\nX &lt;- don$FEC\nsd(X)/mean(X)\n#&gt; [1] 0.2290819\n\n# fonction\ncv&lt;-function(var) {sd(var)/mean(var)}\ncv(X)\n#&gt; [1] 0.2290819\n\n\n\n3.3.2 Dénombrement\nUne variable quantitative peut être discrétisée avec cut(). Elle devient alors un facteur qu’on peut dénomber avec table() puis visualiseer avec plot() sous la forme de diagramme en bâtons.\n\nX&lt;-cut(don$FEC, c(1,1.5,2,2.5,3,3.5))\nstr(X)\n#&gt;  Factor w/ 5 levels \"(1,1.5]\",\"(1.5,2]\",..: 5 1 1 2 1 2 2 1 1 2 ...\ntable(X)\n#&gt; X\n#&gt; (1,1.5] (1.5,2] (2,2.5] (2.5,3] (3,3.5] \n#&gt;       7      13       4       0       1\n\n\nplot(X, col=c(\"green\",\"yellow\",\"orange\",\"red\",\"brown\"),\n     main = \"Fécondité en Europe en 1988\", xlab = \"classes\")\n\n\n\n\n\n\n3.3.3 Boîte à moustaches\nLa fonction boxplot() permet de visualiser une distribution sous forme de boîte à moustache où l’on repère facilement :\n\nla médiane\nles quartiles Q1 et Q3\nle minimum et le maximum\nles valeurs extrêmes situées à une distance supéreiure à 1.5 x (Q3-Q1) de la médiane\n\nLa syntaxe de base est la suivante :\n\nX&lt;-don$FEC\nboxplot(X)\n\n\n\n\nMais on peut améliorer la figure avec quelques paramètres de plus\n\nboxplot(X,horizontal = TRUE, col = \"gray80\",\n        main = \"Fécondité des pays européens en 1988\",\n        xlab = \"nb. enfants par femme\")\n\n\n\n\nEt on peut retirer les valeurs exceptionnelles avec le paramètre outline=FALSE\n\nboxplot(X,horizontal = TRUE, col = \"gray80\",\n        main = \"Fécondité des pays européens en 1988\",\n        xlab = \"nb. enfants par femme\",\n        outline = FALSE)\n\n\n\n\n\n\n3.3.4 Histogramme\nDans le cas d’une variable quantitative continue, la visualisation la plus logique est l’histogramme que l’on peut tracer avec la fonction hist(). Celle-ci comporte de nombreux paramètres que l’on peut visualiser dans la fenêtre Help qui se trouve en bas à gauche de R-studio :\nComme d’hebitude, on peut appliquer la syntaxe la plus simple :\n\nX&lt;-don$FEC\nhist(X)\n\n\n\n\nOn peut ensuite améliorer avec l’ajout de titres et un choix précis de classes. Dans le cas de la fécondité, il est par exemple important d’utiliser le seuil de 2.1 enfants par femme qui correspond au renouvellement des générations. On remarque que si les classes sont d’amplitudes inégales R utilise la densité de probabilité (rapport entre effectif et amplitude de la classe) et non plus l’effectif ce qui est statistiquement correct (et que ne fait pas Excel …).\n\nhist(X, \n     breaks = c(1.2, 1.5, 1.8, 2.1, 2.4, 3.3), \n     col=c(\"blue\", \"lightblue\",\"lightyellow\",\"orange\",\"red\"),\n     main = \"Fécondité des pays européens en 1988\",\n     ylab = \"Densité de probabilité\", \n     xlab = \"Nombre d'enfants par femme\",\n     xlim=c(1,3.5))\n\n\n\n\nOn peut également ajouter une courbe lissée de la distribution avec les fonctions lines() etdensity()en indiquant la portée du lissage à l'aide du paramètrebw`(band width) qui est exprimé dans l’unité de mesure de X\n\nhist(X, \n     breaks = c(1.2, 1.5, 1.8, 2.1, 2.4, 3.3),\n     col=c(\"blue\", \"lightblue\",\"green\",\"yellow\",\"orange\"),\n     main = \"Fécondité des pays européens en 1988\",\n     ylab = \"Densité de probabilité\", \n     xlab = \"Nombre d'enfants par femme\",\n     xlim=c(1,3.5))\nlines(density(X,bw=0.3),col=\"red\",lwd=2)"
  },
  {
    "objectID": "03-Base.html#exploration-iii-2-variables",
    "href": "03-Base.html#exploration-iii-2-variables",
    "title": "3  R-Base",
    "section": "3.4 Exploration III (2 variables)",
    "text": "3.4 Exploration III (2 variables)\nNous verrons en détail dans les chapitres suivants comment croiser deux variables d’un point de vue statistiques. Mais on peut déjà indiquer brièvement comment les visualiser rapidement à l’aide de trois exemples\n\n3.4.1 Deux variables qualitatives\n\nTableau de contingence\n\n\nX &lt;- don$BLOC\nlevels(X)&lt;-c(\"Capitalise\",\"Socialiste\")\nY&lt;-cut(don$POP, breaks=c(0,10,30,100))\nlevels(Y) &lt;- c(\"petit\",\"moyen\",\"grand\")\ntab&lt;-table(X,Y)\naddmargins(tab)\n#&gt;      Y\n#&gt; X     petit moyen grand Sum\n#&gt;   Cap     9     3     5  17\n#&gt;   Soc     2     5     1   8\n#&gt;   Sum    11     8     6  25\n\n\nGraphique\n\n\nplot(tab, col=c(\"yellow\",\"orange\",\"brown\"))\n\n\n\n\n\nTest (Chi-2)\n\n\ntest&lt;-chisq.test(X,Y)\n#&gt; Warning in chisq.test(X, Y): Chi-squared approximation may be incorrect\ntest\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  X and Y\n#&gt; X-squared = 5.0336, df = 2, p-value = 0.08072\n\n\n\n3.4.2 Deux variables quantitatives\n\nParamètres principaux\n\n\nY &lt;- don$TMI\nX&lt;-don$PNB\nsummary(X)\n#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#&gt;     600    2300    8600    7580   12000   17800\nsummary(Y)\n#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#&gt;    5.80    8.50    9.70   12.99   14.50   43.00\n\n\nGraphique\n\n\nplot(X,Y, xlab=\"PNB par habitant\",ylab=\"Mortalité infantile\")\ntext(X,Y,don$PAYS,pos = 4,cex=0.6)\n\n\n\n\n\nTest (Pearson)\n\n\ncor.test(Y,X)\n#&gt; \n#&gt;  Pearson's product-moment correlation\n#&gt; \n#&gt; data:  Y and X\n#&gt; t = -4.1955, df = 23, p-value = 0.0003459\n#&gt; alternative hypothesis: true correlation is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -0.8360497 -0.3558907\n#&gt; sample estimates:\n#&gt;        cor \n#&gt; -0.6584308\n\n\n\n3.4.3 Une quantitative et une qualitative\n\nGraphique\n\n\nY &lt;- don$TMI\nX &lt;- as.factor(don$BLOC)\nlevels(X)&lt;-c(\"Capitalise\",\"Socialiste\")\nplot(X,Y, \n     col=c(\"blue\",\"red\"),\n     xlab =\"Mortalité infantile\",\n     ylab = \"Bloc politique\",\n     horizontal=T)\n\n\n\n\n\nTest (Fischer)\n\n\nmod&lt;-aov(Y~X)\nsummary(mod)\n#&gt;             Df Sum Sq Mean Sq F value   Pr(&gt;F)    \n#&gt; X            1  797.4   797.4   20.85 0.000137 ***\n#&gt; Residuals   23  879.7    38.2                     \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "03-Base.html#en-résumé",
    "href": "03-Base.html#en-résumé",
    "title": "3  R-Base",
    "section": "3.5 En résumé",
    "text": "3.5 En résumé\n\n\n\nNous avons survolé les principales fonctions élémentaires de R-Base pour montrer qu’il est facile et surtout rapide de les employer en lieu et place d’un tableur comme Excel ou d’un logiciel de statistique click-bouton. Il reste encore beaucoup à apprendre mais à ce stade il est important de bien consolider les acquis et de connaître par coeur le nom des principales fonctions de base qui ont été présentées au cours de ce chapitre."
  },
  {
    "objectID": "11-Corrélation.html#préparation-des-données",
    "href": "11-Corrélation.html#préparation-des-données",
    "title": "4  Corrélation",
    "section": "4.1 Préparation des données",
    "text": "4.1 Préparation des données\n\n4.1.1 Chargement du tableau principal\nOn charge notre bon vieux fichier des pays européens en 1988\n\ndon&lt;-read.table(file = \"resources/data/europe88/euro1988.csv\",\n                sep = \";\",\n                header = T)\ndon$BLOC&lt;-as.factor(don$BLOC)\nlevels(don$BLOC)&lt;-c(\"Capitaliste\",\"Socialiste\")\nhead(don)\n#&gt;   PAYS        BLOC   PNB  TMI ESP URB NAT MOR FEC JEU VIE SUP  POP       X\n#&gt; 1  ALB  Socialiste   600 43.0  71  34  27   6 3.3  35   5  29  3.1 4825115\n#&gt; 2  AUT Capitaliste 10000 10.3  75  55  12  12 1.4  18  14  84  7.6 4299715\n#&gt; 3  BEL Capitaliste  9200  9.7  75  95  12  11 1.5  19  14  31  9.9 3636312\n#&gt; 4  BGR  Socialiste  2000 14.5  72  65  13  11 2.0  21  11 111  9.0 5206070\n#&gt; 5  CHE Capitaliste 17800  6.8  77  61  12   9 1.5  17  14  41  6.6 3869378\n#&gt; 6  CSK  Socialiste  3200 13.9  71  74  14  12 2.0  24  11 128 15.6 4487005\n#&gt;         Y\n#&gt; 1 1684833\n#&gt; 2 2335579\n#&gt; 3 2667243\n#&gt; 4 1930219\n#&gt; 5 2243130\n#&gt; 6 2540281\n\n\n\n4.1.2 Choix des deux variables à analyser\nEn dehors de BLOC et PAYS, on ne garde que deux variables que l’on renomme X et Y avec colnames() et que l’on convertit en type numérique général. Il suffira par la suite de modifier le choix des variables X et Y pour faire d’autres analyses.\n\neur&lt;-don[,c(\"PAYS\",\"BLOC\",\"URB\",\"TMI\")]\ncolnames(eur)&lt;-c(\"PAYS\",\"BLOC\",\"X\",\"Y\")\neur$X&lt;-as.numeric(eur$X)\neur$Y&lt;-as.numeric(eur$Y)\nhead(eur)\n#&gt;   PAYS        BLOC  X    Y\n#&gt; 1  ALB  Socialiste 34 43.0\n#&gt; 2  AUT Capitaliste 55 10.3\n#&gt; 3  BEL Capitaliste 95  9.7\n#&gt; 4  BGR  Socialiste 65 14.5\n#&gt; 5  CHE Capitaliste 61  6.8\n#&gt; 6  CSK  Socialiste 74 13.9\n\n\n\n4.1.3 On est malin …\nMais comme on ne sait plus ce que sont X et Y, on le précise avec des chaînes de caractères qu’on pourra utiliser dans les graphiques. Et on peut préparer une version multilangue …\n\n# Pour la version française\nfr_titre &lt;- \"Les pays européens en 1988\"\nfr_nomX &lt;- \"Taux d'urbanisation en %\"\nfr_nomY &lt;- \"Taux de mortalité infantile en p. 1000\"\nfr_auteur &lt;- \"Claude Grasland, Université Paris Diderot, 2020\"\n\n\n# Pour la version arabe\nar_titre &lt;- \"البلدان الأوروبية في عام 1988\"\nar_nomX &lt;-  \"معدل التحضر في المائة\"\nar_nomY &lt;- \"معدل وفيات الرضع في عام 1000\"\nar_auteur &lt;- \"كلود غراسلاند، جامعة باريس ديدرو، 2020\"\n\n\n# Pour la version anglaise\nen_titre &lt;- \"European countries in 1988\"\nen_nomX &lt;- \"Urbanisation rate %\"\nen_nomY &lt;- \"Infant mortality rate p. 1000\"\nen_auteur &lt;- \"Claude Grasland, University Paris Diderot, 2020\"\n\n\n# Pour la version russe\nru_titre &lt;- \"Европейские страны в 1988 году\"\nru_nomX &lt;- \"Уровень урбанизации в %\"\nru_nomY &lt;- \"Коэффициент младенческой смертности в 1000 году\"\nru_auteur &lt;- \"Клод Грассленд, Парижский университет Дидро, 2020\"\n\n\n\n4.1.4 On est paresseux …\nComme on prévoit qu’il y aura des différences entre pays socialistes et capitalistes, on crée deux sous-tableaux\n\neur_soc&lt;-eur[eur$BLOC==\"Socialiste\",]\neur_cap&lt;-eur[eur$BLOC==\"Capitaliste\",]"
  },
  {
    "objectID": "11-Corrélation.html#exploration-visuelle",
    "href": "11-Corrélation.html#exploration-visuelle",
    "title": "4  Corrélation",
    "section": "4.2 Exploration visuelle",
    "text": "4.2 Exploration visuelle\n\n4.2.1 Visualisation avec plot(X,Y)\nLa manière la plus simple d’analyser la relation entre X et Y est d’utiliser un simple plot\n\nplot(eur$X,eur$Y)\n\n\n\n\nLa fonction plot() comporte de nombreux paramètres permettant d’améliorer le graphique et de l’habiller. Voici un exemple d’habillage en français\n\nplot(eur$X,eur$Y,\n     main = fr_titre,   # titre\n     cex.main = 1,      # police du titre\n     sub = fr_auteur,   # sous-titre\n     cex.sub = 0.6,     # police du sous-titre\n     xlab = fr_nomX,    # nom de l'axe X\n     xlim = c(20,100),   # intervalle de l'axe X\n     ylab = fr_nomY,    # nom de l'axe Y\n     ylim = c(0,50),    # intervalle de l'axe Y\n     cex.axis = 0.8,    # police des gradations d'axes\n     cex.lab = 0.8,     # police des noms d'axes\n     cex = 0.6,         # taille des symboles\n     col = \"blue\")       # couleur des symboles\n\n\n\n\nOu en anglais: il suffit de changer le nom des variables relatives aux titres.\n\nplot(eur$X,eur$Y,\n     main = en_titre,   # titre\n     cex.main = 1,      # police du titre\n     sub = en_auteur,   # sous-titre\n     cex.sub = 0.5,     # police du sous-titre\n     xlab = en_nomX,    # nom de l'axe X\n     xlim = c(20,100),   # intervalle de l'axe X\n     ylab = en_nomY,    # nom de l'axe Y\n     ylim = c(0,50),    # intervalle de l'axe Y\n     cex.axis = 0.7,    # police des gradations d'axes\n     cex.lab = 0.7,     # police des noms d'axes\n     cex = 0.6,         # taille des symboles\n     col = \"blue\")       # couleur des symboles\n\n\n\n\n\n\n4.2.2 Identification des points avec cor + text(…)\nOn peut ajouter au graphique généré par plot(X,Y) une couche de labels avec text(X,Y,Code). On précise la position avec pos =, la taille de police avex cex = et la couleur avec col =.\n\nplot(x = eur$X,\n     y = eur$Y,\n     cex=0.5,\n     col= \"blue\",\n     ylim =c(0,50))\ntext(x = eur$X,\n     y = eur$Y,\n     label = eur$PAYS,\n     cex = 0.7,\n     pos=3,\n     col = \"blue\")\n\n\n\n\n\n\n4.2.3 Ajout de lignes horizontales ou verticales avec cor() + abline(…)\nOn peut rajouter à un graphique des lignes horizontales ou verticales avec abline en précisant leur position avec h= ou v=, leur épaisseur avec lwd = , leur style avec lty= et leur couleur avec col=\n\nplot(eur$X,eur$Y,\n     main = fr_titre,   # titre\n     cex.main = 1,      # police du titre\n     sub = fr_auteur,   # sous-titre\n     cex.sub = 0.6,     # police du sous-titre\n     xlab = fr_nomX,    # nom de l'axe X\n     xlim = c(20,100),   # intervalle de l'axe X\n     ylab = fr_nomY,    # nom de l'axe Y\n     ylim = c(0,50),    # intervalle de l'axe Y\n     cex.axis = 0.8,    # police des gradations d'axes\n     cex.lab = 0.8,     # police des noms d'axes\n     cex = 0.6,         # taille des symboles\n     col = \"blue\")       # couleur des symboles\n\n# Ajout d'une ligne horizontale  correspondant à la moyenne de Y\nabline(h=mean(eur$Y),col=\"red\",lwd = 1, lty = 2)\n# Ajout d'une ligne verticlae  correspondant à la moyenne de X\nabline(v=mean(eur$X),col=\"red\",lwd = 1, lty = 2)\n\ntext(x = eur$X,\n     y = eur$Y,\n     label = eur$PAYS,\n     cex = 0.6,\n     pos=3,\n     col = \"blue\")\n\n\n\n\nLa fonction abline() peut servir aussi à tracer la droite de régression Y=aX+b produite par la fonction lm()\n\nplot(eur$X,eur$Y)\nmaregression = lm(eur$Y~eur$X)\nabline(maregression,col=\"red\")\n\n\n\n\n\n\n4.2.4 Au delà de R-Base …\nIl existe des packages spécialisés permettant de faire des graphiques plus sophistiqués. Mais on les apprendra ultérieuement. Juste un exemple :\n\nlibrary(car)\nscatterplot(eur$X,eur$Y)"
  },
  {
    "objectID": "11-Corrélation.html#coefficients-de-corrélation",
    "href": "11-Corrélation.html#coefficients-de-corrélation",
    "title": "4  Corrélation",
    "section": "4.3 Coefficients de corrélation",
    "text": "4.3 Coefficients de corrélation\n\n4.3.1 Définition\n\n4.3.1.1 Relation linéaire/monotone/complexe\n\nil existe une relation linéaire entre deux variables quantitatives X et Y si l’on peut prédire leurs valeurs respectives par les fonctions Y = a1.X + b1 et X = a2.X = b2\nil existe une relation monotone entre deux variables quantitatives X et Y si l’on peut prédire les valeurs Y en fonction de celle de X far une fonction Y=f(X) qui est strictement croissante ou strictement décroissante.\nil existe une relation complexe entre deux variables quantitatives X et Y si l’on peut prédire les valeurs Y en fonction de celle de X par une fonction Y=f(X) qui comporte au moins un point minimum ou maximum de changement de pente (annulation de la dérivée première)\n\n\n\n\n\n\n\n\n4.3.1.2 Relation positive/négative/nulle\n\nUne relation linéaire ou monotone est positive si à un accroissement de X correspond un accroissement de Y\nUne relation linéaire ou monotone est négative si à un accroissement de X correspond une diminution de Y\nune relation est nulle si une variation de X n’entraine pas de variation de Y\n\n\n\n\n\n\n\n\n4.3.1.3 Relation forte/faible/nulle\n\nUne relation linéaire est forte si une valeur de X permet de prédire la valeur de Y avec une faible marge d’erreur.\nUne relation linéaire ou monotone est faible si une valeur de X permet de prédire la valeur de Y avec une forte marge d’erreur.\nune relation linéaire est nulle si une valeur de X ne permet aucunement de prédire la valeur de Y\n\n\n\n\n\n\n\n\n4.3.1.4 Relation significative/non siginificative\n\nUne relation linéaire est significative si l’effectif permettant de la mettre en évidence est suffisamment grand pour qu’on puisse exclure qu’elle soit l’effet du hasard.\nUne relation linéaire ou monotone est non significative si l’effectif permettant de la mettre en évidence n’est pas suffisamment grand pour qu’on puisse exclure qu’elle soit l’effet du hasard.\nOn considère traditionnellement qu’une relation est significative s’il y a moins de 5% de chances qu’elle soit l’effet du hasard (p-value &lt; 0.05).\n\n\n\n\n\n\n\n\n\n4.3.2 La fonction cor()\n\nLa fonction cor() permet de mesurer le coefficient de corrélation de deux variable X et Y.\nElle permet de détecter les relations linéaires en choisissant le paramètre (par défaut) method = pearson\n\nElle permet de détecter les relations non linéaires en choisissant le paramètre method = spearman qui mesure l’existence d’une relation monotone entre les rangs de X et Y\nLa syntaxe de la fonction cor() est très simple et permet de calculer trois types de corrélation. La méthode par défaut est pearson c’est-à-dire le coefficient de corrélation linéaire\n\n\ncor(eur$X,eur$Y)\n#&gt; [1] -0.6547219\ncor(eur$X,eur$Y, method = \"spearman\")\n#&gt; [1] -0.5699443\ncor(eur$X,eur$Y, method = \"kendall\")\n#&gt; [1] -0.4053653\n\ncor() permet de savoir si la relation est linéaire ou monotone\n\n\n\n\n\ncor() permet de repérer l’effet d’une valeur exceptionnelle\n\n\n\n\n\ncor() permet de savoir si la relation est positive ou négative\n\n\n\n\n\ncor() permet de avoir si la relation est forte ou faible\n\n\n\n\n\n\n\n4.3.3 La fonction cor.test()\n\nla fonction cor() permet de savoir si une relation est forte ou faible, positive ou négative, linéaire ou non linéaire. Mais cor() ne permet pas de savoir si une relation est significative ou pas.\nC’est la fonction cor.test() qui permet de tester la significativité d’une relation en fournissant un intervalle de confiance du coefficient de corrélation et une probabilité de rejet de H0 : il n’y a pas de relation appelée en anglais la p-value.\np-value &gt; 0.10 : relation non significative\n0.10 &gt; p-value &gt; 0.05 : relation presque significative\np-value &lt; 0.05 : relation significative\np-value &lt; 0.01 : relation très significative\n\nMême syntaxe que cor() :\n\ncor.test(eur$Y,eur$X)\n#&gt; \n#&gt;  Pearson's product-moment correlation\n#&gt; \n#&gt; data:  eur$Y and eur$X\n#&gt; t = -4.1541, df = 23, p-value = 0.0003835\n#&gt; alternative hypothesis: true correlation is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -0.8340765 -0.3501838\n#&gt; sample estimates:\n#&gt;        cor \n#&gt; -0.6547219\n\n\ncor.test(eur$Y,eur$X, method=\"spearman\")\n#&gt; Warning in cor.test.default(eur$Y, eur$X, method = \"spearman\"): Cannot compute\n#&gt; exact p-value with ties\n#&gt; \n#&gt;  Spearman's rank correlation rho\n#&gt; \n#&gt; data:  eur$Y and eur$X\n#&gt; S = 4081.9, p-value = 0.002936\n#&gt; alternative hypothesis: true rho is not equal to 0\n#&gt; sample estimates:\n#&gt;        rho \n#&gt; -0.5699443\n\n\n\n4.3.4 En résumé : intensité ou significativité ?\n\nLe carré du coefficient de corrélation appelé r-square ou r2 permet de mesurer le pouvoir explicatif de X par rapport à Y. Il ne dépend pas du nombre d’observations.\nle test de significativité ou p-value mesure la significativité de la relation c’est-à-dire le fait que la relation entre X et Y ne soit pas l’effet du hasard. Il dépend à la fois du niveau de corrélation et du nombre d’observations.\nA gauche : une relation forte mais non significative\nA droite : une relation faible mais très significative\n\n\n\n\n\n\nAnalysez le diagramme suivant :\n\n\n\n\n\nAnalysez les deux diagrammes suivants :"
  },
  {
    "objectID": "11-Corrélation.html#matrice-de-corrélation",
    "href": "11-Corrélation.html#matrice-de-corrélation",
    "title": "4  Corrélation",
    "section": "4.4 Matrice de corrélation",
    "text": "4.4 Matrice de corrélation\n\n4.4.1 Objectif de l’analyse\n\nSoit un ensemble de variables quantitatives continues \\((X_1...X_i...X_k)\\) décrivant les mêmes individus.\nOn se propose de construire la matrice \\(R_{ij}[1...i...k ; 1...j...k]\\) indiquant pour chaque paire de variable \\(ij\\) leur coefficient de corrélation (linéaire ou de rang)\nPuis de construire la matrice \\(p_{ij}[1...i...k ; 1...j...k]\\) indiquant pour chaque paire de variable \\(ij\\) la probabilité H0 d’absence de relation, c’est-à-dire le degré de significativité de la corrélation.\n\n\n\n4.4.2 Utilisation des résultats\n\nMettre en évidence des groupes de variables significativement corrélées entre elles, que ce soit de façon positive ou négative.\nPréparer la réalisation d’une analyse en composantes principales qui regroupera les variables corrélées entre elles en facteurs.\nIdentifier des variables non redondantes pour construire un modèle de régression multiple.\nIndentifier des variables fortement corrélées pouvant servir de proxy pour estimer des valeurs manquantes dans un tableau\n\n\n\n4.4.3 Visualisation d’une matrice de corrélation\n_ Sous la forme de tableaux montrant si possible à la fois les coefficients de corrélation et les seuils de significativité.\n\nSous la forme de graphes montrant de façon visuelle l’intesité, le signe et la significativité des relations.\nSous la forme de plans factoriels résultant d’une analyse en composantes principales.\n\nChacun de ces objectifs supposant en général l’emploi de packages spécialisés.\n\n\n4.4.4 Exemple : création d’un tableau quantitatif\nOn ne sélectionne que des variables quantitatives et on ajoute les noms des pays en attribut des lignes.\n\ntab&lt;-don[,c(\"PNB\",\"TMI\",\"ESP\",\"URB\",\"NAT\",\"MOR\",\"FEC\")]\nrow.names(tab)&lt;-don$PAYS\nhead(tab,3)\n#&gt;       PNB  TMI ESP URB NAT MOR FEC\n#&gt; ALB   600 43.0  71  34  27   6 3.3\n#&gt; AUT 10000 10.3  75  55  12  12 1.4\n#&gt; BEL  9200  9.7  75  95  12  11 1.5\n\nOn calcule la corrélation\n\nresul&lt;-cor(tab)\nstr(resul)\n#&gt;  num [1:7, 1:7] 1 -0.658 0.83 0.508 -0.466 ...\n#&gt;  - attr(*, \"dimnames\")=List of 2\n#&gt;   ..$ : chr [1:7] \"PNB\" \"TMI\" \"ESP\" \"URB\" ...\n#&gt;   ..$ : chr [1:7] \"PNB\" \"TMI\" \"ESP\" \"URB\" ...\n\nOn affiche la matrice de corrélation en arrondissant les valeurs\n\nround(resul,3)\n#&gt;        PNB    TMI    ESP    URB    NAT    MOR    FEC\n#&gt; PNB  1.000 -0.658  0.830  0.508 -0.466  0.125 -0.614\n#&gt; TMI -0.658  1.000 -0.728 -0.655  0.797 -0.414  0.814\n#&gt; ESP  0.830 -0.728  1.000  0.583 -0.501 -0.071 -0.619\n#&gt; URB  0.508 -0.655  0.583  1.000 -0.514  0.352 -0.554\n#&gt; NAT -0.466  0.797 -0.501 -0.514  1.000 -0.482  0.950\n#&gt; MOR  0.125 -0.414 -0.071  0.352 -0.482  1.000 -0.426\n#&gt; FEC -0.614  0.814 -0.619 -0.554  0.950 -0.426  1.000\n\n\n\n4.4.5 Utilisation du package psych\nLa fonction cor.test() de Rbase ne permet pas de calculer les corrélations pour toute une matrice. Aussi on charge le package psych qui dispose d’une fonction corr.test() beaucoup plus puissante qui crée plusieurs matrices de résultats\n\nlibrary(psych)\n#&gt; \n#&gt; Attaching package: 'psych'\n#&gt; The following object is masked from 'package:car':\n#&gt; \n#&gt;     logit\n#&gt; The following objects are masked from 'package:ggplot2':\n#&gt; \n#&gt;     %+%, alpha\nresults&lt;-psych::corr.test(tab)\nnames(results)\n#&gt;  [1] \"r\"      \"n\"      \"t\"      \"p\"      \"p.adj\"  \"se\"     \"sef\"    \"adjust\"\n#&gt;  [9] \"sym\"    \"ci\"     \"ci2\"    \"ci.adj\" \"stars\"  \"Call\"\n\nOn retrouve la matrice des coefficiences de corrélation\n\nround(results$r,3)\n#&gt;        PNB    TMI    ESP    URB    NAT    MOR    FEC\n#&gt; PNB  1.000 -0.658  0.830  0.508 -0.466  0.125 -0.614\n#&gt; TMI -0.658  1.000 -0.728 -0.655  0.797 -0.414  0.814\n#&gt; ESP  0.830 -0.728  1.000  0.583 -0.501 -0.071 -0.619\n#&gt; URB  0.508 -0.655  0.583  1.000 -0.514  0.352 -0.554\n#&gt; NAT -0.466  0.797 -0.501 -0.514  1.000 -0.482  0.950\n#&gt; MOR  0.125 -0.414 -0.071  0.352 -0.482  1.000 -0.426\n#&gt; FEC -0.614  0.814 -0.619 -0.554  0.950 -0.426  1.000\n\nMais aussi la matrice des tests de significativité\n\nround(results$p,3)\n#&gt;       PNB   TMI   ESP   URB   NAT   MOR   FEC\n#&gt; PNB 0.000 0.006 0.000 0.086 0.114 1.000 0.014\n#&gt; TMI 0.000 0.000 0.001 0.006 0.000 0.170 0.000\n#&gt; ESP 0.000 0.000 0.000 0.027 0.086 1.000 0.013\n#&gt; URB 0.010 0.000 0.002 0.000 0.086 0.254 0.045\n#&gt; NAT 0.019 0.000 0.011 0.009 0.000 0.103 0.000\n#&gt; MOR 0.552 0.040 0.738 0.085 0.015 0.000 0.170\n#&gt; FEC 0.001 0.000 0.001 0.004 0.000 0.034 0.000\n\nOn peut aussi faire une jolie matrice colorée avec des tests de signficativité sous forme d’étoiles\n\ncorPlot(tab, stars=TRUE, diag=FALSE)\n\n\n\n\n\n\n4.4.6 Utilisation du package factoMineR\nSi on veut voir les axes factoriels d’une analyse en composante principales on utilise la fonction PCA() de FactoMineR\n\nlibrary(FactoMineR)\nmonacp&lt;-PCA(tab, graph=FALSE)\n\nOn pourra ensuite visualiser la corrélation des variables avec les principaux axes factoriels et les coordonnées des individus sur ceux-ci.\n\n4.4.6.1 Corrélation des variables avec les axes factoriels\n\nplot.PCA(monacp,choix = \"varcor\")\n\n\n\n\n\n\n4.4.6.2 Coordonnées des individus sur les axes factoriels\n\nplot.PCA(monacp,choix = \"ind\",)"
  },
  {
    "objectID": "12-Régression.html#préparation-des-données",
    "href": "12-Régression.html#préparation-des-données",
    "title": "5  Régression simple",
    "section": "5.1 Préparation des données",
    "text": "5.1 Préparation des données\n\n5.1.1 Chargement du tableau principal\nOn charge notre bon vieux fichier des pays européens en 1988\n\ndon&lt;-read.table(file = \"resources/data/europe88/euro1988.csv\",\n                sep = \";\",\n                header = T)\ndon$BLOC&lt;-as.factor(don$BLOC)\nlevels(don$BLOC)&lt;-c(\"Capitaliste\",\"Socialiste\")\nhead(don)\n#&gt;   PAYS        BLOC   PNB  TMI ESP URB NAT MOR FEC JEU VIE SUP  POP       X\n#&gt; 1  ALB  Socialiste   600 43.0  71  34  27   6 3.3  35   5  29  3.1 4825115\n#&gt; 2  AUT Capitaliste 10000 10.3  75  55  12  12 1.4  18  14  84  7.6 4299715\n#&gt; 3  BEL Capitaliste  9200  9.7  75  95  12  11 1.5  19  14  31  9.9 3636312\n#&gt; 4  BGR  Socialiste  2000 14.5  72  65  13  11 2.0  21  11 111  9.0 5206070\n#&gt; 5  CHE Capitaliste 17800  6.8  77  61  12   9 1.5  17  14  41  6.6 3869378\n#&gt; 6  CSK  Socialiste  3200 13.9  71  74  14  12 2.0  24  11 128 15.6 4487005\n#&gt;         Y\n#&gt; 1 1684833\n#&gt; 2 2335579\n#&gt; 3 2667243\n#&gt; 4 1930219\n#&gt; 5 2243130\n#&gt; 6 2540281\n\n\n\n5.1.2 Choix des deux variables à analyser\nEn dehors de BLOC et PAYS, on ne garde que les deux variables PNB et TMI que l’on renomme X et Y avec colnames() et que l’on convertit en type numérique général. Il suffira par la suite de modifier le choix des variables X et Y pour faire d’autres analyses.\n\neur&lt;-don[,c(\"PAYS\",\"BLOC\",\"PNB\",\"TMI\")]\ncolnames(eur)&lt;-c(\"PAYS\",\"BLOC\",\"X\",\"Y\")\neur$X&lt;-as.numeric(eur$X)\neur$Y&lt;-as.numeric(eur$Y)\nhead(eur)\n#&gt;   PAYS        BLOC     X    Y\n#&gt; 1  ALB  Socialiste   600 43.0\n#&gt; 2  AUT Capitaliste 10000 10.3\n#&gt; 3  BEL Capitaliste  9200  9.7\n#&gt; 4  BGR  Socialiste  2000 14.5\n#&gt; 5  CHE Capitaliste 17800  6.8\n#&gt; 6  CSK  Socialiste  3200 13.9\n\nOn prépare les titres\n\n# Pour la version française\ntitre &lt;- \"Les pays européens en 1988\"\nnomX &lt;- \"Produit National brut ($/hab)\"\nnomY &lt;- \"Taux de mortalité infantile en p. 1000\"\nauteur &lt;- \"Claude Grasland, Université Paris Diderot, 2020\"\n\nComme on prévoit qu’il y aura des différences entre pays socialistes et capitalistes, on crée deux sous-tableaux\n\neur_soc&lt;-eur[eur$BLOC==\"Socialiste\",]\neur_cap&lt;-eur[eur$BLOC==\"Capitaliste\",]"
  },
  {
    "objectID": "12-Régression.html#forme-de-la-relation",
    "href": "12-Régression.html#forme-de-la-relation",
    "title": "5  Régression simple",
    "section": "5.2 Forme de la relation",
    "text": "5.2 Forme de la relation\n\n5.2.1 Vérification de la normalité de X et Y\nLa régression linéaire met en relation deux variables quantitatives X et Y dont on suppose que la distribution est normale (gaussienne) , c’est-à-dire unimodale et symérique.\n\n\n\n\n\nOn peut tester la normalité des disributions par inspection visuelle à l’aide de hist()\n\n\n\n\n\nLes fonctions qqnorm() et qqline() sont plus précises …\n\nqqnorm(eur$X, col=\"blue\",ylab=nomX)\nqqline(eur$X,col=\"red\")\n\n\n\n\nLes fonctions qqnorm() et qqline() sont plus précises …\n\nqqnorm(eur$Y, col=\"blue\",ylab=nomY)\nqqline(eur$Y,col=\"red\")\n\n\n\n\nMais la solution la plus précise est le test de Shapiro qui pose l’hypothèse H0 : la distribution est normale.\n\nshapiro.test(eur$X)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  eur$X\n#&gt; W = 0.9175, p-value = 0.04495\nshapiro.test(eur$Y)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  eur$Y\n#&gt; W = 0.72466, p-value = 0.00001594\n\n\n\n5.2.2 Visualisation de la forme de la relation\nOn peut faire un simple plot(X,Y). Mais on peut aussi créer pour cela une fonction personalisée adapté à ses préférences\n\nmonplot &lt;- function (varX , varY,  varN )\n{ \n  plot(varX,varY,\n     main = titre,      # titre\n     cex.main = 1,      # police du titre\n     cex = 0.6,         # taille des symboles\n     pch = 19,          # cercles pleins\n     col = \"red\")      # couleur des symboles\n  text(varX,varY,varN,cex=0.5,pos=3) # nom des élément\n  abline(v=mean(varX),lty=2,lwd=1,col=\"blue\") # moyenne X\n  abline(h=mean(varY),lty=2,lwd=1,col=\"blue\") # moyenne Y   \n  }\n\nJe peux désormais utiliser ma fonction monplot() !\n\nmonplot(varX = eur$X,varY = eur$Y, varN = eur$PAYS)\n\n\n\n\nJe peux décider de ne pas afficher le label des points.\n\nmonplot(varX = eur$X,varY = eur$Y, varN = NULL)\n\n\n\n\n\n\n5.2.3 Analyse de la corrélation\nJe commence par celuler le coefficient de corrélation linéaire (r) et le pouvoir explicatif de X par rapport à Y (r2)\n\ncor(eur$X,eur$Y)       # coefficient de corrélation (r)\n#&gt; [1] -0.6584308\n100*cor(eur$X,eur$Y)**2    # pouvoir explicatif (r2)\n#&gt; [1] 43.35312\n\nPuis, je teste la significativité de la corrélation linéaire …\n\ncor.test(eur$X,eur$Y)  # test de significativité (p-value)\n#&gt; \n#&gt;  Pearson's product-moment correlation\n#&gt; \n#&gt; data:  eur$X and eur$Y\n#&gt; t = -4.1955, df = 23, p-value = 0.0003459\n#&gt; alternative hypothesis: true correlation is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -0.8360497 -0.3558907\n#&gt; sample estimates:\n#&gt;        cor \n#&gt; -0.6584308\n\n… et je la compare à celle du coefficient de corrélation de rang de Spearman\n\ncor.test(eur$X,eur$Y, method=\"spearman\")  # test de significativité (p-value)\n#&gt; Warning in cor.test.default(eur$X, eur$Y, method = \"spearman\"): Cannot compute\n#&gt; exact p-value with ties\n#&gt; \n#&gt;  Spearman's rank correlation rho\n#&gt; \n#&gt; data:  eur$X and eur$Y\n#&gt; S = 4796.3, p-value = 0.0000001094\n#&gt; alternative hypothesis: true rho is not equal to 0\n#&gt; sample estimates:\n#&gt;        rho \n#&gt; -0.8447182\n\nOn peut conclure des analyses précédentes que :\n\nil existe une relation significative (p-value &lt; 0.05)\ncette relation est positive (r &gt; 0 )\ncette relation a un pouvoir explicatif moyen (r2 = 45%)\n\nMais …\n\nla relation est monotone mais non linéaire car le coefficient de Spearman (-0.90) est beaucoup plus fort que le coefficient de Pearson (-0.68) et également plus significatif"
  },
  {
    "objectID": "12-Régression.html#ajustement-du-modèle",
    "href": "12-Régression.html#ajustement-du-modèle",
    "title": "5  Régression simple",
    "section": "5.3 Ajustement du modèle",
    "text": "5.3 Ajustement du modèle\n\n5.3.1 Hypothèses statistiques\nConditions a priori\n\nX et Y sont deux variables normales (gaussienne)\nil existe une corrélation significative entre X et Y (p&lt; 0.05)\nX explique une part suffisamment forte de Y (r2 &gt; 20% )\nLe nuage de point affiche une forme linéaire\nles points sont répartis de façon régulière le long du nuage de points\nIl n’y a pas de valeurs exceptionnelles susceptibles de perturber le calcul.\n\nOn charge le package car (companion to applied regession).\n\nlibrary(car)\n#&gt; Loading required package: carData\n#&gt; \n#&gt; Attaching package: 'car'\n#&gt; The following object is masked from 'package:dplyr':\n#&gt; \n#&gt;     recode\n#&gt; The following object is masked from 'package:purrr':\n#&gt; \n#&gt;     some\n\nMéthode des moindres carrés ordinaire (MCO)\n\nLa droite \\(y_i = a.x_i + b + \\epsilon_i\\) qui minimise la somme des carrés des écarts entre les valeurs observées \\(y_i\\) et les valeurs estimées \\(\\hat{y_i}\\) a pour équation :\n\\(COV(X,Y) = \\sum_{i=1}^k \\sum_{j=1}^k (x_{i}-\\bar{x})^2.(y_{i}-\\bar{y})^2\\)\n\\(a = COV(X,Y) / (\\sigma_X)^2\\)\n\\(b = \\bar{y} - a.\\bar{x}\\)\n\nAnalyse de la variance\n\nLa somme des carré des écarts totale (\\(SCE_{tot}\\)) correspond à la variance de la variable à expliquer : \\(SCE_{tot} = \\sum_{i=1}^k (y_{i}-\\bar{y})^2\\)\nLa somme des carré des écarts résiduels (\\(SCE_{err}\\)) correspond à la somme des carrés des différences entre valeurs observées et estimées \\(SCE_{error} = \\sum_{i=1}^k (y_{i}-\\hat{y})^2\\)\nLe pouvoir explicatif d’un modèle de régression correspond à la part de la variance de Y expliquée par X.\n\\(Var. expliquée = (SCE_{tot}-SCE_{res}) / SCE_{tot} = r(X,Y)^{2}\\)\n\nVérifications a posteriori\nUn modèle de régression n’est valide que si les résidus de ce modèle \\(\\epsilon_i = (y_i - \\hat{y}_i)\\) remplissent les conditions suivantes :\n\nNormalité de la distribution des résidus\nAbsence d’autocorrélation des résidus\nHomogénéité de la variance des résidus\nAbsence de valeur à fort effet de levier\n\nSi ces quatre conditions ne sont pas remplies, les estimations de Y en fonction de X seront entâchées d’erreur et leur intervalle de confiance ne sera pas valable.\n\n\n5.3.2 La fonction lm()\nLa fonction lm() ou lm est l’abbréviation de linear model permet d’effectuer la plupart des modèles de régression linéaire basés sur la méthode des moindres carrés ordinaire. Sa syntaxe est a priori très simple et renvoie les coefficients b et a du modèle de régression.\n\nlm(eur$Y~eur$X)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = eur$Y ~ eur$X)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)        eur$X  \n#&gt;   20.890709    -0.001042\n\nMais en réalité lm() crée une liste de résultats que l’on a intérêt à stocker pour en examiner les composantes une à une.\n\nmonmodel&lt;-lm(eur$Y~eur$X)\nstr(monmodel)\n#&gt; List of 12\n#&gt;  $ coefficients : Named num [1:2] 20.89071 -0.00104\n#&gt;   ..- attr(*, \"names\")= chr [1:2] \"(Intercept)\" \"eur$X\"\n#&gt;  $ residuals    : Named num [1:25] 22.73 -0.17 -1.6 -4.31 4.46 ...\n#&gt;   ..- attr(*, \"names\")= chr [1:25] \"1\" \"2\" \"3\" \"4\" ...\n#&gt;  $ effects      : Named num [1:25] -64.96 26.96 -5.02 -8.69 2.2 ...\n#&gt;   ..- attr(*, \"names\")= chr [1:25] \"(Intercept)\" \"eur$X\" \"\" \"\" ...\n#&gt;  $ rank         : int 2\n#&gt;  $ fitted.values: Named num [1:25] 20.27 10.47 11.3 18.81 2.34 ...\n#&gt;   ..- attr(*, \"names\")= chr [1:25] \"1\" \"2\" \"3\" \"4\" ...\n#&gt;  $ assign       : int [1:2] 0 1\n#&gt;  $ qr           :List of 5\n#&gt;   ..$ qr   : num [1:25, 1:2] -5 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 ...\n#&gt;   .. ..- attr(*, \"dimnames\")=List of 2\n#&gt;   .. .. ..$ : chr [1:25] \"1\" \"2\" \"3\" \"4\" ...\n#&gt;   .. .. ..$ : chr [1:2] \"(Intercept)\" \"eur$X\"\n#&gt;   .. ..- attr(*, \"assign\")= int [1:2] 0 1\n#&gt;   ..$ qraux: num [1:2] 1.2 1.14\n#&gt;   ..$ pivot: int [1:2] 1 2\n#&gt;   ..$ tol  : num 0.0000001\n#&gt;   ..$ rank : int 2\n#&gt;   ..- attr(*, \"class\")= chr \"qr\"\n#&gt;  $ df.residual  : int 23\n#&gt;  $ xlevels      : Named list()\n#&gt;  $ call         : language lm(formula = eur$Y ~ eur$X)\n#&gt;  $ terms        :Classes 'terms', 'formula'  language eur$Y ~ eur$X\n#&gt;   .. ..- attr(*, \"variables\")= language list(eur$Y, eur$X)\n#&gt;   .. ..- attr(*, \"factors\")= int [1:2, 1] 0 1\n#&gt;   .. .. ..- attr(*, \"dimnames\")=List of 2\n#&gt;   .. .. .. ..$ : chr [1:2] \"eur$Y\" \"eur$X\"\n#&gt;   .. .. .. ..$ : chr \"eur$X\"\n#&gt;   .. ..- attr(*, \"term.labels\")= chr \"eur$X\"\n#&gt;   .. ..- attr(*, \"order\")= int 1\n#&gt;   .. ..- attr(*, \"intercept\")= int 1\n#&gt;   .. ..- attr(*, \"response\")= int 1\n#&gt;   .. ..- attr(*, \".Environment\")=&lt;environment: R_GlobalEnv&gt; \n#&gt;   .. ..- attr(*, \"predvars\")= language list(eur$Y, eur$X)\n#&gt;   .. ..- attr(*, \"dataClasses\")= Named chr [1:2] \"numeric\" \"numeric\"\n#&gt;   .. .. ..- attr(*, \"names\")= chr [1:2] \"eur$Y\" \"eur$X\"\n#&gt;  $ model        :'data.frame':   25 obs. of  2 variables:\n#&gt;   ..$ eur$Y: num [1:25] 43 10.3 9.7 14.5 6.8 13.9 9.2 8.6 8.4 9 ...\n#&gt;   ..$ eur$X: num [1:25] 600 10000 9200 2000 17800 3200 3700 12000 12600 4800 ...\n#&gt;   ..- attr(*, \"terms\")=Classes 'terms', 'formula'  language eur$Y ~ eur$X\n#&gt;   .. .. ..- attr(*, \"variables\")= language list(eur$Y, eur$X)\n#&gt;   .. .. ..- attr(*, \"factors\")= int [1:2, 1] 0 1\n#&gt;   .. .. .. ..- attr(*, \"dimnames\")=List of 2\n#&gt;   .. .. .. .. ..$ : chr [1:2] \"eur$Y\" \"eur$X\"\n#&gt;   .. .. .. .. ..$ : chr \"eur$X\"\n#&gt;   .. .. ..- attr(*, \"term.labels\")= chr \"eur$X\"\n#&gt;   .. .. ..- attr(*, \"order\")= int 1\n#&gt;   .. .. ..- attr(*, \"intercept\")= int 1\n#&gt;   .. .. ..- attr(*, \"response\")= int 1\n#&gt;   .. .. ..- attr(*, \".Environment\")=&lt;environment: R_GlobalEnv&gt; \n#&gt;   .. .. ..- attr(*, \"predvars\")= language list(eur$Y, eur$X)\n#&gt;   .. .. ..- attr(*, \"dataClasses\")= Named chr [1:2] \"numeric\" \"numeric\"\n#&gt;   .. .. .. ..- attr(*, \"names\")= chr [1:2] \"eur$Y\" \"eur$X\"\n#&gt;  - attr(*, \"class\")= chr \"lm\"\n\nUn résumé des résultats principaux est fourni avec summary() appliqué à l’objet créé par lm().\n\nsummary(monmodel)\n\nOn obtient ainsi :\n\nl’équation de la droite Y = a.X+b\nla significativité et l’intervalle de confiance de a et b\nle pouvoir explicatif du modèle \\(r(X,Y)^2\\)\n\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = eur$Y ~ eur$X)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -7.8351 -2.7982 -1.6039  0.6391 22.7345 \n#&gt; \n#&gt; Coefficients:\n#&gt;               Estimate Std. Error t value      Pr(&gt;|t|)    \n#&gt; (Intercept) 20.8907087  2.2796125   9.164 0.00000000386 ***\n#&gt; eur$X       -0.0010420  0.0002484  -4.196      0.000346 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 6.427 on 23 degrees of freedom\n#&gt; Multiple R-squared:  0.4335, Adjusted R-squared:  0.4089 \n#&gt; F-statistic:  17.6 on 1 and 23 DF,  p-value: 0.0003459\n\nOn peut également analyser plus en détail la variance en appliquant anova() à l’objet créé par lm() ce qui monte la quantité de variance expliquée par X et la quantité de variance résiduelle. Le test de Fisher (Pr&gt;F) détermine si le modèle est significatif et renvoie la même valeur que la p-value du coeff. de corrélation.\n\nanova(monmodel)\n#&gt; Analysis of Variance Table\n#&gt; \n#&gt; Response: eur$Y\n#&gt;           Df Sum Sq Mean Sq F value    Pr(&gt;F)    \n#&gt; eur$X      1 727.09  727.09  17.602 0.0003459 ***\n#&gt; Residuals 23 950.05   41.31                      \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nOn peut extraire de l’objet créé par lm() les valeurs estimées de Y et les résidus c’est-à-dire les erreurs d’estimation.\n\neur$Y_estim&lt;-monmodel$fitted.values\neur$Y_resid&lt;-monmodel$residuals\nhead(eur)\n#&gt;   PAYS        BLOC     X    Y  Y_estim    Y_resid\n#&gt; 1  ALB  Socialiste   600 43.0 20.26548 22.7345189\n#&gt; 2  AUT Capitaliste 10000 10.3 10.47025 -0.1702487\n#&gt; 3  BEL Capitaliste  9200  9.7 11.30389 -1.6038855\n#&gt; 4  BGR  Socialiste  2000 14.5 18.80662 -4.3066167\n#&gt; 5  CHE Capitaliste 17800  6.8  2.34229  4.4577101\n#&gt; 6  CSK  Socialiste  3200 13.9 17.55616 -3.6561615\n\nOn peut tracer la droite de régression avec abline()\n\nmonplot(eur$X,eur$Y,eur$PAYS)\nabline(monmodel, col=\"blue\",lwd=2)\n\n\n\n\nOn peut enfin analyser a posteriori la qualité de la régression avec plot().\n\npar(mfrow=c(2,2))\nplot(monmodel,labels.id = eur$PAYS)"
  },
  {
    "objectID": "12-Régression.html#diagnostics-du-modèle",
    "href": "12-Régression.html#diagnostics-du-modèle",
    "title": "5  Régression simple",
    "section": "5.4 Diagnostics du modèle",
    "text": "5.4 Diagnostics du modèle\n\n5.4.1 Diagnostic 1 : Indépendance des résidus ?\nL’objectif est de savoir si les résidus se répartissent régulièrement de part et d’autre de la droite de régression tout au long de celle-ci. Si c’est bien le cas le graphique residuals Vs Fitted généré par plot(monmodel,1) devrait donner une droite horizontale :\n\nplot(monmodel,1,labels.id = eur$PAYS)\n\n\n\n\nOn peut tester statistiquement l’indépendance des résidus à l’aide du test de Durbin-Watson qui mesure si deux valeurs successives ont des résidus proches. L’indépendance des résidus est rejetée si p-value &lt; 0.05\n\ndurbinWatsonTest(monmodel)\n#&gt;  lag Autocorrelation D-W Statistic p-value\n#&gt;    1     -0.03883526      1.455678   0.148\n#&gt;  Alternative hypothesis: rho != 0\n\nIci on trouve p-value &gt; 0.05 donc les résidus sont indépendants.\n\n\n5.4.2 Diagnostic 2 : Normalité des résidus ?\nL’objectif est de savoir si les résidus ont une distribution normale Si c’est bien le cas le graphique généré par plot(monmodel,2) devrait donner une droite oblique :\n\nplot(monmodel,2,labels.id = eur$PAYS)\n\n\n\n\nOn peut tester statistiquement la normalité des résidus à l’aide du test de Shapiro-Wilk. Les résidus sont normaux si p-value &gt; 0.05\n\nshapiro.test(monmodel$residuals)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  monmodel$residuals\n#&gt; W = 0.81605, p-value = 0.0004263\n\nIci on trouve une p-value très clairement inférieure à 0.05 donc la distribution des résidus n’est pas gaussienne.\n\n\n5.4.3 Diagnostic 3 : Homogénéité des résidus ?\nL’objectif est de savoir si la variance des résidus est constante, c’est-à-dire si il s’écarte environ de la même distance tout au long de la droite . Si c’est bien le cas le graphique généré par plot(monmodel,3) devrait donner une droite horizontale\n\nplot(monmodel,3,labels.id = eur$PAYS)\n\n\n\n\nOn peut tester statistiquement l’homogénéité des résidus à l’aide du test de Breush-Pagan. L’hypothèse d’homogénéité est rejetée si la p-value est inférieure à 0.05.\n\nncvTest(monmodel)\n#&gt; Non-constant Variance Score Test \n#&gt; Variance formula: ~ fitted.values \n#&gt; Chisquare = 9.429701, Df = 1, p = 0.002135\n\nIci, la p-value est inférieure à 0.05 donc les résidus ne sont pas homogènes.\n\n\n5.4.4 Diagnostic 4 : Absence de valeur exceptionnelles ?\nL’objectif est de savoir s’il existe des valeurs qui exercent une influence exceptionnelle sur les résultats de la régression. On peut reprérer ces valeurs de plusieurs manières, notamment à l’aide de la distance de Cook générée par plot(monmodel,4).O n repère le cas particulier de l’Albanie :\n\nplot(monmodel,4,labels.id = eur$PAYS)\n\n\n\n\nLe test statistique de Bonferroni permet de déterminer s’il existe des valeurs exceptionnelles avec une p-value &lt; 0.05.\n\noutlierTest(monmodel, labels = eur$PAYS)\n#&gt;     rstudent unadjusted p-value Bonferroni p\n#&gt; ALB 5.905381       0.0000060791   0.00015198\n\nIci, on doit conclure qu’il existe au moins une valeur exceptionnelle, l’Albanie, susceptible de fausser les conclusions du modèle de régression."
  },
  {
    "objectID": "12-Régression.html#améliorations-du-modèle",
    "href": "12-Régression.html#améliorations-du-modèle",
    "title": "5  Régression simple",
    "section": "5.5 Améliorations du modèle",
    "text": "5.5 Améliorations du modèle\n\n5.5.1 Modèle linéaire (R2 = 46%)\n\nscatterplot(eur$X,eur$Y, ellipse = T,smooth = F,pch=19)\ntext(eur$X,eur$Y, eur$PAYS, col=\"red\",pos=2,cex=0.6)\n\n\n\n\n\n\n5.5.2 Modèle linéaire sans l’Albanie (R2 = 53%)\n\neur2&lt;-eur[eur$PAYS !=\"ALB\",]\nscatterplot(eur2$X,eur2$Y, ellipse = T,smooth = F,pch=19)\ntext(eur2$X,eur2$Y, eur2$PAYS, col=\"red\",pos=2,cex=0.6)\n\n\n\n\n\n\n5.5.3 Modèle exponentiel (R2 = 63%)\n\nscatterplot(eur$X,log(eur$Y), ellipse = T,smooth = F,  pch=19)\ntext(eur$X,log(eur$Y), eur$PAYS, col=\"red\",pos=2,cex=0.6)\n\n\n\n\n\n\n5.5.4 Modèle puissance (R2 = 83%)\n\nscatterplot(log(eur$X),log(eur$Y), ellipse = T,smooth = F,  pch=19)\ntext(log(eur$X),log(eur$Y), eur$PAYS, col=\"red\",pos=2,cex=0.6)"
  },
  {
    "objectID": "13-Anova.html#préparation-des-données",
    "href": "13-Anova.html#préparation-des-données",
    "title": "6  Analyse de variance",
    "section": "6.1 Préparation des données",
    "text": "6.1 Préparation des données\n\n6.1.1 Chargement du fichier\nOn charge un fichier statistique appelé tips.csv où les séparateurs sont des points-virgules et les décimales des points.\n\ndon&lt;-read.table(file = \"resources/data/tips/tips.csv\",\n                sep = \";\",\n                header = T)\nhead(don)\n\n  IDEN TOTBILL  TIP SEX SMOKER DAY TIME SIZE\n1 R001   16.99 1.01   1      0   6    1    2\n2 R002   10.34 1.66   0      0   6    1    3\n3 R003   21.01 3.50   0      0   6    1    3\n4 R004   23.68 3.31   0      0   6    1    2\n5 R005   24.59 3.61   1      0   6    1    4\n6 R006   25.29 4.71   0      0   6    1    4\n\n\n\n\n6.1.2 Contenu du fichier\nCe dossier contient les pourboires (tips en anglais, d’où le nom du fichier) d’un serveur dans un restaurant américain aux débuts des années 1990. Le restaurant était dans un centre commercial. Il y avait une zone fumeurs et une zone non fumeurs.Les données indiquent le prix du repas, le pourboire, le sexe de la personne qui a payé et donné le pourboire, si c’était dans la zone fumeurs ou non, le jour où le repas a été pris, si c’était en journée ou en soirée et enfin, le nombre de convives.\nSources : Ces données sont disponibles dans le package R nommé rggobi et sont décrites dans l’ouvrage de Cook et Swayne intitulé Interactive and Dynamic Graphics for Data Analysis. Elles font partie des données d’exemple du livre de Bryant et Smith dont la première édition est parue en 1995 dont le titre est Practical Data Analysis: Case Studies in Business Statistics.\n\n\n6.1.3 Dictionaire des variables\n\nIDEN : identifiant du repas\nTOTBILL : prix du repas (en dollars des années 1990)\nTIP : pourboire (en dollars des années 1990)\nSEX : sexe de la personne qui a payé (0 = Homme, 1 = Femme)\nSMOKER : la personne qui a payé est non-fumeur (O) ou fumeur (1)\nDAY : jour de la semaine (1 = dimanche, 2 = lundi, 3 = mardi, …)\nTIME : repas pris en journée (0) ou le soir (1)\nSIZE : nombre de convives\n\n\n\n6.1.4 Recodage des variables\nLe type de plusieurs variables est incorrect. On transforme les codes numériques en facteur et on recode les niveaux en français :\n\ndon$IDEN&lt;-as.character(don$IDEN)\ndon$SEX&lt;-as.factor(don$SEX)\nlevels(don$SEX)&lt;-c(\"Homme\",\"Femme\")\ndon$SMOKER&lt;-as.factor(don$SMOKER)\nlevels(don$SMOKER)&lt;-c(\"Non fumeur\", \"Fumeur\")\ndon$DAY&lt;-as.factor(don$DAY)\nlevels(don$DAY)&lt;-c(\"Mercredi\",\"Jeudi\",\"Vendredi\",\"Samedi\")\ndon$TIME&lt;-as.factor(don$TIME)\nlevels(don$TIME)&lt;-c(\"Journée\",\"Soirée\")\n\n\n\n6.1.5 Ajout d’une nouvelle variable\nOn crée la variable PCT qui est le rapport entre le pourboire (TIP) et le prix total (TOTBILL) du repas exprimé en pourcentage.\n\ndon$PCT&lt;-100*don$TIP/don$TOTBILL\n\n\n\n6.1.6 Résumé de l’ensemble du tableau\n\nsummary(don)\n\n     IDEN              TOTBILL           TIP            SEX     \n Length:244         Min.   : 3.07   Min.   : 1.000   Homme:157  \n Class :character   1st Qu.:13.35   1st Qu.: 2.000   Femme: 87  \n Mode  :character   Median :17.80   Median : 2.900              \n                    Mean   :19.79   Mean   : 2.998              \n                    3rd Qu.:24.13   3rd Qu.: 3.562              \n                    Max.   :50.81   Max.   :10.000              \n        SMOKER          DAY          TIME          SIZE           PCT        \n Non fumeur:151   Mercredi:62   Journée: 68   Min.   :1.00   Min.   : 3.564  \n Fumeur    : 93   Jeudi   :19   Soirée :176   1st Qu.:2.00   1st Qu.:12.913  \n                  Vendredi:87                 Median :2.00   Median :15.477  \n                  Samedi  :76                 Mean   :2.57   Mean   :16.080  \n                                              3rd Qu.:3.00   3rd Qu.:19.148  \n                                              Max.   :6.00   Max.   :71.034"
  },
  {
    "objectID": "13-Anova.html#rappels-sur-la-régression",
    "href": "13-Anova.html#rappels-sur-la-régression",
    "title": "6  Analyse de variance",
    "section": "6.2 Rappels sur la régression",
    "text": "6.2 Rappels sur la régression\n\n6.2.1 La distribution de PCT est-elle normale ?\n\nhist(don$PCT, breaks = 10,col=\"lightyellow\",probability = TRUE)\nlines(density(don$PCT,bw=3),col=\"red\",lwd=1)\n\n\n\n\nLa distribution semble normale . Mais est-ce l’avis du test de Shapiro ?\n\nshapiro.test(don$PCT)\n\n\n    Shapiro-Wilk normality test\n\ndata:  don$PCT\nW = 0.79943, p-value &lt; 2.2e-16\n\n\nQue nous apprend la boxplot ?\n\nboxplot(don$PCT, col=\"lightyellow\",horizontal = T)\n\n\n\n\nLa distribution devient presque parfaitement gaussienne si on retire les 4 valeurs exceptionnelles !\n\ndon2&lt;-don[don$PCT&lt;30,]\nshapiro.test(don2$PCT)\n\n\n    Shapiro-Wilk normality test\n\ndata:  don2$PCT\nW = 0.99435, p-value = 0.5066\n\n\n\nhist(don2$PCT, breaks = 10,col=\"lightyellow\",probability = TRUE)\nlines(density(don2$PCT,bw=3),col=\"red\",lwd=1)\n\n\n\n\n\n\n6.2.2 Y-a-t-il une relation entre le prix du repas et le pourboire ?\nOn fait le graphique …\n\nplot(don2$TOTBILL,don2$TIP)\n\n\n\n\nPuis on teste le coefficient de Pearson et celui de Sperman\n\ncor.test(don2$TIP,don2$TOTBILL)\n\n\n    Pearson's product-moment correlation\n\ndata:  don2$TIP and don2$TOTBILL\nt = 14.906, df = 239, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.6223204 0.7543075\nsample estimates:\n      cor \n0.6941023 \n\ncor.test(don2$TIP,don2$TOTBILL, method=\"spearman\")\n\nWarning in cor.test.default(don2$TIP, don2$TOTBILL, method = \"spearman\"):\nCannot compute exact p-value with ties\n\n\n\n    Spearman's rank correlation rho\n\ndata:  don2$TIP and don2$TOTBILL\nS = 688482, p-value &lt; 2.2e-16\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.7048791 \n\n\n\n\n6.2.3 Modèle de régression\nOn calcule le modèle de régression\n\nmareg&lt;-lm(don2$TIP~don2$TOTBILL)\n\n\nplot(don2$TOTBILL,don2$TIP, xlab=\"Repas ($)\",ylab = \"Pourboire ($)\",pch=19,cex=0.5)\nabline(mareg,col=\"red\",lwd=1)"
  },
  {
    "objectID": "13-Anova.html#test-dégalité-des-moyennes",
    "href": "13-Anova.html#test-dégalité-des-moyennes",
    "title": "6  Analyse de variance",
    "section": "6.3 Test d’égalité des moyennes",
    "text": "6.3 Test d’égalité des moyennes\n\n6.3.1 Hypothèses\nOn considère une variable Y quantitative continue définie sur une population de réféence P et une variable X qualitative à deux modalités divisant P en deux sous population P1 et P2.\nSoit par exemple la variable Y = PCT et la variable X = SEX. On peut se demander si les femmes sont plus généreuses que les hommes, les hommes sont plus généreux que les femmes, les hommes sont différents des femmes, etc…\n\nY&lt;-don2$PCT\nnomY &lt;-\"Pourboire relatif (%)\"\n\nX&lt;-don2$SEX\nnomX &lt;- \"Sexe du client\"\n\n#X&lt;-don2$SMOKER\n#nomX&lt;- \"Tabagisme\"\n\n#X&lt;-don2$TIME\n#nomX&lt;- \"Moment de la journée\"\n\n\n\n6.3.2 Visualisations\nLe plus simple est d’utiliser boxplot() en version de base …\n\nboxplot(Y~X)\n\n\n\n\n… ou améliorée\n\nboxplot(Y~X,horizontal=T, xlab = nomY, ylab=nomX, col=\"gray80\")\n\n\n\n\nOn peut aussi utiliser le package beanplot() en version simple …\n\nlibrary(beanplot)\nbeanplot(Y~X)\n\n\n\n\n… ou améliorée :\n\nlibrary(beanplot)\nbeanplot(Y~X,horizontal=T, xlab = nomY, ylab=nomX,col = \"gray80\")\n\n\n\n\n\n\n6.3.3 Paramètres principaux\nOn détermine la moyenne et l’écart-type de chaque échantillon avec la fonction tapply() couplée avec les fonctions mean(), sd() ou summary()\n\ntapply(Y,X, mean)\n\n   Homme    Femme \n15.41076 16.16741 \n\ntapply(Y,X,sd)\n\n   Homme    Femme \n4.732686 4.329426 \n\ntapply(Y,X, summary)\n\n$Homme\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  3.564  12.136  15.325  15.411  18.622  29.199 \n\n$Femme\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  5.643  13.999  15.522  16.167  19.284  27.952 \n\n\n\n\n6.3.4 Test d’égalité des moyennes\nSi la distribution est gaussienne on utilise le test de Student :\n\nt.test(Y~X)\n\n\n    Welch Two Sample t-test\n\ndata:  Y by X\nt = -1.254, df = 186.21, p-value = 0.2114\nalternative hypothesis: true difference in means between group Homme and group Femme is not equal to 0\n95 percent confidence interval:\n -1.9470273  0.4337437\nsample estimates:\nmean in group Homme mean in group Femme \n           15.41076            16.16741 \n\n\nSi ce n’est pas le cas et s’il y a des valeurs exceptionnelles on préfèrera le test de Wilcoxon basé sur les rangs des valeurs (comme le coefficient de corrélation de Spearman)\n\nwilcox.test(Y~X)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  Y by X\nW = 5953, p-value = 0.1908\nalternative hypothesis: true location shift is not equal to 0\n\n\nLorsque les deux tests divergent dans leur conclusions, il y a certainement un problème de violation de l’hypothèse gaussienne. Dans ce cas, il faut sans doute transformer Y ou retirer des valeurs exceptionnelles (Cf.cours sur la corrélation et la régression)"
  },
  {
    "objectID": "13-Anova.html#analyse-de-variance",
    "href": "13-Anova.html#analyse-de-variance",
    "title": "6  Analyse de variance",
    "section": "6.4 Analyse de variance",
    "text": "6.4 Analyse de variance\n\n6.4.1 Hypothèses\nOn considère une variable Y quantitative continue définie sur une population de réféence P et une variable X qualitative à k modalités divisant P en k sous population P1…Pk.\nSoit par exemple la variable Y = PCT et la variable X = DAY. On peut se demander si la générosité des pourboires varie en fonction des jours de la semaine (mercredi, jeudi, vendredi ou samedi). On fera toutefois attention au fait que l’échantillon n’est pas très équilibré\n\ntable(don2$DAY)\n\n\nMercredi    Jeudi Vendredi   Samedi \n      62       19       86       74 \n\n\n\n\n6.4.2 Calcul des paramètres principaux\nOn va calculer les paramètres principaux de chacune des quatre sous population à l’aide de la superfonction tapply() dont la syntaxe est la suivante\ntapply(variable à analyser, variable de partition , function)\nLa fonction tapply() s’applique sur les tableaux (data.frame). Il y a des fonctions équvalentes pour les listes, les matrices, etc…\n\nmoy&lt;-tapply(X = don2$PCT, INDEX = don2$DAY, FUN = mean)\nmoy\n\nMercredi    Jeudi Vendredi   Samedi \n16.12756 16.99130 15.11450 15.61781 \n\nect&lt;-tapply(don2$PCT, don2$DAY, sd)\nect\n\nMercredi    Jeudi Vendredi   Samedi \n3.865182 4.766531 4.803544 4.858665 \n\n100*ect/moy\n\nMercredi    Jeudi Vendredi   Samedi \n23.96631 28.05277 31.78104 31.10976 \n\n\n\ntapply(don2$PCT, don2$DAY, summary)\n\n$Mercredi\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  7.296  13.821  15.385  16.128  19.269  26.631 \n\n$Jeudi\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  10.36   13.37   15.56   16.99   19.66   26.35 \n\n$Vendredi\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  3.564  12.373  15.099  15.114  18.767  29.199 \n\n$Samedi\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  5.945  11.737  15.965  15.618  18.494  28.054 \n\n\n\n\n6.4.3 Visualisation\nOn utilise comme précédemment boxplot() :\n\nboxplot(don2$PCT~don2$DAY, col=\"gray80\")\n\n\n\n\nOu bien beanplot() :\n\nlibrary(beanplot)\nbeanplot(don2$PCT~don2$DAY,col = \"gray80\")\n\n\n\n\n\n\n6.4.4 Modélisation simple\nLa solution la plus simple est d’utiliser la fonction lm() que l’on a déjà vu pour la régression.\n\nmonmodel&lt;-lm(don2$PCT~don2$DAY)\nsummary(monmodel)\n\n\nCall:\nlm(formula = don2$PCT ~ don2$DAY)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.5507  -2.7549  -0.1519   3.2335  14.0845 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       16.1276     0.5836  27.634   &lt;2e-16 ***\ndon2$DAYJeudi      0.8637     1.2050   0.717    0.474    \ndon2$DAYVendredi  -1.0131     0.7656  -1.323    0.187    \ndon2$DAYSamedi    -0.5097     0.7912  -0.644    0.520    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.595 on 237 degrees of freedom\nMultiple R-squared:  0.01435,   Adjusted R-squared:  0.001876 \nF-statistic:  1.15 on 3 and 237 DF,  p-value: 0.3295\n\n\nOn peut ensuite appliquer une analyse de variance avec anova() sur le modèle pour mesurer la variance totale et la variance résiduelle ainsi que la significativité de la relation.\n\nanova(monmodel)\n\nAnalysis of Variance Table\n\nResponse: don2$PCT\n           Df Sum Sq Mean Sq F value Pr(&gt;F)\ndon2$DAY    3   72.9  24.293  1.1503 0.3295\nResiduals 237 5004.9  21.117               \n\n\nEt on peut effectuer quelques diagnostics sur les résidus :\n\npar(mfrow = c(2,2))\nplot(monmodel,c(1,2,3,4))\n\n\n\n\n\n\n6.4.5 Modélisation avancée\nD’un point de vue statistique, l’analyse de variance à un facteur fait appel à des modèles et des hhypothèses plus sophistiqués que le modèle de base présenté ici et comporte de nombreux tests. On se reportera donc ave profit aux trois cours en lignes de Claire Della Vedova pour une approche plus poussée\nhttps://statistique-et-logiciel-r.com/anova-a-un-facteur-partie-1/\nhttps://statistique-et-logiciel-r.com/anova-a-un-facteur-partie-2-la-pratique/\nhttps://statistique-et-logiciel-r.com/anova-a-un-facteur-quand-les-hypotheses-ne-sont-pas-satisfaites/"
  },
  {
    "objectID": "13-Anova.html#annexe-les-variables-hybrides",
    "href": "13-Anova.html#annexe-les-variables-hybrides",
    "title": "6  Analyse de variance",
    "section": "6.5 Annexe : les variables hybrides",
    "text": "6.5 Annexe : les variables hybrides\nLe nombre de convives (SIZE) n’est ni une variable quantitative continue, ni une variable qualitative de type catégorielle. On peut donc l’appréhender de deux points de vue différents sur le plan statistique\n\nvariable quantitative discrète : ce qui permet d’utiliser un modèle de régression linéaire.\nvariable qualitative ordinale : ce qui permet d’utiliser un modèle d’analyse de variance.\n\n\n6.5.1 SIZE = quantitative discrète\n\nhist(don$SIZE, breaks=6, col=\"gray80\")\n\n\n\n\n\nmodreg&lt;-lm(don2$PCT~don2$SIZE)\nsummary(modreg)\n\n\nCall:\nlm(formula = don2$PCT ~ don2$SIZE)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12.4591  -2.9738  -0.2625   3.4693  13.2193 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  17.2116     0.8545  20.143   &lt;2e-16 ***\ndon2$SIZE    -0.5944     0.3108  -1.913    0.057 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.574 on 239 degrees of freedom\nMultiple R-squared:  0.01507,   Adjusted R-squared:  0.01095 \nF-statistic: 3.658 on 1 and 239 DF,  p-value: 0.057\n\n\n\nplot(don2$SIZE,don2$PCT, col=\"blue\", pch=19, cex=0.7)\nabline(modreg, col=\"red\")\n\n\n\n\n\n\n6.5.2 SIZE = qualitative ordinale\nOn recode les catégories trop rares …\n\ndon2$SIZE2&lt;-as.factor(don2$SIZE)\nlevels(don2$SIZE2)&lt;-c(\"1-2\",\"1-2\",\"3+\",\"3+\",\"3+\",\"3+\")\nsummary(don2$SIZE2)\n\n1-2  3+ \n157  84 \n\nplot(don2$SIZE2)\n\n\n\n\n\ntapply(don2$PCT, don2$SIZE2, mean)\n\n     1-2       3+ \n16.09466 14.89818 \n\ntapply(don2$PCT, don2$SIZE2, sd)\n\n     1-2       3+ \n4.626275 4.472961 \n\n\n\nbeanplot(don2$PCT~don2$SIZE2)\n\n\n\n\n\nmodvar&lt;-lm(don2$PCT~don2$SIZE2)\nsummary(modvar)\n\n\nCall:\nlm(formula = don2$PCT ~ don2$SIZE2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12.5308  -2.7696  -0.3176   3.4082  13.1553 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   16.0947     0.3650  44.093   &lt;2e-16 ***\ndon2$SIZE23+  -1.1965     0.6183  -1.935   0.0541 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.574 on 239 degrees of freedom\nMultiple R-squared:  0.01543,   Adjusted R-squared:  0.01131 \nF-statistic: 3.745 on 1 and 239 DF,  p-value: 0.05414"
  }
]