[
  {
    "objectID": "index.html#à-propos-de-ce-document",
    "href": "index.html#à-propos-de-ce-document",
    "title": "Introduction à la statistique bivariée avec R",
    "section": "À propos de ce document",
    "text": "À propos de ce document\nCe document est une introduction aux méthodes statistiques d’analyse bivariée et aux représentations graphiques avec le logicielR\nIl est basé sur R version 4.3.1 (2023-06-16).\nCe document est régulièrement corrigé et mis à jour. La version de référence est disponible en ligne à l’adresse :\n\nhttps://github.com/ClaudeGrasland/bivaR2023\n\nLe code source est disponible sur GitHub.\nPour toute suggestion ou correction, il est possible de me contacter par mail"
  },
  {
    "objectID": "index.html#remerciements",
    "href": "index.html#remerciements",
    "title": "Introduction à la statistique bivariée avec R",
    "section": "Remerciements",
    "text": "Remerciements\nCe document est rédigé en quarto à partir du modèle proposé par Julien Barnier dans son Introduction à R et au Tidyverse"
  },
  {
    "objectID": "index.html#licence",
    "href": "index.html#licence",
    "title": "Introduction à la statistique bivariée avec R",
    "section": "Licence",
    "text": "Licence\nCe document est mis à disposition selon les termes de la Licence Creative Commons Attribution - Pas d’Utilisation Commerciale - Partage dans les Mêmes Conditions 4.0 International.\n\n\n\nLicence Creative Commons"
  },
  {
    "objectID": "01-PremierPas.html#opérations-arithmétiques",
    "href": "01-PremierPas.html#opérations-arithmétiques",
    "title": "1  Premier pas",
    "section": "1.1 Opérations arithmétiques",
    "text": "1.1 Opérations arithmétiques\nNous allons commencer par passer quelques commandes arithmétiques simples. Il suffit de les taper dans la console de R pour qu’elles s’executent automatiquement.\n\n8+2\n#&gt; [1] 10\n\n8-2\n#&gt; [1] 6\n\n8*2\n#&gt; [1] 16\n\n8/2\n#&gt; [1] 4\n\n8**2\n#&gt; [1] 64\n\n8**(1/2)\n#&gt; [1] 2.828427\n\nlog(10)\n#&gt; [1] 2.302585\n\nlog10(10)\n#&gt; [1] 1\n\nsqrt(10)\n#&gt; [1] 3.162278\n\nsin(pi)\n#&gt; [1] 0.0000000000000001224647\n\ncos(pi)\n#&gt; [1] -1\n\ntan(pi)\n#&gt; [1] -0.0000000000000001224647"
  },
  {
    "objectID": "01-PremierPas.html#les-objets-de-base-valeur-vecteur-matrice",
    "href": "01-PremierPas.html#les-objets-de-base-valeur-vecteur-matrice",
    "title": "1  Premier pas",
    "section": "1.2 Les objets de base : valeur, vecteur, matrice",
    "text": "1.2 Les objets de base : valeur, vecteur, matrice\nLes objets élémentéires de R apparaissent dans la fenêtre environnement sous la rubrique Values\n\n1.2.1 Eléments\nUn élément est unique et constitue la brique de base de tous les objets suivants. On peut aussi l’interpréter comme un vecteur de longueur 1 ou une matrice de dimension 1x1.\n\nx&lt;-8\ny&lt;-2\n\nx+y\n#&gt; [1] 10\nx*y\n#&gt; [1] 16\nx**y\n#&gt; [1] 64\n\nLes éléments se combinent différemment selon leur type. Par exemple, des éléments de type caractère (character) peuvent être assemblés avec l’instruction paste() ou découpez avec l’instruction substr() :\n\nx&lt;-\"Bonjour\"\ny&lt;- \"tout le monde\"\nz&lt;- \"!\"\npaste(x,y,z)\n#&gt; [1] \"Bonjour tout le monde !\"\nsubstr(x,1,3)\n#&gt; [1] \"Bon\"\n\nQuant aux éléments logiques (logical) nous verrons qu’ils peuvent se combiner avec des opérateurs comme & quii signifie ET ou bien | qui signifie OU.\n\nx&lt;-TRUE\ny&lt;-FALSE\n\nx & y\n#&gt; [1] FALSE\nx | y \n#&gt; [1] TRUE\n\n\n\n1.2.2 vecteurs (vectors)\nUn vecteur est un ensemble d’éléments de même type que l’on a concaténés à l’aide de l’instruction c(). On peut ensuite les aditionner, les multiplier ou les combiner avec des éléments.\n\nx &lt;- c(1,2,4,8,16)\ny &lt;- 4\nx+y\n#&gt; [1]  5  6  8 12 20\nx*y\n#&gt; [1]  4  8 16 32 64\nx**y\n#&gt; [1]     1    16   256  4096 65536\n\nOn remarque dans l’exemple ci-dessus que R n’a pas de problème pour combiner des vecteurs de tailles différentes.\n\n\n1.2.3 Matrices (matrix)\nUne matrice est un ensemble de vecteurs de même longueur et de même type. On peut donc construire une matrice en concaténant des vecteurs verticalement avec cbind()ou horizontalement avec rbind().\n\n\n# deux vecteurs\nx1 &lt;- c(1,2,4,8,16)\nx2 &lt;- c(5,10,15,20,25)\n\n# matrice en colonnes\nm1 &lt;- cbind(x1,x2)\nm1\n#&gt;      x1 x2\n#&gt; [1,]  1  5\n#&gt; [2,]  2 10\n#&gt; [3,]  4 15\n#&gt; [4,]  8 20\n#&gt; [5,] 16 25\n\n# matrice en lignes\nm2 &lt;- rbind(x1,x2)\nm2\n#&gt;    [,1] [,2] [,3] [,4] [,5]\n#&gt; x1    1    2    4    8   16\n#&gt; x2    5   10   15   20   25\n\n# piège !\nm3 &lt;- c(x1,x2)\nm3\n#&gt;  [1]  1  2  4  8 16  5 10 15 20 25\nis.matrix(m3)\n#&gt; [1] FALSE\n\n\n\n\nSi on assemble deux vecteurs à l’aide de la commande c()on obtient un vecteur et pas une matrice."
  },
  {
    "objectID": "01-PremierPas.html#ne-pas-confondre-listes-et-vecteurs",
    "href": "01-PremierPas.html#ne-pas-confondre-listes-et-vecteurs",
    "title": "1  Premier pas",
    "section": "1.3 Ne pas confondre listes et vecteurs !",
    "text": "1.3 Ne pas confondre listes et vecteurs !\nR utilise des types plus complexes d’objets qui lui sont propres et qui sont en général des listes ou des listes de listes.\n\nliste simple\nliste de liste\nlistes de vecteur = data.frame\n…\n\n\n\n\nLes vecteurs regroupent des éléments de même type tandis que les listes regroupent des éléments ou des objets de type quelconque. Le type liste est donc beaucoup plus général, mais aussi plus difficile d’emploi.\n\n\nOn peut comparer une liste à un panier de course dans lequel on mélange des choux, des carottes, des navets, une boîte de douze oeufs, un paquet de croquettes pour chiens, etc…\n\n\n\n\n# Format vecteur\nprenom &lt;- c(\"Ali\", \"Amine\",\n    \"Anne\",\"Marc\",\"Zayneb\")\nsexe &lt;- c(\"H\",\"H\",\"F\",\"H\",\"F\")\nage  &lt;- c(21,22,24,18,25)\n\n\n# Format liste\nAli &lt;- list(\"H\",21)\nAmine &lt;- list(\"F\",22)\nAnne &lt;- list(\"F\",28)\nMarc &lt;- list (\"H\",18)\nZayneb &lt;- list(\"F\",25)\n\n# Ne pas confondre !\nAli &lt;- c(\"H\",21)\nAli\n#&gt; [1] \"H\"  \"21\"\nAli &lt;- list(\"H\",21)\nAli\n#&gt; [[1]]\n#&gt; [1] \"H\"\n#&gt; \n#&gt; [[2]]\n#&gt; [1] 21"
  },
  {
    "objectID": "01-PremierPas.html#attention-aux-types-de-variables",
    "href": "01-PremierPas.html#attention-aux-types-de-variables",
    "title": "1  Premier pas",
    "section": "1.4 Attention aux types de variables …",
    "text": "1.4 Attention aux types de variables …\nChaque valeur, vecteur ou matrice appartient à un seul type de données. Il est important de ne pas les confondre, sous peine d’obtenir des résultats … douteux. On se limitera ici aux principaux types, d’autres étant vus ultérieurement dans l’année :\n\nnumeric : type général (entier, réels, …)\nlogique : type booleen (TRUE/FALSE)\ndate : année, mois, jour,n heure, minutes, secondes, …\ncharacter : texte quelconque\nfactor : variable catégorielle (codage d’enquêtes …)\n\nLa commande str() permet de vérifier le type d’un vecteur (ou d’une matrice) et d’en afficher la dimension.\n\n# Format charactère\nprenom &lt;- c(\"Ali\", \"Amine\",\"Anne\",\n            \"Marc\",\"Zayneb\")\nstr(prenom)\n#&gt;  chr [1:5] \"Ali\" \"Amine\" \"Anne\" \"Marc\" \"Zayneb\"\n\n# Format logique\nlikeR &lt;- c(TRUE,FALSE, TRUE,\n           FALSE, FALSE)\nstr(likeR)\n#&gt;  logi [1:5] TRUE FALSE TRUE FALSE FALSE\n# Format Factor\nsexe &lt;- c(1,1,2,1,2)\nsexe&lt;-as.factor(sexe)\nlevels(sexe) &lt;-c(\"Homme\",\"Femme\")\nstr(sexe)\n#&gt;  Factor w/ 2 levels \"Homme\",\"Femme\": 1 1 2 1 2\n\n# Format numerique\nage  &lt;- c(21,22,24,18,25)\nstr(age)\n#&gt;  num [1:5] 21 22 24 18 25\n\n# Format date\nnais&lt;-c(\"1999-10-28\",\"1998-10-13\",\n \"1996-10-15\",\"2002-02-07\",\"1995-06-18\")\nnais&lt;-as.Date(nais)\nstr(nais)\n#&gt;  Date[1:5], format: \"1999-10-28\" \"1998-10-13\" \"1996-10-15\" \"2002-02-07\" \"1995-06-18\""
  },
  {
    "objectID": "01-PremierPas.html#types-de-tableaux-et-guerres-de-religion.",
    "href": "01-PremierPas.html#types-de-tableaux-et-guerres-de-religion.",
    "title": "1  Premier pas",
    "section": "1.5 Types de tableaux et guerres de religion.",
    "text": "1.5 Types de tableaux et guerres de religion.\nR est un langage qui a beaucouop évolué au cours du temps, suscitant l’apparition de nouveaux types d’objets mieux adapéts à certaines fonctions. Du coup, il existe plusieurs format de tableaux de données, plus ou moins compatibles entre eux.\nOn notera que dans la fenêtre environnement, les tableaux apparaissent dans la sous-fenêtre data et non plus dans la sous-fenêtre values comme c’était le cas pour les éléments, vecteurs ou matrices.\n\n1.5.1 Le type data.frame :\nC’est le type d’origine correspondant à ce qu’on appelle le langage R-Base. Il se présente en pratique comme une liste de vecteurs qui peuvent être de types différents mais qui sont de même longueur.\n\n# Création d'un data.frame\ntab1&lt;-data.frame(prenom,nais,\n                age,sexe,likeR)\nstr(tab1)\n#&gt; 'data.frame':    5 obs. of  5 variables:\n#&gt;  $ prenom: chr  \"Ali\" \"Amine\" \"Anne\" \"Marc\" ...\n#&gt;  $ nais  : Date, format: \"1999-10-28\" \"1998-10-13\" ...\n#&gt;  $ age   : num  21 22 24 18 25\n#&gt;  $ sexe  : Factor w/ 2 levels \"Homme\",\"Femme\": 1 1 2 1 2\n#&gt;  $ likeR : logi  TRUE FALSE TRUE FALSE FALSE\n\n\n\n1.5.2 Le type tibble\nc’est un type créé par Hadley Wickham pour développer la suite de fonctions Tidyverse ou ggplot\n\n# Création d'un tibble\nlibrary(tidyr, quiet=T)\ntab2&lt;-tibble(prenom,nais,\n            age,sexe,likeR)\nstr(tab2)\n#&gt; tibble [5 × 5] (S3: tbl_df/tbl/data.frame)\n#&gt;  $ prenom: chr [1:5] \"Ali\" \"Amine\" \"Anne\" \"Marc\" ...\n#&gt;  $ nais  : Date[1:5], format: \"1999-10-28\" \"1998-10-13\" ...\n#&gt;  $ age   : num [1:5] 21 22 24 18 25\n#&gt;  $ sexe  : Factor w/ 2 levels \"Homme\",\"Femme\": 1 1 2 1 2\n#&gt;  $ likeR : logi [1:5] TRUE FALSE TRUE FALSE FALSE\n\n\n\n1.5.3 Le type data.table\nC’est un type récent créé pour traiter les tableaux de très grande taille à l’aide du package … data.table\n\n\n# Création d'un data.table\nlibrary(data.table, quiet=T)\n#&gt; \n#&gt; Attaching package: 'data.table'\n#&gt; The following objects are masked from 'package:lubridate':\n#&gt; \n#&gt;     hour, isoweek, mday, minute, month, quarter, second, wday, week,\n#&gt;     yday, year\n#&gt; The following objects are masked from 'package:dplyr':\n#&gt; \n#&gt;     between, first, last\n#&gt; The following object is masked from 'package:purrr':\n#&gt; \n#&gt;     transpose\ntab3&lt;-data.table(prenom,nais,\n                age,sexe,likeR)\nstr(tab3)\n#&gt; Classes 'data.table' and 'data.frame':   5 obs. of  5 variables:\n#&gt;  $ prenom: chr  \"Ali\" \"Amine\" \"Anne\" \"Marc\" ...\n#&gt;  $ nais  : Date, format: \"1999-10-28\" \"1998-10-13\" ...\n#&gt;  $ age   : num  21 22 24 18 25\n#&gt;  $ sexe  : Factor w/ 2 levels \"Homme\",\"Femme\": 1 1 2 1 2\n#&gt;  $ likeR : logi  TRUE FALSE TRUE FALSE FALSE\n#&gt;  - attr(*, \".internal.selfref\")=&lt;externalptr&gt;"
  },
  {
    "objectID": "01-PremierPas.html#en-résumé",
    "href": "01-PremierPas.html#en-résumé",
    "title": "1  Premier pas",
    "section": "1.6 En résumé",
    "text": "1.6 En résumé\n\n\n\nR est un langage de programmation multifonction qui évolue depuis maintenant plus de 30 ans et auquel s’ajoutent continuellement de nouveaux packages. A la différence de SPSS, il n’est pas spécialisé uniquement en statistique, même si le coeur du logiciel est bien centré sur la statistique. Pour progresser rapidement en R il est indispensable :\n\n\n\nde prêter une grande attention aux types de variables et de tableaux.\n\n\nde ne pas chercher à utiliser trop vite de nouveaux packages tant que l’on n’a pas acquis une pratique suffisante du R-Base.\n\n\nde consulter la documentation et les forums de discussion en cas de difficulté."
  },
  {
    "objectID": "01-PremierPas.html#exercices",
    "href": "01-PremierPas.html#exercices",
    "title": "1  Premier pas",
    "section": "1.7 Exercices",
    "text": "1.7 Exercices\nExercice 1\nConstruire le vecteur x suivant :\n\n#&gt; [1] \"Paris\"    \"Londres\"  \"Tokyo\"    \"New York\"\n\n\n\nx &lt;- c(\"Paris\", \"Londres\",\"Tokyo\",\"New York\")\n\n\nConstruire le vecteur y suivant :\n\n#&gt; [1] \"France\"      \"Royaume-Uni\" \"Japon\"       \"USA\"\n\n\n\ny &lt;- c(\"France\", \"Royaume-Uni\",\"Japon\",\"USA\")\n\n\nConstruire le vecteur z suivant :\n\n#&gt; [1] 10.2 14.6 42.8 23.9\n\n\n\nz &lt;- c(10.2, 14.6,42.8,23.9)\n\n\nConstruire la matrice m1\n\n#&gt;   [,1]     [,2]          [,3]    [,4]      \n#&gt; x \"Paris\"  \"Londres\"     \"Tokyo\" \"New York\"\n#&gt; y \"France\" \"Royaume-Uni\" \"Japon\" \"USA\"\n\n\n\nm1&lt;-rbind(x,y)\n\n\nConstruire le data.frame df\n\n#&gt;             y        x    z\n#&gt; 1      France    Paris 10.2\n#&gt; 2 Royaume-Uni  Londres 14.6\n#&gt; 3       Japon    Tokyo 42.8\n#&gt; 4         USA New York 23.9\n\n\n\ndf&lt;-data.frame(y,x,z)\n\n\nExercice 2 (d’après J.Barnier)\nOn a demandé à 4 ménages le revenu des deux conjoints, et le nombre de personnes du ménage :\n\nconjoint1 &lt;- c(1200, 1180, 1750, 2100)\nconjoint2 &lt;- c(1450, 1870, 1690, 0)\nnb_personnes &lt;- c(4, 2, 3, 2)\n\nCalculer le revenu total de chaque ménage, puis diviser par le nombre de personnes pour obtenir le revenu par personne de chaque ménage.\n\n\nrevenu_total &lt;- conjoint1 + conjoint2\nrevenu_total / nb_personnes"
  },
  {
    "objectID": "02-OfficeKiller.html#rstudio-et-les-projets-r",
    "href": "02-OfficeKiller.html#rstudio-et-les-projets-r",
    "title": "2  Office Killer",
    "section": "2.1 Rstudio et les projets R",
    "text": "2.1 Rstudio et les projets R\n\n\nAu commencement, les dieux de la statistique créèrent le langage R.\nMais l’interface était vide et vague,\nles ténèbres couvraient les lignes de code\nR-Studio dit : Que le projet soit et le projet fut.\n\n\nSi l’on veut s’épargner bien des désagréments dans l’apprentissage de R, il faut prendre dès le départ de bonnes habitudes. Parmi celles-ci, l’une des plus importantes est le fait d’inscrire toujours son travail dans le cadre d’un projet R c’est-à-dire - en simplifiant beaucoup - un répertoire de travail contenant l’ensemble des données, programmes, résultats… que l’on pourra par la suite compresser, archiver et transmettre à quelqu’un d’autre.\n\n2.1.1 Lancement de R studio\nSauf à être complètement masochiste, on n’utilise jamais R directement mais on lance d’abord l’interface R-Studio qui facilite conisdérablement l’ensemble des opérations et offre une gamme considérable de services. Il ne faut toutefois pas confondre les deux et il serait par exemple ridicule d’indiquer sur un CV en vue d’un emploi de statisticien que l’on sait utiliser R-studio en oubliant de préciser que l’on maîtrise R.\n\n\n2.1.2 Création d’un projet\nPour créer un projet on utilise le menus déroulant File/new project/ … et on définit un dossier de notre ordinateur (existant ou à créer) qui contiendra le projet. Une fois l’opération effectuée, on pourra constater que ce dossier contient un fichier xxx.Rproj ou xxx est en principe le nom du dossier dans lequel vous avez stocké le projet.\nCe fichier contient toute une série d’informations dont nous ne parlerons pas dans ce cours d’initiation mais qui, pour faire simple, définissent un ensemble de réglages du logiciel et de préférences de l’utilisateur.\nSi vous fermez Rstudio (faites-le !) il vous suffira pour reprendre votre travail là où vous vous étiez arrêté :\n\nde lancer R-studio et de cliquer sur File/open project/… suivi du nom du fichier xxx.Rproj\nou plus simplement encore de double cliquer sur le fichier xxx.Rproj ce qui lancera automatiquement Rstudio\n\nLe dossier contenant votre projet R peut être organisé à votre convenance. Certains mettent tout les fichier pêle-mêle dans le dossier. D’autres préfèrent créer des sous-dossiers contenant des données, des programmes, des résultats, des figures. Vous déciderez à l’usage de ce qui vous convient le mieux, mais le point important est que tout ce qui entre ou sort de vos programmes R doit être de préférence stocké dans le répertoire du projet."
  },
  {
    "objectID": "02-OfficeKiller.html#programme-r-excel-killer",
    "href": "02-OfficeKiller.html#programme-r-excel-killer",
    "title": "2  Office Killer",
    "section": "2.2 Programme R : Excel killer ?",
    "text": "2.2 Programme R : Excel killer ?\n\n\nC’est pourquoi tu quittera Word et Excel, et t’attachera à R studio,\net vous deviendrez une seule chair.\n\n\nLa fonction initiale d’un langage de programmation comme R est … de créer des programmes c’est-à-dire des ensembles d’instruction permettant d’accomplir une tâche à l’intérieur d’une chaîne de production. Dans le cas d’un logiciel spécialisé dans l’analyse statistique, il s’agira donc de partir de données (statistiques, géographiques, textuelles, …) pour aboutir à des résultats prenant la forme de tableaux, cartes ou graphiques. Il ne s’agit donc en somme que d’une étape du travail de recherche où le principal avantage de R est d’automatiser une tâche et de faciliter sa reproduction ultérieure avec en arrière plan un objectif de productivité puisque l’ordinateur réalise en quelques millisecondes des tâches qui prendraient des heures avec un logiciel click-bouton de type Excel.\n\n\n\n\n\nPrenons un exemple simple de problème facile à résoudre avec R mais plus compliqué avec des logiciels click-boutons. Il s’agit d’un exemple pédagogique tiré d’un très vieux cours d’analyse spatiale portant sur les semis de point et les localisations optimales.\nOn considère une carte papier permettant de localiser 5 station services à l’intérieur d’une ville à plan en damier. Chaque station livre chacune la même quantité de carburant par semaine aux clients. On souhaite répondre aux questions suivantes :\n\nComment saisir les données dans une fichier numérique ?\nComment reproduire la carte papier sous forme d’un graphique ?\nComment calculer la dsitance à vol d’oiseau entre toutes les stations ?\nComment calculer la dsitance routière entre toutes les stations ?\nOù localiser un dépôt de carburant permettant d’alimenter les cinq stations en minimisant la distance moyenne de livraison (critère d’efficacite)\nOù localiser une caserne de pompier qui doit pouvoir intervenir rapidement sur toute les stations et qui doit minimiser la distance maximale à la station la plus éloignée (critère d’équité).\nComment visualiser ces deux localisations sur la carte des stations ?\nComment reproduire ces tâches rapidement s’il y a des ajouts ou suppressions de stations\n\n\n\n\n\n\nOn constitue deux équipes d’étudiants, certains utilisant un programme R et d’autres Excel. On se propose de voir qui ira le plus vite sur chacune des 8 tâches proposées.\n\n2.2.1 Round 1. Saisie des données et affichage du tableau\nOn crée un programme R avec File/New File/R Script puis on l’enregistre avec File/Save/ … suivi du nom du programme.\n\n# Saisie des variables\nCODE &lt;- c(\"A\",\"B\",\"C\",\"D\",\"E\")\nX &lt;- c(10,20,40,50,180)\nY &lt;- c(40,60,40,60,50)\n\n# Regroupement dans un tableau\ncoo &lt;- data.frame(X,Y)\n\n# Ajout du nom des lignes\nrow.names(coo) &lt;- CODE\n\n# Affichage du tableau\ncoo\n#&gt;     X  Y\n#&gt; A  10 40\n#&gt; B  20 60\n#&gt; C  40 40\n#&gt; D  50 60\n#&gt; E 180 50\n\nNormalement, les étudiants qui utilisent un tableur ont du aller plus vite et Excel mène sur R par 1-0\n\n\n2.2.2 Round 2. Affichage de la carte\nVous devez essayez de reproduire l’image correspondant au problème posé\n\nplot(X,Y, \n     col=\"red\", \n     pch=20, \n     xlim=c(0,180),\n     ylim=c(0,90),\n     asp = 1)\ntext(X,Y,\n     labels = CODE, \n     pos = 2)\n\n\n\n\nLa création d’un graphique est à première vue plus facile avec un logiciel click-bouton. L’avantage est très clairement pour Excel qui mène désormais 2 à 0.\n\n\n2.2.3 Round 3. Calcul de la station la plus accessible à vol d’oiseau (distance euclidienne)\nVous devez calculer une matrice de distance euclidienne entre toutes les stations et trouver la plus accessible.\n\n\n# calcul la matrice de distance euclidienne\nmat&lt;-dist(coo, upper = T, method = \"euclidean\")\nmat\n#&gt;           A         B         C         D         E\n#&gt; A            22.36068  30.00000  44.72136 170.29386\n#&gt; B  22.36068            28.28427  30.00000 160.31220\n#&gt; C  30.00000  28.28427            22.36068 140.35669\n#&gt; D  44.72136  30.00000  22.36068           130.38405\n#&gt; E 170.29386 160.31220 140.35669 130.38405\n\n# distance moyenne\napply(as.matrix(mat),1,mean)\n#&gt;         A         B         C         D         E \n#&gt;  53.47518  48.19143  44.20033  45.49322 120.26936\n\nLà, je parie que les utilisateurs d’Excel ont eu un peu plus de mal … En tous les cas, Excel ne mèneplus que par 2 à 1\n\n\n2.2.4 Round 4. Calcul de la station la plus accessible par la route (distance de Manhattan)\nVous devez calculer une matrice de distance de Manhattan entre toutes les stations et trouver la plus accessible.\n\n\n# calcul la matrice de distance de Manhattan\nmat&lt;-dist(coo,upper = T, method = \"manhattan\")\nmat\n#&gt;     A   B   C   D   E\n#&gt; A      30  30  60 180\n#&gt; B  30      40  30 170\n#&gt; C  30  40      30 150\n#&gt; D  60  30  30     140\n#&gt; E 180 170 150 140\n\n# distance moyenne de Manhattan\napply(as.matrix(mat),1,mean)\n#&gt;   A   B   C   D   E \n#&gt;  60  54  50  52 128\n\nJe reconnais que c’est unpeu facile, mais à nouveau R l’emporte ce qui fait désormais match nul 2-2\n\n\n2.2.5 Round 5. Localisation du dépôt de carburant\nDans le cas particulier de la distance de Manhattan, le calcul du point le plus proche de tous les autres s’obtient facilement en calculant le point médian dont les coordonnées correspondent à la médiane de X et la médiane de Y.\n\nmedX &lt;- median(X)\nmedX\n#&gt; [1] 40\nmedY &lt;- median(Y)\nmedY\n#&gt; [1] 50\n\nA priori, le calcul est aussi facile dans R et dans Excel : match nul 3-3\n\n\n2.2.6 Round 6. Localisation de la caserne de pompiers\nDans le cas particulier de la distance de Manhattan, le calcul du point minimisant la distance maximale s’obtient en trouvant le centre du diamètre minimal en X et en Y. Il s’agit de la localisation la plus équitable où le plus défavorisé est le moins défavorisé possible.\n\nequX &lt;- (max(X)+min(X))/2\nequX\n#&gt; [1] 95\nequY &lt;- (max(Y)+min(Y))/2\nequY\n#&gt; [1] 50\n\nA priori, le calcul est toujours aussi facile dans R et dans Excel : match nul 4-4\n\n\n2.2.7 Round 7. Visualisation des deux points sur la carte\nOn va placer en bleu le point médian et en vert le point le plus équitable. Dans le cas de R on peut recopier les lignes de code du graphique du round n°2 ce qui gagne désormais du temps :\n\n# Programme antérieur\nplot(X,Y, \n     col=\"red\", \n     pch=20, \n     xlim=c(0,180),\n     ylim=c(0,90),\n     asp = 1)\ntext(X,Y,\n     labels = CODE, \n     pos = 2)\n\n# Ajout du dépôt de carburant\npoints(medX, medY, col=\"blue\", pch=3)\ntext(medX,medY, \"dépot\",pos=1)\n\n# Ajout du point médian\npoints(equX, equY, col=\"green\", pch=3)\ntext(equX,equY, \"caserne\",pos=1)\n\n\n\n\nLe résultat du match est incertain mais R n’est plus désavantagé puisqu’on peut recycler les lignes de code précédentes pour le graphique de base. Disons 5-5 même s’il y a de fortes chances que R l’emporte.\n\n\n2.2.8 Dernier round. Refaire toute l’analyse avec une station de plus\nDeux stations F(100,20) et G(150,30) ont été ajoutées. Il faut refaire la carte finale. Cela ne pose aucun problème dans R puisqu’il suffit de modifier l’entrée des données et récupérer des bouts de programme\n\n# (1) Saisie des variables\nCODE &lt;- c(\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\")\nX &lt;- c(10,20,40,50,180,100,150)\nY &lt;- c(40,60,40,60,50,20,30)\ncoo &lt;- data.frame(X,Y)\nrow.names(coo) &lt;- CODE\n\n\n# (2) calcul des points centraux\nmedX &lt;- median(X)\nmedY &lt;- median(Y)\nequX &lt;- (max(X)+min(X))/2\nequY &lt;- (max(Y)+min(Y))/2\n\n\n# (3) Graphique\nplot(X,Y, \n     col=\"red\", \n     pch=20, \n     xlim=c(0,180),\n     ylim=c(0,90),\n     asp = 1)\ntext(X,Y,\n     labels = CODE, \n     pos = 2)\n\n# Ajout du dépôt de carburant\npoints(medX, medY, col=\"blue\", pch=3)\ntext(medX,medY, \"Dépôt\",pos=1)\n\n# Ajout du point médian\npoints(equX, equY, col=\"green\", pch=3)\ntext(equX,equY, \"Caserne\",pos=1)\n\n\n\n\nExcel n’a aucune chance d’aller plus vite et R remporte le match par KO !"
  },
  {
    "objectID": "02-OfficeKiller.html#document-rmd-word-killer",
    "href": "02-OfficeKiller.html#document-rmd-word-killer",
    "title": "2  Office Killer",
    "section": "2.3 Document Rmd : Word killer ?",
    "text": "2.3 Document Rmd : Word killer ?\n\n\nR-Studio dit : « Faisons une interface de rédaction adaptée à notre travail,\nQue l’utilisateur puissent y insérer les tableaux, les graphiques, les cartes, les références bibliographiques, et tous les écrits qui les commentent. »\n\n\nNous venons de voir comment une bonne pratique de R peut conduire progressivement à abandonner l’usage des tableurs (Excel, Open Office) sauf peut-être pour l’étape de saisie des données. Dès lors qu’il s’agit de réaliser des graphiques ou des calculs statistiques complexes, la rédaction d’un programme se révèle beaucoup plus intéressante même si elle impose un coût initial d’apprentissage.\nMais une bonne pratique de R ou plus précisément des documents R markdown peut vous conduire beaucoup plus loin et vous amener à abandonner également votre logiciel de traitement de texte (Word) et votre outil de présentation (Power Point). Le coût d’apprentissage est naturellement un peu plus élevé mais les bénéfices sont à la mesure de l’investissement.\nComme le montre la figure ci-dessous, un document R markdown est en quelques sorte un mélange entre des lignes de code R qui executent des tâches et des lignes de texte où sont expliqués les calculs et commentés les résultats obtenus. En d’autres termes, un document R markdown vous permet de rédiger un article de recherche complet, une présentation à une conférence, un syllabus de cours, dans un seul environnement logiciel (R studio).\nNul besoin de ciseau et de colle pour aller chercher tel tableau ici, tel figure là-bas ou telle carte ailleurs. Tous ces éléments sont intégrs au fur et à mesure de la rédaction ce qui facilite considérablement la concentration. Et surtout - on l’a déjà vu pour le programme R - le document peut facilement être reproduit ou mise à jour sans être obligé de réplique des dizaines de click de souris.\n\n\n\n\n\nNous allons illustrer l’usage de R markdown en rédigeant une courte note sur la distribution de la population et de certains commerces et services à Rennes. L’exemple est repris du Manuel d’analyse spatiale publié par l’INSEE en 2018 et plus précisement de son chapitre 4. Les configurations de points\nComme nous avons pris la perspective de n’employer aucun package R au cours de cette formation initiale, les données ont été légèrement modifiées, notamment pour le tracé de la carte des contours de la ville de Rennes.\n\n2.3.1 Chargement des données\nNous disposons de trois fichiers qui comportent chacun des coordonnées de localisation utilisant la même projection Lambert et que l’on pourra de ce fait superposer. Après les avoir chargés et décrits, on en propose une première visualisation à l’aide des fonctions graphiques de base de R.\n\n\n2.3.2 Contour de Rennes\nOn charge le fichier avec read.table() puis on affiche ses premières lignes avec head()et on regarde sa taille avec dim()\n\nmap &lt;- read.table(file = \"resources/data/rennes/map.csv\",\n                  header = T,\n                  sep = \";\")\nhead(map,2)\n#&gt;          x       y\n#&gt; 1 346382.1 6786334\n#&gt; 2 346460.0 6786704\ndim(map)\n#&gt; [1] 37  2\n\nOn affiche le contour avec les instructions plot() et lines(). On doit impérativement ajouter le paramètre asp = 1 dans plot() pour imposer une échelle identique sur l’axe vertical et l’axe horizontal.\n\nplot(map$x,map$y, col=\"red\", asp = 1)\nlines(map$x,map$y, col=\"blue\")\n\n\n\n\n\n\n2.3.3 Distribution de la population\nOn charge le fichier de population de la même manière et on constate qu’il comporte une troisième colonne indiquant la population localisée en chaque point. En fait, il s’agit d’une grille de population qui localise les habitants sur une maille de ??? m\n\npop &lt;- read.table(file = \"resources/data/rennes/popu.csv\",\n                  header = T,\n                  sep = \";\")\nhead(pop,2)\n#&gt;          x       y pop\n#&gt; 1 346202.1 6790631  20\n#&gt; 2 346203.4 6792843   5\ndim(pop)\n#&gt; [1] 24916     3\n\nOn procède à une première cartographie qui ne tient pas compte de l’effectif de population mais indique juste les cases occupées et inoccupées, ce qui permet de donner une vision générale de l’occuparion du sol et du peuplement de Rennes et de l’espace environnant.\n\nplot(pop$x,pop$y, col=\"red\", asp = 1,pch=22, cex=0.01)\nlines(map$x,map$y, col=\"black\")\n\n\n\n\n\n\n2.3.4 Distribution des équipements\nL’INSEE a extrait du fichier de la Base Publique des Equipements quatre types de localisations correspondant aux écoles, aux médecins, aux pharmacies et aux commerces de vêtements. On notera l’ajout du paramètre encoding=“UTF-8” qui permet de lire sans erreur les caractères accentués et d’éviter par exemple que “Vêtements” devienne “VÃªtements”.\n\nbpe &lt;- read.table(file = \"resources/data/rennes/bpe.csv\",\n                  header = T,\n                  sep = \";\",\n                  encoding=\"UTF-8\")\nhead(bpe,2)\n#&gt;            x       y    equ\n#&gt; 286 349156.2 6790525 Ecoles\n#&gt; 287 351800.4 6786774 Ecoles\ndim(bpe)\n#&gt; [1] 767   3\n\nOn utilise l’instruction table()pour dénombrer l’effectif de chaque équipement :\n\ntable(bpe$equ)\n#&gt; \n#&gt;     Ecoles   Médecins Pharmacies  Vêtements \n#&gt;         59        268         70        370\n\nPuis on visualise après avoir attribué une couleur à chaque équipement. On crée pour cela une nouvelle variable :\n\nbpe$couleur&lt;-as.factor(bpe$equ)\nlevels(bpe$couleur)\n#&gt; [1] \"Ecoles\"     \"Médecins\"   \"Pharmacies\" \"Vêtements\"\nlevels(bpe$couleur)&lt;-c(\"blue\",\"green\",\"orange\",\"red\")\nbpe$couleur&lt;-as.character(bpe$couleur)\ntable(bpe$couleur)\n#&gt; \n#&gt;   blue  green orange    red \n#&gt;     59    268     70    370\n\n\n\n2.3.5 Synthèse\nOn peut désormais assembler nos trois couches :\n\nplot(pop$x,pop$y, col=\"gray\", asp = 1,pch=22, cex=0.01)\nlines(map$x,map$y, col=\"black\")\npoints(bpe$x,bpe$y,bg=bpe$couleur, pch=21, cex=0.8)\n\n\n\n\nIl est facile de procéder à un zoom en ajoutant des paramètres xlim et ylim dans la fonction plot() qui précise l’espace d’étude.\n\nplot(pop$x,\n     pop$y, \n     col=\"gray\", \n     asp = 1,\n     pch=22, \n     cex=0.1,\n     xlim = c(351000,353000),\n     ylim = c(6788500,6790500))\n\nlines(map$x,\n      map$y, \n      col=\"black\")\n\npoints(bpe$x,\n       bpe$y,\n       bg=bpe$couleur, \n       pch=21, \n       cex=0.8)\n\n\n\n\nOK, notre carte n’a pas de légende (c’est possible mais vraiment compliqué en R-Base) mais on appréciera le fait d’avoir pu la réaliser en ne se servant que de quelques fonctions élémentaires de R comme"
  },
  {
    "objectID": "02-OfficeKiller.html#diapos-rmd-power-point-killer",
    "href": "02-OfficeKiller.html#diapos-rmd-power-point-killer",
    "title": "2  Office Killer",
    "section": "2.4 Diapos Rmd : Power Point killer",
    "text": "2.4 Diapos Rmd : Power Point killer\nLorsque l’on crée un fichier Markdown, on peut décider qu’il ne s’agit pas d’un document mais d’une présentation et opter pour l’un des deux modes par défaut appelés slidy et ioslides.\n\n\n\n\n\nOn peut ensuite créer un diaporama en donnant un titre général et en séparant chaque diapo par un titre de niveau 2 correspondant à des lignes débutant par ## comme dans l’exemple ci-dessous :\n\n\n\n\n\nIl ne reste plus qu’à compiler le programme avec l’icône Knit (pelotte de laine) pour générer un document .html en forme de dipositives."
  },
  {
    "objectID": "02-OfficeKiller.html#en-résumé",
    "href": "02-OfficeKiller.html#en-résumé",
    "title": "2  Office Killer",
    "section": "2.5 En résumé",
    "text": "2.5 En résumé\n\n\n\nR est un Excel killer mais aussi un Word killer voire un Power point killer… Adopter R peut nuire gravement à vos habitudes antérieures de travail."
  },
  {
    "objectID": "03-Base.html#tableaux",
    "href": "03-Base.html#tableaux",
    "title": "3  R-Base",
    "section": "3.1 Tableaux",
    "text": "3.1 Tableaux\n\n3.1.1 Importation\n\n3.1.1.1 Localisation des fichiers\n\nLa commande getwd() permet de connaître la position du répertoire courant. Si vous avez ouvert un projet (ce qui est vivement recommandé) la localisation est l’emplacement du fichier .Rproj.\n\n\ngetwd() \n#&gt; [1] \"/Users/claudegrasland1/git/bivar2023\"\n\n\nLa commande list.files() permet d’examiner le contenu du répertoire courant\n\n\nlist.files()\n#&gt;  [1] \"_extensions\"           \"_freeze\"               \"_quarto.yml\"          \n#&gt;  [4] \"_setup.qmd\"            \"01-PremierPas.html\"    \"01-PremierPas.qmd\"    \n#&gt;  [7] \"02-OfficeKiller_files\" \"02-OfficeKiller.html\"  \"02-OfficeKiller.qmd\"  \n#&gt; [10] \"03-Base_files\"         \"03-Base.qmd\"           \"03-Base.rmarkdown\"    \n#&gt; [13] \"11-Corrélation.qmd\"    \"12-Régression.qmd\"     \"13-Anova.qmd\"         \n#&gt; [16] \"21-Tabcont.qmd\"        \"bivar2023.Rproj\"       \"css\"                  \n#&gt; [19] \"DESCRIPTION\"           \"docs\"                  \"index.html\"           \n#&gt; [22] \"index.pdf\"             \"index.qmd\"             \"js\"                   \n#&gt; [25] \"latex\"                 \"LICENSE\"               \"README.md\"            \n#&gt; [28] \"resources\"             \"site_libs\"             \"XX-ressources.qmd\"\n\n\n\n3.1.1.2 Chargement d’un fichier texte\n\nAvec la souris\n\nCliquer sur les menus déroulants File/Import Dataset/From text (base) puis suivre le menu\n\n\n\n\n\n\nAvec des lignes de code\n\nOn utilise par exemple la fonction read.table() en précisant les paramètres utiles :\n\neuro1988 &lt;- read.table(file = \"resources/data/europe88/euro1988.csv\", # nom du fichier et chemin d'accès\n                  sep = \";\",                     # séparateur (ici, des points-virgule)\n                  header = TRUE,                 # ligne d'en-tête avec le nom des variables\n                  encoding=\"UTF-8\")              # encodage adapté au français\n\n\n\n3.1.1.3 Dimensions d’un tableau\n\nLa fonction dim() fournit les dimensions d’un tableau\n\n\ndim(euro1988)\n#&gt; [1] 25 15\n\n\nLa fonction class() fournit le type d’un tableau\n\n\nclass(euro1988)\n#&gt; [1] \"data.frame\"\n\n\n\n3.1.1.4 Visualisation du contenu d’un tableau\n\nPremières lignes avec head()\n\n\nhead(euro1988)         # Affiche par défaut les 6 premières lignes\n#&gt;   PAYS BLOC   PNB  TMI ESP URB NAT MOR FEC JEU VIE SUP  POP       X       Y\n#&gt; 1  ALB  Soc   600 43.0  71  34  27   6 3.3  35   5  29  3.1 4825115 1684833\n#&gt; 2  AUT  Cap 10000 10.3  75  55  12  12 1.4  18  14  84  7.6 4299715 2335579\n#&gt; 3  BEL  Cap  9200  9.7  75  95  12  11 1.5  19  14  31  9.9 3636312 2667243\n#&gt; 4  BGR  Soc  2000 14.5  72  65  13  11 2.0  21  11 111  9.0 5206070 1930219\n#&gt; 5  CHE  Cap 17800  6.8  77  61  12   9 1.5  17  14  41  6.6 3869378 2243130\n#&gt; 6  CSK  Soc  3200 13.9  71  74  14  12 2.0  24  11 128 15.6 4487005 2540281\n\n\nDernières lignes avec tail()\n\n\ntail(euro1988,2)         # Affiche les 2 dernières lignes\n#&gt;    PAYS BLOC   PNB  TMI ESP URB NAT MOR FEC JEU VIE SUP  POP       X       Y\n#&gt; 24  SWE  Cap 13200  5.9  77  83  12  11 1.8  18  18 450  8.4 4321587 3961396\n#&gt; 25  YUG  Soc  2300 27.1  70  47  15   8 2.1  24   8 256 23.6 4686147 1996737\n\n\n\n3.1.1.5 Verification des variables\n\nVérifie le type avec str()\n\n\nstr(euro1988)\n#&gt; 'data.frame':    25 obs. of  15 variables:\n#&gt;  $ PAYS: chr  \"ALB\" \"AUT\" \"BEL\" \"BGR\" ...\n#&gt;  $ BLOC: chr  \"Soc\" \"Cap\" \"Cap\" \"Soc\" ...\n#&gt;  $ PNB : int  600 10000 9200 2000 17800 3200 3700 12000 12600 4800 ...\n#&gt;  $ TMI : num  43 10.3 9.7 14.5 6.8 13.9 9.2 8.6 8.4 9 ...\n#&gt;  $ ESP : int  71 75 75 72 77 71 72 75 75 76 ...\n#&gt;  $ URB : int  34 55 95 65 61 74 77 94 84 91 ...\n#&gt;  $ NAT : int  27 12 12 13 12 14 13 10 11 12 ...\n#&gt;  $ MOR : int  6 12 11 11 9 12 13 11 11 8 ...\n#&gt;  $ FEC : num  3.3 1.4 1.5 2 1.5 2 1.7 1.4 1.5 1.7 ...\n#&gt;  $ JEU : int  35 18 19 21 17 24 19 15 18 23 ...\n#&gt;  $ VIE : int  5 14 14 11 14 11 14 15 15 12 ...\n#&gt;  $ SUP : int  29 84 31 111 41 128 108 248 43 505 ...\n#&gt;  $ POP : num  3.1 7.6 9.9 9 6.6 15.6 16.6 61.2 5.1 39 ...\n#&gt;  $ X   : num  4825115 4299715 3636312 5206070 3869378 ...\n#&gt;  $ Y   : num  1684833 2335579 2667243 1930219 2243130 ...\n\n\nRecode avec les fonctions as.xxx()\n\n\neuro1988$BLOC&lt;-as.factor(euro1988$PAYS)\nstr(euro1988)\n#&gt; 'data.frame':    25 obs. of  15 variables:\n#&gt;  $ PAYS: chr  \"ALB\" \"AUT\" \"BEL\" \"BGR\" ...\n#&gt;  $ BLOC: Factor w/ 25 levels \"ALB\",\"AUT\",\"BEL\",..: 1 2 3 4 5 6 7 8 9 10 ...\n#&gt;  $ PNB : int  600 10000 9200 2000 17800 3200 3700 12000 12600 4800 ...\n#&gt;  $ TMI : num  43 10.3 9.7 14.5 6.8 13.9 9.2 8.6 8.4 9 ...\n#&gt;  $ ESP : int  71 75 75 72 77 71 72 75 75 76 ...\n#&gt;  $ URB : int  34 55 95 65 61 74 77 94 84 91 ...\n#&gt;  $ NAT : int  27 12 12 13 12 14 13 10 11 12 ...\n#&gt;  $ MOR : int  6 12 11 11 9 12 13 11 11 8 ...\n#&gt;  $ FEC : num  3.3 1.4 1.5 2 1.5 2 1.7 1.4 1.5 1.7 ...\n#&gt;  $ JEU : int  35 18 19 21 17 24 19 15 18 23 ...\n#&gt;  $ VIE : int  5 14 14 11 14 11 14 15 15 12 ...\n#&gt;  $ SUP : int  29 84 31 111 41 128 108 248 43 505 ...\n#&gt;  $ POP : num  3.1 7.6 9.9 9 6.6 15.6 16.6 61.2 5.1 39 ...\n#&gt;  $ X   : num  4825115 4299715 3636312 5206070 3869378 ...\n#&gt;  $ Y   : num  1684833 2335579 2667243 1930219 2243130 ...\n\n\n\n3.1.1.6 Résume du tableau\nLa fonction summary() donne un aperçu général des variables\n\nsummary(euro1988)\n#&gt;      PAYS                BLOC         PNB             TMI       \n#&gt;  Length:25          ALB    : 1   Min.   :  600   Min.   : 5.80  \n#&gt;  Class :character   AUT    : 1   1st Qu.: 2300   1st Qu.: 8.50  \n#&gt;  Mode  :character   BEL    : 1   Median : 8600   Median : 9.70  \n#&gt;                     BGR    : 1   Mean   : 7580   Mean   :12.99  \n#&gt;                     CHE    : 1   3rd Qu.:12000   3rd Qu.:14.50  \n#&gt;                     CSK    : 1   Max.   :17800   Max.   :43.00  \n#&gt;                     (Other):19                                  \n#&gt;       ESP             URB             NAT            MOR             FEC       \n#&gt;  Min.   :70.00   Min.   :30.00   Min.   :10.0   Min.   : 6.00   Min.   :1.400  \n#&gt;  1st Qu.:72.00   1st Qu.:58.00   1st Qu.:12.0   1st Qu.: 9.00   1st Qu.:1.500  \n#&gt;  Median :75.00   Median :71.00   Median :12.0   Median :11.00   Median :1.700  \n#&gt;  Mean   :73.72   Mean   :68.44   Mean   :13.4   Mean   :10.36   Mean   :1.816  \n#&gt;  3rd Qu.:75.00   3rd Qu.:83.00   3rd Qu.:14.0   3rd Qu.:11.00   3rd Qu.:2.000  \n#&gt;  Max.   :77.00   Max.   :95.00   Max.   :27.0   Max.   :14.00   Max.   :3.300  \n#&gt;                                                                                \n#&gt;       JEU             VIE             SUP             POP       \n#&gt;  Min.   :15.00   Min.   : 5.00   Min.   :  3.0   Min.   : 0.40  \n#&gt;  1st Qu.:19.00   1st Qu.:11.00   1st Qu.: 70.0   1st Qu.: 6.60  \n#&gt;  Median :19.00   Median :13.00   Median :128.0   Median :10.30  \n#&gt;  Mean   :21.16   Mean   :12.52   Mean   :190.7   Mean   :19.83  \n#&gt;  3rd Qu.:23.00   3rd Qu.:14.00   3rd Qu.:301.0   3rd Qu.:23.60  \n#&gt;  Max.   :35.00   Max.   :18.00   Max.   :551.0   Max.   :61.20  \n#&gt;                                                                 \n#&gt;        X                 Y          \n#&gt;  Min.   :2498763   Min.   :1535337  \n#&gt;  1st Qu.:3713871   1st Qu.:1996737  \n#&gt;  Median :4166231   Median :2540281  \n#&gt;  Mean   :4091984   Mean   :2572739  \n#&gt;  3rd Qu.:4686147   3rd Qu.:2851709  \n#&gt;  Max.   :5206070   Max.   :4230412  \n#&gt; \n\n\n\n\n3.1.2 Transformations\n\n3.1.2.1 Copie intégrale\nElle s’effectue avec l’opérateur &lt;-\n\ntab&lt;-euro1988\ndim(tab)\n#&gt; [1] 25 15\nhead(tab,2)\n#&gt;   PAYS BLOC   PNB  TMI ESP URB NAT MOR FEC JEU VIE SUP POP       X       Y\n#&gt; 1  ALB  ALB   600 43.0  71  34  27   6 3.3  35   5  29 3.1 4825115 1684833\n#&gt; 2  AUT  AUT 10000 10.3  75  55  12  12 1.4  18  14  84 7.6 4299715 2335579\ntail(tab,2)\n#&gt;    PAYS BLOC   PNB  TMI ESP URB NAT MOR FEC JEU VIE SUP  POP       X       Y\n#&gt; 24  SWE  SWE 13200  5.9  77  83  12  11 1.8  18  18 450  8.4 4321587 3961396\n#&gt; 25  YUG  YUG  2300 27.1  70  47  15   8 2.1  24   8 256 23.6 4686147 1996737\n\n\n\n3.1.2.2 Sélection de lignes\nOn utilise la syntaxe tab2&lt;-tab[conditions , ] avec les opérateurs logiques suivants\n\n== : est égal à\n!= : est différent de\n&gt;  : est strictement supérieur à\n&lt;  : est strictement inférieur à\n&gt;= : est supérieur ou égal à\n&lt;= : est inférieur ou égal à\n\n& : ET (vrai si les deux conditions sont vérifiées)\n| : OU inclusif (vrai si l’une des conditions est vérifiée)\nxor : OU exclusif (vrai si une seule des conditions est vérifiée)\nExemple de sélection des pays socialistes\n\n\ntabsoc&lt;-euro1988[euro1988$BLOC==\"Soc\",]\ntabsoc\n#&gt;  [1] PAYS BLOC PNB  TMI  ESP  URB  NAT  MOR  FEC  JEU  VIE  SUP  POP  X    Y   \n#&gt; &lt;0 rows&gt; (or 0-length row.names)\n\n\nExemple de sélection des pays non socialistes\n\n\ntabcap&lt;-euro1988[euro1988$BLOC!=\"Soc\",]\ntabcap\n#&gt;    PAYS BLOC   PNB  TMI ESP URB NAT MOR FEC JEU VIE SUP  POP       X       Y\n#&gt; 1   ALB  ALB   600 43.0  71  34  27   6 3.3  35   5  29  3.1 4825115 1684833\n#&gt; 2   AUT  AUT 10000 10.3  75  55  12  12 1.4  18  14  84  7.6 4299715 2335579\n#&gt; 3   BEL  BEL  9200  9.7  75  95  12  11 1.5  19  14  31  9.9 3636312 2667243\n#&gt; 4   BGR  BGR  2000 14.5  72  65  13  11 2.0  21  11 111  9.0 5206070 1930219\n#&gt; 5   CHE  CHE 17800  6.8  77  61  12   9 1.5  17  14  41  6.6 3869378 2243130\n#&gt; 6   CSK  CSK  3200 13.9  71  74  14  12 2.0  24  11 128 15.6 4487005 2540281\n#&gt; 7   DDR  DDR  3700  9.2  72  77  13  13 1.7  19  14 108 16.6 4166231 2825762\n#&gt; 8   DEU  DEU 12000  8.6  75  94  10  11 1.4  15  15 248 61.2 3962835 2640209\n#&gt; 9   DNK  DNK 12600  8.4  75  84  11  11 1.5  18  15  43  5.1 3958433 3234283\n#&gt; 10  ESP  ESP  4800  9.0  76  91  12   8 1.7  23  12 505 39.0 2875285 1646307\n#&gt; 11  FIN  FIN 12200  5.8  74  62  12  10 1.6  19  13 337  4.9 4774974 4230412\n#&gt; 12  FRA  FRA 10100  8.0  75  73  14  10 1.8  21  13 551 55.9 3441707 2245325\n#&gt; 13  GBR  GBR  8900  9.5  75  91  13  12 1.8  19  15 245 57.1 3212580 3065463\n#&gt;  [ reached 'max' / getOption(\"max.print\") -- omitted 12 rows ]\n\n\nExemple de sélection des pays de plus 10 millions d’habitant\n\n\ntabbig&lt;-euro1988[euro1988$POP&gt;20,]\ntabbig\n#&gt;    PAYS BLOC   PNB  TMI ESP URB NAT MOR FEC JEU VIE SUP  POP       X       Y\n#&gt; 8   DEU  DEU 12000  8.6  75  94  10  11 1.4  15  15 248 61.2 3962835 2640209\n#&gt; 10  ESP  ESP  4800  9.0  76  91  12   8 1.7  23  12 505 39.0 2875285 1646307\n#&gt; 12  FRA  FRA 10100  8.0  75  73  14  10 1.8  21  13 551 55.9 3441707 2245325\n#&gt; 13  GBR  GBR  8900  9.5  75  91  13  12 1.8  19  15 245 57.1 3212580 3065463\n#&gt; 17  ITA  ITA  8600 10.1  75  72  10  10 1.4  19  13 301 57.3 4184347 1884241\n#&gt; 21  POL  POL  2100 17.5  71  61  17  10 2.2  26   9 313 38.0 4622269 2851709\n#&gt; 23  ROU  ROU  1200 25.6  70  49  16  11 2.3  25   9 238 23.0 5120263 2251425\n#&gt; 25  YUG  YUG  2300 27.1  70  47  15   8 2.1  24   8 256 23.6 4686147 1996737\n\n\nExemple de sélection des pays socialistes de plus 20 millions d’habitant (on mélange deux conditions avec l’opérateur &)\n\n\ntabsocbig&lt;-euro1988[euro1988$BLOC==\"Soc\" & euro1988$POP&gt;20,]\ntabsocbig\n#&gt;  [1] PAYS BLOC PNB  TMI  ESP  URB  NAT  MOR  FEC  JEU  VIE  SUP  POP  X    Y   \n#&gt; &lt;0 rows&gt; (or 0-length row.names)\n\n\n\n3.1.2.3 Sélection de colonnes\nOn utilise la syntaxe tab2&lt;-tab[  ,  liste ] avec différentes syntaxes pour les listes de variables :\n\nSélection nominale\n\n\ntab&lt;-euro1988[,c(\"PAYS\", \"BLOC\", \"PNB\", \"TMI\",\"POP\")]\nhead(tab,2)\n#&gt;   PAYS BLOC   PNB  TMI POP\n#&gt; 1  ALB  ALB   600 43.0 3.1\n#&gt; 2  AUT  AUT 10000 10.3 7.6\n\n\nSélection de positions\n\n\ntab&lt;-euro1988[,c(1:4, 13)]\nhead(tab,2)\n#&gt;   PAYS BLOC   PNB  TMI POP\n#&gt; 1  ALB  ALB   600 43.0 3.1\n#&gt; 2  AUT  AUT 10000 10.3 7.6\n\n\n\n3.1.2.4 Sélection simultanée de lignes et colonnes\nOn utilise la syntaxe tab2&lt;-tab[ conditions ,  liste]\n\nExemple : PNB et BLOC des pays de moins de 5 millions d’habitant\n\n\ntab&lt;-euro1988[euro1988$POP&lt;5, c(\"PAYS\",\"BLOC\",\"POP\",\"PNB\")]\ntab\n#&gt;    PAYS BLOC POP   PNB\n#&gt; 1   ALB  ALB 3.1   600\n#&gt; 11  FIN  FIN 4.9 12200\n#&gt; 16  IRL  IRL 3.5  5100\n#&gt; 18  LUX  LUX 0.4 16500\n#&gt; 20  NOR  NOR 4.2 15500\n\n\n\n\n3.1.3 Extractions\n\n3.1.3.1 Extraction d’une Variable = Vecteur\n\nSolution n°1 : utilisation de l’opérateur $\n\n\nmyvar&lt;-euro1988$POP\nstr(myvar)\n#&gt;  num [1:25] 3.1 7.6 9.9 9 6.6 15.6 16.6 61.2 5.1 39 ...\nmean(myvar)\n#&gt; [1] 19.828\n\n-Solution n°2 : utilisation de [ , ]\n\nmyvar&lt;-euro1988[,13]\nstr(myvar)\n#&gt;  num [1:25] 3.1 7.6 9.9 9 6.6 15.6 16.6 61.2 5.1 39 ...\nmean(myvar)\n#&gt; [1] 19.828\n\n\n\n3.1.3.2 Création d’une matrice\nOn sélectionne les lignes et les colonnes puis on convertit en matrice avec l’instruction as.matrix(). Attention, les variables doivent être de même type (toutes numériques ou toutes caractère ou …), sinon R effectue une conversion forcée.\n\nExemple 1 : création d’une matrice de corrélation\n\nOn commence par extraire trois variables du tableau pour en faire une matrice :\n\nmymat&lt;-euro1988[,c(\"PNB\",\"TMI\",\"FEC\")]\nrow.names(mymat)&lt;-euro1988$PAYS  # facultatif : donne le nom des lignes\nstr(mymat)\n#&gt; 'data.frame':    25 obs. of  3 variables:\n#&gt;  $ PNB: int  600 10000 9200 2000 17800 3200 3700 12000 12600 4800 ...\n#&gt;  $ TMI: num  43 10.3 9.7 14.5 6.8 13.9 9.2 8.6 8.4 9 ...\n#&gt;  $ FEC: num  3.3 1.4 1.5 2 1.5 2 1.7 1.4 1.5 1.7 ...\nmymat&lt;-as.matrix(mymat)\nstr(mymat)\n#&gt;  num [1:25, 1:3] 600 10000 9200 2000 17800 3200 3700 12000 12600 4800 ...\n#&gt;  - attr(*, \"dimnames\")=List of 2\n#&gt;   ..$ : chr [1:25] \"ALB\" \"AUT\" \"BEL\" \"BGR\" ...\n#&gt;   ..$ : chr [1:3] \"PNB\" \"TMI\" \"FEC\"\n\nPuis on applique la fonction cor() à cette matrice pour en faire une matrice de corrélation ;\n\nmycor&lt;-cor(mymat)\nmycor\n#&gt;            PNB        TMI        FEC\n#&gt; PNB  1.0000000 -0.6584308 -0.6144008\n#&gt; TMI -0.6584308  1.0000000  0.8136871\n#&gt; FEC -0.6144008  0.8136871  1.0000000\nstr(mycor)\n#&gt;  num [1:3, 1:3] 1 -0.658 -0.614 -0.658 1 ...\n#&gt;  - attr(*, \"dimnames\")=List of 2\n#&gt;   ..$ : chr [1:3] \"PNB\" \"TMI\" \"FEC\"\n#&gt;   ..$ : chr [1:3] \"PNB\" \"TMI\" \"FEC\"\n\n\nExemple 2 : Création d’une matrice de distance\n\nOn commence par extraire les coordonnées (X,Y) sous forme de matrice\n\nmatcoo&lt;-as.matrix(euro1988[,c(\"X\",\"Y\")])\nrow.names(matcoo)&lt;-euro1988$PAYS  # facultatif : donne le nom des lignes\nstr(matcoo)\n#&gt;  num [1:25, 1:2] 4825115 4299715 3636312 5206070 3869378 ...\n#&gt;  - attr(*, \"dimnames\")=List of 2\n#&gt;   ..$ : chr [1:25] \"ALB\" \"AUT\" \"BEL\" \"BGR\" ...\n#&gt;   ..$ : chr [1:2] \"X\" \"Y\"\nhead(matcoo)\n#&gt;           X       Y\n#&gt; ALB 4825115 1684833\n#&gt; AUT 4299715 2335579\n#&gt; BEL 3636312 2667243\n#&gt; BGR 5206070 1930219\n#&gt; CHE 3869378 2243130\n#&gt; CSK 4487005 2540281\n\nPuis on transforme ces coordonnées en distance à l’aide de la fonction dist()\n\nmatdis&lt;-as.matrix(dist(matcoo))\nstr(matdis)\n#&gt;  num [1:25, 1:25] 0 836370 1542200 453145 1106855 ...\n#&gt;  - attr(*, \"dimnames\")=List of 2\n#&gt;   ..$ : chr [1:25] \"ALB\" \"AUT\" \"BEL\" \"BGR\" ...\n#&gt;   ..$ : chr [1:25] \"ALB\" \"AUT\" \"BEL\" \"BGR\" ...\nmatdis[1:10,1:5]\n#&gt;           ALB       AUT       BEL       BGR       CHE\n#&gt; ALB       0.0  836370.2 1542200.5  453144.9 1106855.4\n#&gt; AUT  836370.2       0.0  741690.6  992872.1  440155.5\n#&gt; BEL 1542200.5  741690.6       0.0 1734169.4  483933.6\n#&gt; BGR  453144.9  992872.1 1734169.4       0.0 1372828.3\n#&gt; CHE 1106855.4  440155.5  483933.6 1372828.3       0.0\n#&gt; CSK  919842.9  277453.7  860114.5  942990.5  685391.6\n#&gt; DDR 1317515.9  508033.5  553120.4 1372320.3  653897.6\n#&gt; DEU 1286962.2  454189.8  327639.9 1431684.2  407929.4\n#&gt; DNK 1775368.8  961323.9  652147.5 1804766.4  995146.1\n#&gt; ESP 1950211.4 1582434.4 1273370.9 2348013.0 1159491.1\n\nEt on calcule le pays le plus proche de tous les autres à l’aide de la fonction apply() (qu’on verra ultérieurement dans un autre chapitre)\n\nmean(matdis)\n#&gt; [1] 1262347\naccess&lt;-apply(matdis, FUN=mean,1)\naccess&lt;-access[order(access)]\nround(access,0)\n#&gt;     DEU     AUT     DDR     LUX     CSK     CHE     BEL     NLD     HUN     POL \n#&gt;  898957  926937  932604  944407  954421  966312  981428  984509 1043514 1062733 \n#&gt;     ITA     DNK     FRA     YUG     GBR     ROU     ALB     BGR     GRC     IRL \n#&gt; 1095500 1105659 1125130 1133254 1301552 1309032 1348834 1450710 1558508 1559733 \n#&gt;     SWE     NOR     ESP     FIN     PRT \n#&gt; 1592972 1692199 1701144 1923979 1964658"
  },
  {
    "objectID": "03-Base.html#exploration-i-var.-quali.",
    "href": "03-Base.html#exploration-i-var.-quali.",
    "title": "3  R-Base",
    "section": "3.2 Exploration I (var. quali.)",
    "text": "3.2 Exploration I (var. quali.)\n\n3.2.1 Sélection et recodage\nLes variables qualitatives nominales ou factor sont des objets composés d’une liste de numéros et d’une liste d’étiquettes.\n\n# Chargement du tableau de données\ndon &lt;- read.table(file = \"resources/data/europe88/euro1988.csv\", # nom du fichier et chemin d'accès\n                  sep = \";\",                     # séparateur (ici, des points-virgule)\n                  header = TRUE,                 # ligne d'en-tête avec le nom des variables\n                  encoding=\"UTF-8\")              # encodage adapté au français\n\n# Extraction de la variable\nX&lt;-don$BLOC\nX\n#&gt;  [1] \"Soc\" \"Cap\" \"Cap\" \"Soc\" \"Cap\" \"Soc\" \"Soc\" \"Cap\" \"Cap\" \"Cap\" \"Cap\" \"Cap\"\n#&gt; [13] \"Cap\" \"Cap\" \"Soc\" \"Cap\" \"Cap\" \"Cap\" \"Cap\" \"Cap\" \"Soc\" \"Cap\" \"Soc\" \"Cap\"\n#&gt; [25] \"Soc\"\n\n# Vérification du type\nstr(X)\n#&gt;  chr [1:25] \"Soc\" \"Cap\" \"Cap\" \"Soc\" \"Cap\" \"Soc\" \"Soc\" \"Cap\" \"Cap\" \"Cap\" ...\n\nSi la variable chargée est de type character il faut la transformer avec as.factor() et repérer les niveaux disponibles avec levels()\n\nX&lt;-as.factor(X)\nclass(X)\n#&gt; [1] \"factor\"\nlevels(X)\n#&gt; [1] \"Cap\" \"Soc\"\n\nOn peut remplacer les niveaux en utilisant l’instruction levels()à nouveau, mais suivie d’un vecteur de charactères indiquant les changements de nom.\n\n\nlevels(X)&lt;-c(\"Capitaliste\",\n             \"Socialiste\")\nX\n#&gt;  [1] Socialiste  Capitaliste Capitaliste Socialiste  Capitaliste Socialiste \n#&gt;  [7] Socialiste  Capitaliste Capitaliste Capitaliste Capitaliste Capitaliste\n#&gt; [13] Capitaliste Capitaliste Socialiste  Capitaliste Capitaliste Capitaliste\n#&gt; [19] Capitaliste Capitaliste Socialiste  Capitaliste Socialiste  Capitaliste\n#&gt; [25] Socialiste \n#&gt; Levels: Capitaliste Socialiste\nstr(X)\n#&gt;  Factor w/ 2 levels \"Capitaliste\",..: 2 1 1 2 1 2 2 1 1 1 ...\n\nOn peut transformer une variable quantitative en facteur avec la fonction cut()\n\nY&lt;-cut(don$POP, breaks=c(0,10,30,100))\nY\n#&gt;  [1] (0,10]   (0,10]   (0,10]   (0,10]   (0,10]   (10,30]  (10,30]  (30,100]\n#&gt;  [9] (0,10]   (30,100] (0,10]   (30,100] (30,100] (10,30]  (10,30]  (0,10]  \n#&gt; [17] (30,100] (0,10]   (10,30]  (0,10]   (30,100] (10,30]  (10,30]  (0,10]  \n#&gt; [25] (10,30] \n#&gt; Levels: (0,10] (10,30] (30,100]\nstr(Y)\n#&gt;  Factor w/ 3 levels \"(0,10]\",\"(10,30]\",..: 1 1 1 1 1 2 2 3 1 3 ...\n\nOn peut ensuite recoder les classes avec levels()\n\nlevels(Y)&lt;-c(\"Petit\",\"Moyen\",\"Grand\")\nY\n#&gt;  [1] Petit Petit Petit Petit Petit Moyen Moyen Grand Petit Grand Petit Grand\n#&gt; [13] Grand Moyen Moyen Petit Grand Petit Moyen Petit Grand Moyen Moyen Petit\n#&gt; [25] Moyen\n#&gt; Levels: Petit Moyen Grand\nstr(Y)\n#&gt;  Factor w/ 3 levels \"Petit\",\"Moyen\",..: 1 1 1 1 1 2 2 3 1 3 ...\n\n\n\n3.2.2 Table de dénombrement\nPour dénomber une variable qualitative, on utilise l’instruction table() qui crée un objet particulier qui n’est ni un data.frame, ni une matrix.\n\ntab&lt;-table(X)\ntab\n#&gt; X\n#&gt; Capitaliste  Socialiste \n#&gt;          17           8\nstr(tab)\n#&gt;  'table' int [1:2(1d)] 17 8\n#&gt;  - attr(*, \"dimnames\")=List of 1\n#&gt;   ..$ X: chr [1:2] \"Capitaliste\" \"Socialiste\"\n\nOn peut créer des tables à 2, 3 ou 4 dimensions\n\ntab2&lt;-table(X,Y)\ntab2\n#&gt;              Y\n#&gt; X             Petit Moyen Grand\n#&gt;   Capitaliste     9     3     5\n#&gt;   Socialiste      2     5     1\nstr(tab2)\n#&gt;  'table' int [1:2, 1:3] 9 2 3 5 5 1\n#&gt;  - attr(*, \"dimnames\")=List of 2\n#&gt;   ..$ X: chr [1:2] \"Capitaliste\" \"Socialiste\"\n#&gt;   ..$ Y: chr [1:3] \"Petit\" \"Moyen\" \"Grand\"\n\nUn objet de type table peut être manipulé par des fonctions spéciales comme addmargins() quii rajoute des sommes en ligne (et en colonne si la table est de dimension 2)\n\naddmargins(tab)\n#&gt; X\n#&gt; Capitaliste  Socialiste         Sum \n#&gt;          17           8          25\naddmargins(tab2)\n#&gt;              Y\n#&gt; X             Petit Moyen Grand Sum\n#&gt;   Capitaliste     9     3     5  17\n#&gt;   Socialiste      2     5     1   8\n#&gt;   Sum            11     8     6  25\n\n\n\n\n\n\n\nNote\n\n\n\nLes objets de type table sont souvent la source de crises de nerf de la part des étudiants qui les confondent avec des objets de type vecteur, matrice ou data.frame. Il existe des fonctions de conversion d’un type vers un autre mais leur emploi n’est pas très simple.\nOn retiendra donc dans l’immédiat que les résultats de l’instruction tablesont des objets transitoires qui servent uniquement à afficher des résultats ou produire des graphiques à l’aide des instructions plot() ou barplot().\n\n\n\n\n3.2.3 Graphique avec plot()\nLa fonction plot() s’applique à la plupart de objets R. Elle produit des résultats différents selon le type d’objet qu’elle a identifié. Si on l’applique à un vecteur de type factor on obtient un diagramme en bâtons (à ne pas confondre avec un histogramme)\n\nplot(X)\n\n\n\n\nOn peut améliorer le graphique en lui ajoutant des paramètres c’est-à-dire des instructions séparées par des virgules. Le retour à la ligne après chaque paramètre n’est pas obligatoire mais il est recommandé car il rend le code plus clair.\n\nplot(X,\n     col=c(\"blue\",\"red\"), \n     main= \"Europe en 1988\",\n     xlab = \"Type politique\", \n     ylab = \"Nombre de pays\")"
  },
  {
    "objectID": "03-Base.html#exploration-ii-var.-quanti",
    "href": "03-Base.html#exploration-ii-var.-quanti",
    "title": "3  R-Base",
    "section": "3.3 Exploration II (var. quanti)",
    "text": "3.3 Exploration II (var. quanti)\n\n3.3.1 Résumés numériques\nUne variable numérique peut faire l’objet d’un ensemble de résumés statistiques à l’aide de fonctions élémentaires\n\nmin() : minimum\nmax() : maximum\nmean() : moyenne\nsd() : écart-type (en anglais : standard deviation, soit sd en abrégé)\nsum() : somme\n\n\nX &lt;- don$FEC\nmin(X)\n#&gt; [1] 1.4\nmax(X)\n#&gt; [1] 3.3\nmean(X)\n#&gt; [1] 1.816\nsd(X)\n#&gt; [1] 0.4160128\n\nPour calculer les quantiles on peut utiliser la fonction quantile() en paramétrant la valeur de fréquence cumulée ascendante\n\nquantile(X,0) : minimum\nquantile(X,0.10) : D1 (premier décile)\nquantile(X,0.25) : Q1 (premier quartile)\nquantile(X,0.5) : Q2 (médiane)\nquantile(X,0.75) : Q3 (troisième quartile)\nquantile(X,0.90) : D9 (dernier décile)\nquantile(X,1) : maximum\n\n\nX&lt;-don$FEC\nquantile(X,0.5)\n#&gt; 50% \n#&gt; 1.7\nsel&lt;-c(0,0.25,0.5,0.75,1)\nquantile(X,sel)\n#&gt;   0%  25%  50%  75% 100% \n#&gt;  1.4  1.5  1.7  2.0  3.3\nsel&lt;-c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1)\nquantile(X,sel)\n#&gt;   0%  10%  20%  30%  40%  50%  60%  70%  80%  90% 100% \n#&gt; 1.40 1.44 1.50 1.60 1.70 1.70 1.80 1.80 2.02 2.26 3.30\n\nIl peut arriver qu’une fonction soit manquante dans R, comme par exemple le coefficient de variation. Dans ce cas, on peut faire le calcul par des lignes de code ou créer sa propre fonction avec l’instruction function(). La fonction qui est stockée en mémoire apparaît dans la fenêtre Environnement. Lorsqu’on a créé plusieurs fonctions, on peut en faire un programme R qu’on charge en mémoire au début de chaque session. A plus long terme, on peut en faire un package qu’on partagera avec les autres utilisateurs de R.\nA titre d’exemple, nous créons une fonction cv() qui calcule le rapport entre l’écart-type et la moyenne d’une distribution :\n\n# lignes de code\nX &lt;- don$FEC\nsd(X)/mean(X)\n#&gt; [1] 0.2290819\n\n# fonction\ncv&lt;-function(var) {sd(var)/mean(var)}\ncv(X)\n#&gt; [1] 0.2290819\n\n\n\n3.3.2 Dénombrement\nUne variable quantitative peut être discrétisée avec cut(). Elle devient alors un facteur qu’on peut dénomber avec table() puis visualiseer avec plot() sous la forme de diagramme en bâtons.\n\nX&lt;-cut(don$FEC, c(1,1.5,2,2.5,3,3.5))\nstr(X)\n#&gt;  Factor w/ 5 levels \"(1,1.5]\",\"(1.5,2]\",..: 5 1 1 2 1 2 2 1 1 2 ...\ntable(X)\n#&gt; X\n#&gt; (1,1.5] (1.5,2] (2,2.5] (2.5,3] (3,3.5] \n#&gt;       7      13       4       0       1\n\n\nplot(X, col=c(\"green\",\"yellow\",\"orange\",\"red\",\"brown\"),\n     main = \"Fécondité en Europe en 1988\", xlab = \"classes\")\n\n\n\n\n\n\n3.3.3 Boîte à moustaches\nLa fonction boxplot() permet de visualiser une distribution sous forme de boîte à moustache où l’on repère facilement :\n\nla médiane\nles quartiles Q1 et Q3\nle minimum et le maximum\nles valeurs extrêmes situées à une distance supéreiure à 1.5 x (Q3-Q1) de la médiane\n\nLa syntaxe de base est la suivante :\n\nX&lt;-don$FEC\nboxplot(X)\n\n\n\n\nMais on peut améliorer la figure avec quelques paramètres de plus\n\nboxplot(X,horizontal = TRUE, col = \"gray80\",\n        main = \"Fécondité des pays européens en 1988\",\n        xlab = \"nb. enfants par femme\")\n\n\n\n\nEt on peut retirer les valeurs exceptionnelles avec le paramètre outline=FALSE\n\nboxplot(X,horizontal = TRUE, col = \"gray80\",\n        main = \"Fécondité des pays européens en 1988\",\n        xlab = \"nb. enfants par femme\",\n        outline = FALSE)\n\n\n\n\n\n\n3.3.4 Histogramme\nDans le cas d’une variable quantitative continue, la visualisation la plus logique est l’histogramme que l’on peut tracer avec la fonction hist(). Celle-ci comporte de nombreux paramètres que l’on peut visualiser dans la fenêtre Help qui se trouve en bas à gauche de R-studio :\nComme d’hebitude, on peut appliquer la syntaxe la plus simple :\n\nX&lt;-don$FEC\nhist(X)\n\n\n\n\nOn peut ensuite améliorer avec l’ajout de titres et un choix précis de classes. Dans le cas de la fécondité, il est par exemple important d’utiliser le seuil de 2.1 enfants par femme qui correspond au renouvellement des générations. On remarque que si les classes sont d’amplitudes inégales R utilise la densité de probabilité (rapport entre effectif et amplitude de la classe) et non plus l’effectif ce qui est statistiquement correct (et que ne fait pas Excel …).\n\nhist(X, \n     breaks = c(1.2, 1.5, 1.8, 2.1, 2.4, 3.3), \n     col=c(\"blue\", \"lightblue\",\"lightyellow\",\"orange\",\"red\"),\n     main = \"Fécondité des pays européens en 1988\",\n     ylab = \"Densité de probabilité\", \n     xlab = \"Nombre d'enfants par femme\",\n     xlim=c(1,3.5))\n\n\n\n\nOn peut également ajouter une courbe lissée de la distribution avec les fonctions lines() etdensity()en indiquant la portée du lissage à l'aide du paramètrebw`(band width) qui est exprimé dans l’unité de mesure de X\n\nhist(X, \n     breaks = c(1.2, 1.5, 1.8, 2.1, 2.4, 3.3),\n     col=c(\"blue\", \"lightblue\",\"green\",\"yellow\",\"orange\"),\n     main = \"Fécondité des pays européens en 1988\",\n     ylab = \"Densité de probabilité\", \n     xlab = \"Nombre d'enfants par femme\",\n     xlim=c(1,3.5))\nlines(density(X,bw=0.3),col=\"red\",lwd=2)"
  },
  {
    "objectID": "03-Base.html#exploration-iii-2-variables",
    "href": "03-Base.html#exploration-iii-2-variables",
    "title": "3  R-Base",
    "section": "3.4 Exploration III (2 variables)",
    "text": "3.4 Exploration III (2 variables)\nNous verrons en détail dans les chapitres suivants comment croiser deux variables d’un point de vue statistiques. Mais on peut déjà indiquer brièvement comment les visualiser rapidement à l’aide de trois exemples\n\n3.4.1 Deux variables qualitatives\n\nTableau de contingence\n\n\nX &lt;- don$BLOC\nlevels(X)&lt;-c(\"Capitalise\",\"Socialiste\")\nY&lt;-cut(don$POP, breaks=c(0,10,30,100))\nlevels(Y) &lt;- c(\"petit\",\"moyen\",\"grand\")\ntab&lt;-table(X,Y)\naddmargins(tab)\n#&gt;      Y\n#&gt; X     petit moyen grand Sum\n#&gt;   Cap     9     3     5  17\n#&gt;   Soc     2     5     1   8\n#&gt;   Sum    11     8     6  25\n\n\nGraphique\n\n\nplot(tab, col=c(\"yellow\",\"orange\",\"brown\"))\n\n\n\n\n\nTest (Chi-2)\n\n\ntest&lt;-chisq.test(X,Y)\n#&gt; Warning in chisq.test(X, Y): Chi-squared approximation may be incorrect\ntest\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  X and Y\n#&gt; X-squared = 5.0336, df = 2, p-value = 0.08072\n\n\n\n3.4.2 Deux variables quantitatives\n\nParamètres principaux\n\n\nY &lt;- don$TMI\nX&lt;-don$PNB\nsummary(X)\n#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#&gt;     600    2300    8600    7580   12000   17800\nsummary(Y)\n#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#&gt;    5.80    8.50    9.70   12.99   14.50   43.00\n\n\nGraphique\n\n\nplot(X,Y, xlab=\"PNB par habitant\",ylab=\"Mortalité infantile\")\ntext(X,Y,don$PAYS,pos = 4,cex=0.6)\n\n\n\n\n\nTest (Pearson)\n\n\ncor.test(Y,X)\n#&gt; \n#&gt;  Pearson's product-moment correlation\n#&gt; \n#&gt; data:  Y and X\n#&gt; t = -4.1955, df = 23, p-value = 0.0003459\n#&gt; alternative hypothesis: true correlation is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -0.8360497 -0.3558907\n#&gt; sample estimates:\n#&gt;        cor \n#&gt; -0.6584308\n\n\n\n3.4.3 Une quantitative et une qualitative\n\nGraphique\n\n\nY &lt;- don$TMI\nX &lt;- as.factor(don$BLOC)\nlevels(X)&lt;-c(\"Capitalise\",\"Socialiste\")\nplot(X,Y, \n     col=c(\"blue\",\"red\"),\n     xlab =\"Mortalité infantile\",\n     ylab = \"Bloc politique\",\n     horizontal=T)\n\n\n\n\n\nTest (Fischer)\n\n\nmod&lt;-aov(Y~X)\nsummary(mod)\n#&gt;             Df Sum Sq Mean Sq F value   Pr(&gt;F)    \n#&gt; X            1  797.4   797.4   20.85 0.000137 ***\n#&gt; Residuals   23  879.7    38.2                     \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "03-Base.html#en-résumé",
    "href": "03-Base.html#en-résumé",
    "title": "3  R-Base",
    "section": "3.5 En résumé",
    "text": "3.5 En résumé\n\n\n\nNous avons survolé les principales fonctions élémentaires de R-Base pour montrer qu’il est facile et surtout rapide de les employer en lieu et place d’un tableur comme Excel ou d’un logiciel de statistique click-bouton. Il reste encore beaucoup à apprendre mais à ce stade il est important de bien consolider les acquis et de connaître par coeur le nom des principales fonctions de base qui ont été présentées au cours de ce chapitre."
  },
  {
    "objectID": "11-Corrélation.html#préparation-des-données",
    "href": "11-Corrélation.html#préparation-des-données",
    "title": "4  Corrélation",
    "section": "4.1 Préparation des données",
    "text": "4.1 Préparation des données\n\n4.1.1 Chargement du tableau principal\nOn charge notre bon vieux fichier des pays européens en 1988\n\ndon&lt;-read.table(file = \"resources/data/europe88/euro1988.csv\",\n                sep = \";\",\n                header = T)\ndon$BLOC&lt;-as.factor(don$BLOC)\nlevels(don$BLOC)&lt;-c(\"Capitaliste\",\"Socialiste\")\nhead(don)\n#&gt;   PAYS        BLOC   PNB  TMI ESP URB NAT MOR FEC JEU VIE SUP  POP       X\n#&gt; 1  ALB  Socialiste   600 43.0  71  34  27   6 3.3  35   5  29  3.1 4825115\n#&gt; 2  AUT Capitaliste 10000 10.3  75  55  12  12 1.4  18  14  84  7.6 4299715\n#&gt; 3  BEL Capitaliste  9200  9.7  75  95  12  11 1.5  19  14  31  9.9 3636312\n#&gt; 4  BGR  Socialiste  2000 14.5  72  65  13  11 2.0  21  11 111  9.0 5206070\n#&gt; 5  CHE Capitaliste 17800  6.8  77  61  12   9 1.5  17  14  41  6.6 3869378\n#&gt; 6  CSK  Socialiste  3200 13.9  71  74  14  12 2.0  24  11 128 15.6 4487005\n#&gt;         Y\n#&gt; 1 1684833\n#&gt; 2 2335579\n#&gt; 3 2667243\n#&gt; 4 1930219\n#&gt; 5 2243130\n#&gt; 6 2540281\n\n\n\n4.1.2 Choix des deux variables à analyser\nEn dehors de BLOC et PAYS, on ne garde que deux variables que l’on renomme X et Y avec colnames() et que l’on convertit en type numérique général. Il suffira par la suite de modifier le choix des variables X et Y pour faire d’autres analyses.\n\neur&lt;-don[,c(\"PAYS\",\"BLOC\",\"URB\",\"TMI\")]\ncolnames(eur)&lt;-c(\"PAYS\",\"BLOC\",\"X\",\"Y\")\neur$X&lt;-as.numeric(eur$X)\neur$Y&lt;-as.numeric(eur$Y)\nhead(eur)\n#&gt;   PAYS        BLOC  X    Y\n#&gt; 1  ALB  Socialiste 34 43.0\n#&gt; 2  AUT Capitaliste 55 10.3\n#&gt; 3  BEL Capitaliste 95  9.7\n#&gt; 4  BGR  Socialiste 65 14.5\n#&gt; 5  CHE Capitaliste 61  6.8\n#&gt; 6  CSK  Socialiste 74 13.9\n\n\n\n4.1.3 On est malin …\nMais comme on ne sait plus ce que sont X et Y, on le précise avec des chaînes de caractères qu’on pourra utiliser dans les graphiques. Et on peut préparer une version multilangue …\n\n# Pour la version française\nfr_titre &lt;- \"Les pays européens en 1988\"\nfr_nomX &lt;- \"Taux d'urbanisation en %\"\nfr_nomY &lt;- \"Taux de mortalité infantile en p. 1000\"\nfr_auteur &lt;- \"Claude Grasland, Université Paris Diderot, 2020\"\n\n\n# Pour la version arabe\nar_titre &lt;- \"البلدان الأوروبية في عام 1988\"\nar_nomX &lt;-  \"معدل التحضر في المائة\"\nar_nomY &lt;- \"معدل وفيات الرضع في عام 1000\"\nar_auteur &lt;- \"كلود غراسلاند، جامعة باريس ديدرو، 2020\"\n\n\n# Pour la version anglaise\nen_titre &lt;- \"European countries in 1988\"\nen_nomX &lt;- \"Urbanisation rate %\"\nen_nomY &lt;- \"Infant mortality rate p. 1000\"\nen_auteur &lt;- \"Claude Grasland, University Paris Diderot, 2020\"\n\n\n# Pour la version russe\nru_titre &lt;- \"Европейские страны в 1988 году\"\nru_nomX &lt;- \"Уровень урбанизации в %\"\nru_nomY &lt;- \"Коэффициент младенческой смертности в 1000 году\"\nru_auteur &lt;- \"Клод Грассленд, Парижский университет Дидро, 2020\"\n\n\n\n4.1.4 On est paresseux …\nComme on prévoit qu’il y aura des différences entre pays socialistes et capitalistes, on crée deux sous-tableaux\n\neur_soc&lt;-eur[eur$BLOC==\"Socialiste\",]\neur_cap&lt;-eur[eur$BLOC==\"Capitaliste\",]"
  },
  {
    "objectID": "11-Corrélation.html#exploration-visuelle",
    "href": "11-Corrélation.html#exploration-visuelle",
    "title": "4  Corrélation",
    "section": "4.2 Exploration visuelle",
    "text": "4.2 Exploration visuelle\n\n4.2.1 Visualisation avec plot(X,Y)\nLa manière la plus simple d’analyser la relation entre X et Y est d’utiliser un simple plot\n\nplot(eur$X,eur$Y)\n\n\n\n\nLa fonction plot() comporte de nombreux paramètres permettant d’améliorer le graphique et de l’habiller. Voici un exemple d’habillage en français\n\nplot(eur$X,eur$Y,\n     main = fr_titre,   # titre\n     cex.main = 1,      # police du titre\n     sub = fr_auteur,   # sous-titre\n     cex.sub = 0.6,     # police du sous-titre\n     xlab = fr_nomX,    # nom de l'axe X\n     xlim = c(20,100),   # intervalle de l'axe X\n     ylab = fr_nomY,    # nom de l'axe Y\n     ylim = c(0,50),    # intervalle de l'axe Y\n     cex.axis = 0.8,    # police des gradations d'axes\n     cex.lab = 0.8,     # police des noms d'axes\n     cex = 0.6,         # taille des symboles\n     col = \"blue\")       # couleur des symboles\n\n\n\n\nOu en anglais: il suffit de changer le nom des variables relatives aux titres.\n\nplot(eur$X,eur$Y,\n     main = en_titre,   # titre\n     cex.main = 1,      # police du titre\n     sub = en_auteur,   # sous-titre\n     cex.sub = 0.5,     # police du sous-titre\n     xlab = en_nomX,    # nom de l'axe X\n     xlim = c(20,100),   # intervalle de l'axe X\n     ylab = en_nomY,    # nom de l'axe Y\n     ylim = c(0,50),    # intervalle de l'axe Y\n     cex.axis = 0.7,    # police des gradations d'axes\n     cex.lab = 0.7,     # police des noms d'axes\n     cex = 0.6,         # taille des symboles\n     col = \"blue\")       # couleur des symboles\n\n\n\n\n\n\n4.2.2 Identification des points avec cor + text(…)\nOn peut ajouter au graphique généré par plot(X,Y) une couche de labels avec text(X,Y,Code). On précise la position avec pos =, la taille de police avex cex = et la couleur avec col =.\n\nplot(x = eur$X,\n     y = eur$Y,\n     cex=0.5,\n     col= \"blue\",\n     ylim =c(0,50))\ntext(x = eur$X,\n     y = eur$Y,\n     label = eur$PAYS,\n     cex = 0.7,\n     pos=3,\n     col = \"blue\")\n\n\n\n\n\n\n4.2.3 Ajout de lignes horizontales ou verticales avec cor() + abline(…)\nOn peut rajouter à un graphique des lignes horizontales ou verticales avec abline en précisant leur position avec h= ou v=, leur épaisseur avec lwd = , leur style avec lty= et leur couleur avec col=\n\nplot(eur$X,eur$Y,\n     main = fr_titre,   # titre\n     cex.main = 1,      # police du titre\n     sub = fr_auteur,   # sous-titre\n     cex.sub = 0.6,     # police du sous-titre\n     xlab = fr_nomX,    # nom de l'axe X\n     xlim = c(20,100),   # intervalle de l'axe X\n     ylab = fr_nomY,    # nom de l'axe Y\n     ylim = c(0,50),    # intervalle de l'axe Y\n     cex.axis = 0.8,    # police des gradations d'axes\n     cex.lab = 0.8,     # police des noms d'axes\n     cex = 0.6,         # taille des symboles\n     col = \"blue\")       # couleur des symboles\n\n# Ajout d'une ligne horizontale  correspondant à la moyenne de Y\nabline(h=mean(eur$Y),col=\"red\",lwd = 1, lty = 2)\n# Ajout d'une ligne verticlae  correspondant à la moyenne de X\nabline(v=mean(eur$X),col=\"red\",lwd = 1, lty = 2)\n\ntext(x = eur$X,\n     y = eur$Y,\n     label = eur$PAYS,\n     cex = 0.6,\n     pos=3,\n     col = \"blue\")\n\n\n\n\nLa fonction abline() peut servir aussi à tracer la droite de régression Y=aX+b produite par la fonction lm()\n\nplot(eur$X,eur$Y)\nmaregression = lm(eur$Y~eur$X)\nabline(maregression,col=\"red\")\n\n\n\n\n\n\n4.2.4 Au delà de R-Base …\nIl existe des packages spécialisés permettant de faire des graphiques plus sophistiqués. Mais on les apprendra ultérieuement. Juste un exemple :\n\nlibrary(car)\nscatterplot(eur$X,eur$Y)"
  },
  {
    "objectID": "11-Corrélation.html#coefficients-de-corrélation",
    "href": "11-Corrélation.html#coefficients-de-corrélation",
    "title": "4  Corrélation",
    "section": "4.3 Coefficients de corrélation",
    "text": "4.3 Coefficients de corrélation\n\n4.3.1 Définition\n\n4.3.1.1 Relation linéaire/monotone/complexe\n\nil existe une relation linéaire entre deux variables quantitatives X et Y si l’on peut prédire leurs valeurs respectives par les fonctions Y = a1.X + b1 et X = a2.X = b2\nil existe une relation monotone entre deux variables quantitatives X et Y si l’on peut prédire les valeurs Y en fonction de celle de X far une fonction Y=f(X) qui est strictement croissante ou strictement décroissante.\nil existe une relation complexe entre deux variables quantitatives X et Y si l’on peut prédire les valeurs Y en fonction de celle de X par une fonction Y=f(X) qui comporte au moins un point minimum ou maximum de changement de pente (annulation de la dérivée première)\n\n\n\n\n\n\n\n\n4.3.1.2 Relation positive/négative/nulle\n\nUne relation linéaire ou monotone est positive si à un accroissement de X correspond un accroissement de Y\nUne relation linéaire ou monotone est négative si à un accroissement de X correspond une diminution de Y\nune relation est nulle si une variation de X n’entraine pas de variation de Y\n\n\n\n\n\n\n\n\n4.3.1.3 Relation forte/faible/nulle\n\nUne relation linéaire est forte si une valeur de X permet de prédire la valeur de Y avec une faible marge d’erreur.\nUne relation linéaire ou monotone est faible si une valeur de X permet de prédire la valeur de Y avec une forte marge d’erreur.\nune relation linéaire est nulle si une valeur de X ne permet aucunement de prédire la valeur de Y\n\n\n\n\n\n\n\n\n4.3.1.4 Relation significative/non siginificative\n\nUne relation linéaire est significative si l’effectif permettant de la mettre en évidence est suffisamment grand pour qu’on puisse exclure qu’elle soit l’effet du hasard.\nUne relation linéaire ou monotone est non significative si l’effectif permettant de la mettre en évidence n’est pas suffisamment grand pour qu’on puisse exclure qu’elle soit l’effet du hasard.\nOn considère traditionnellement qu’une relation est significative s’il y a moins de 5% de chances qu’elle soit l’effet du hasard (p-value &lt; 0.05).\n\n\n\n\n\n\n\n\n\n4.3.2 La fonction cor()\n\nLa fonction cor() permet de mesurer le coefficient de corrélation de deux variable X et Y.\nElle permet de détecter les relations linéaires en choisissant le paramètre (par défaut) method = pearson\n\nElle permet de détecter les relations non linéaires en choisissant le paramètre method = spearman qui mesure l’existence d’une relation monotone entre les rangs de X et Y\nLa syntaxe de la fonction cor() est très simple et permet de calculer trois types de corrélation. La méthode par défaut est pearson c’est-à-dire le coefficient de corrélation linéaire\n\n\ncor(eur$X,eur$Y)\n#&gt; [1] -0.6547219\ncor(eur$X,eur$Y, method = \"spearman\")\n#&gt; [1] -0.5699443\ncor(eur$X,eur$Y, method = \"kendall\")\n#&gt; [1] -0.4053653\n\ncor() permet de savoir si la relation est linéaire ou monotone\n\n\n\n\n\ncor() permet de repérer l’effet d’une valeur exceptionnelle\n\n\n\n\n\ncor() permet de savoir si la relation est positive ou négative\n\n\n\n\n\ncor() permet de avoir si la relation est forte ou faible\n\n\n\n\n\n\n\n4.3.3 La fonction cor.test()\n\nla fonction cor() permet de savoir si une relation est forte ou faible, positive ou négative, linéaire ou non linéaire. Mais cor() ne permet pas de savoir si une relation est significative ou pas.\nC’est la fonction cor.test() qui permet de tester la significativité d’une relation en fournissant un intervalle de confiance du coefficient de corrélation et une probabilité de rejet de H0 : il n’y a pas de relation appelée en anglais la p-value.\np-value &gt; 0.10 : relation non significative\n0.10 &gt; p-value &gt; 0.05 : relation presque significative\np-value &lt; 0.05 : relation significative\np-value &lt; 0.01 : relation très significative\n\nMême syntaxe que cor() :\n\ncor.test(eur$Y,eur$X)\n#&gt; \n#&gt;  Pearson's product-moment correlation\n#&gt; \n#&gt; data:  eur$Y and eur$X\n#&gt; t = -4.1541, df = 23, p-value = 0.0003835\n#&gt; alternative hypothesis: true correlation is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -0.8340765 -0.3501838\n#&gt; sample estimates:\n#&gt;        cor \n#&gt; -0.6547219\n\n\ncor.test(eur$Y,eur$X, method=\"spearman\")\n#&gt; Warning in cor.test.default(eur$Y, eur$X, method = \"spearman\"): Cannot compute\n#&gt; exact p-value with ties\n#&gt; \n#&gt;  Spearman's rank correlation rho\n#&gt; \n#&gt; data:  eur$Y and eur$X\n#&gt; S = 4081.9, p-value = 0.002936\n#&gt; alternative hypothesis: true rho is not equal to 0\n#&gt; sample estimates:\n#&gt;        rho \n#&gt; -0.5699443\n\n\n\n4.3.4 En résumé : intensité ou significativité ?\n\nLe carré du coefficient de corrélation appelé r-square ou r2 permet de mesurer le pouvoir explicatif de X par rapport à Y. Il ne dépend pas du nombre d’observations.\nle test de significativité ou p-value mesure la significativité de la relation c’est-à-dire le fait que la relation entre X et Y ne soit pas l’effet du hasard. Il dépend à la fois du niveau de corrélation et du nombre d’observations.\nA gauche : une relation forte mais non significative\nA droite : une relation faible mais très significative\n\n\n\n\n\n\nAnalysez le diagramme suivant :\n\n\n\n\n\nAnalysez les deux diagrammes suivants :"
  },
  {
    "objectID": "11-Corrélation.html#matrice-de-corrélation",
    "href": "11-Corrélation.html#matrice-de-corrélation",
    "title": "4  Corrélation",
    "section": "4.4 Matrice de corrélation",
    "text": "4.4 Matrice de corrélation\n\n4.4.1 Objectif de l’analyse\n\nSoit un ensemble de variables quantitatives continues \\((X_1...X_i...X_k)\\) décrivant les mêmes individus.\nOn se propose de construire la matrice \\(R_{ij}[1...i...k ; 1...j...k]\\) indiquant pour chaque paire de variable \\(ij\\) leur coefficient de corrélation (linéaire ou de rang)\nPuis de construire la matrice \\(p_{ij}[1...i...k ; 1...j...k]\\) indiquant pour chaque paire de variable \\(ij\\) la probabilité H0 d’absence de relation, c’est-à-dire le degré de significativité de la corrélation.\n\n\n\n4.4.2 Utilisation des résultats\n\nMettre en évidence des groupes de variables significativement corrélées entre elles, que ce soit de façon positive ou négative.\nPréparer la réalisation d’une analyse en composantes principales qui regroupera les variables corrélées entre elles en facteurs.\nIdentifier des variables non redondantes pour construire un modèle de régression multiple.\nIndentifier des variables fortement corrélées pouvant servir de proxy pour estimer des valeurs manquantes dans un tableau\n\n\n\n4.4.3 Visualisation d’une matrice de corrélation\n_ Sous la forme de tableaux montrant si possible à la fois les coefficients de corrélation et les seuils de significativité.\n\nSous la forme de graphes montrant de façon visuelle l’intesité, le signe et la significativité des relations.\nSous la forme de plans factoriels résultant d’une analyse en composantes principales.\n\nChacun de ces objectifs supposant en général l’emploi de packages spécialisés.\n\n\n4.4.4 Exemple : création d’un tableau quantitatif\nOn ne sélectionne que des variables quantitatives et on ajoute les noms des pays en attribut des lignes.\n\ntab&lt;-don[,c(\"PNB\",\"TMI\",\"ESP\",\"URB\",\"NAT\",\"MOR\",\"FEC\")]\nrow.names(tab)&lt;-don$PAYS\nhead(tab,3)\n#&gt;       PNB  TMI ESP URB NAT MOR FEC\n#&gt; ALB   600 43.0  71  34  27   6 3.3\n#&gt; AUT 10000 10.3  75  55  12  12 1.4\n#&gt; BEL  9200  9.7  75  95  12  11 1.5\n\nOn calcule la corrélation\n\nresul&lt;-cor(tab)\nstr(resul)\n#&gt;  num [1:7, 1:7] 1 -0.658 0.83 0.508 -0.466 ...\n#&gt;  - attr(*, \"dimnames\")=List of 2\n#&gt;   ..$ : chr [1:7] \"PNB\" \"TMI\" \"ESP\" \"URB\" ...\n#&gt;   ..$ : chr [1:7] \"PNB\" \"TMI\" \"ESP\" \"URB\" ...\n\nOn affiche la matrice de corrélation en arrondissant les valeurs\n\nround(resul,3)\n#&gt;        PNB    TMI    ESP    URB    NAT    MOR    FEC\n#&gt; PNB  1.000 -0.658  0.830  0.508 -0.466  0.125 -0.614\n#&gt; TMI -0.658  1.000 -0.728 -0.655  0.797 -0.414  0.814\n#&gt; ESP  0.830 -0.728  1.000  0.583 -0.501 -0.071 -0.619\n#&gt; URB  0.508 -0.655  0.583  1.000 -0.514  0.352 -0.554\n#&gt; NAT -0.466  0.797 -0.501 -0.514  1.000 -0.482  0.950\n#&gt; MOR  0.125 -0.414 -0.071  0.352 -0.482  1.000 -0.426\n#&gt; FEC -0.614  0.814 -0.619 -0.554  0.950 -0.426  1.000\n\n\n\n4.4.5 Utilisation du package psych\nLa fonction cor.test() de Rbase ne permet pas de calculer les corrélations pour toute une matrice. Aussi on charge le package psych qui dispose d’une fonction corr.test() beaucoup plus puissante qui crée plusieurs matrices de résultats\n\nlibrary(psych)\n#&gt; \n#&gt; Attaching package: 'psych'\n#&gt; The following object is masked from 'package:car':\n#&gt; \n#&gt;     logit\n#&gt; The following objects are masked from 'package:ggplot2':\n#&gt; \n#&gt;     %+%, alpha\nresults&lt;-psych::corr.test(tab)\nnames(results)\n#&gt;  [1] \"r\"      \"n\"      \"t\"      \"p\"      \"p.adj\"  \"se\"     \"sef\"    \"adjust\"\n#&gt;  [9] \"sym\"    \"ci\"     \"ci2\"    \"ci.adj\" \"stars\"  \"Call\"\n\nOn retrouve la matrice des coefficiences de corrélation\n\nround(results$r,3)\n#&gt;        PNB    TMI    ESP    URB    NAT    MOR    FEC\n#&gt; PNB  1.000 -0.658  0.830  0.508 -0.466  0.125 -0.614\n#&gt; TMI -0.658  1.000 -0.728 -0.655  0.797 -0.414  0.814\n#&gt; ESP  0.830 -0.728  1.000  0.583 -0.501 -0.071 -0.619\n#&gt; URB  0.508 -0.655  0.583  1.000 -0.514  0.352 -0.554\n#&gt; NAT -0.466  0.797 -0.501 -0.514  1.000 -0.482  0.950\n#&gt; MOR  0.125 -0.414 -0.071  0.352 -0.482  1.000 -0.426\n#&gt; FEC -0.614  0.814 -0.619 -0.554  0.950 -0.426  1.000\n\nMais aussi la matrice des tests de significativité\n\nround(results$p,3)\n#&gt;       PNB   TMI   ESP   URB   NAT   MOR   FEC\n#&gt; PNB 0.000 0.006 0.000 0.086 0.114 1.000 0.014\n#&gt; TMI 0.000 0.000 0.001 0.006 0.000 0.170 0.000\n#&gt; ESP 0.000 0.000 0.000 0.027 0.086 1.000 0.013\n#&gt; URB 0.010 0.000 0.002 0.000 0.086 0.254 0.045\n#&gt; NAT 0.019 0.000 0.011 0.009 0.000 0.103 0.000\n#&gt; MOR 0.552 0.040 0.738 0.085 0.015 0.000 0.170\n#&gt; FEC 0.001 0.000 0.001 0.004 0.000 0.034 0.000\n\nOn peut aussi faire une jolie matrice colorée avec des tests de signficativité sous forme d’étoiles\n\ncorPlot(tab, stars=TRUE, diag=FALSE)\n\n\n\n\n\n\n4.4.6 Utilisation du package factoMineR\nSi on veut voir les axes factoriels d’une analyse en composante principales on utilise la fonction PCA() de FactoMineR\n\nlibrary(FactoMineR)\nmonacp&lt;-PCA(tab, graph=FALSE)\n\nOn pourra ensuite visualiser la corrélation des variables avec les principaux axes factoriels et les coordonnées des individus sur ceux-ci.\n\n4.4.6.1 Corrélation des variables avec les axes factoriels\n\nplot.PCA(monacp,choix = \"varcor\")\n\n\n\n\n\n\n4.4.6.2 Coordonnées des individus sur les axes factoriels\n\nplot.PCA(monacp,choix = \"ind\",)"
  },
  {
    "objectID": "12-Régression.html#préparation-des-données",
    "href": "12-Régression.html#préparation-des-données",
    "title": "5  Régression simple",
    "section": "5.1 Préparation des données",
    "text": "5.1 Préparation des données\n\n5.1.1 Chargement du tableau principal\nOn charge notre bon vieux fichier des pays européens en 1988\n\ndon&lt;-read.table(file = \"resources/data/europe88/euro1988.csv\",\n                sep = \";\",\n                header = T)\ndon$BLOC&lt;-as.factor(don$BLOC)\nlevels(don$BLOC)&lt;-c(\"Capitaliste\",\"Socialiste\")\nhead(don)\n#&gt;   PAYS        BLOC   PNB  TMI ESP URB NAT MOR FEC JEU VIE SUP  POP       X\n#&gt; 1  ALB  Socialiste   600 43.0  71  34  27   6 3.3  35   5  29  3.1 4825115\n#&gt; 2  AUT Capitaliste 10000 10.3  75  55  12  12 1.4  18  14  84  7.6 4299715\n#&gt; 3  BEL Capitaliste  9200  9.7  75  95  12  11 1.5  19  14  31  9.9 3636312\n#&gt; 4  BGR  Socialiste  2000 14.5  72  65  13  11 2.0  21  11 111  9.0 5206070\n#&gt; 5  CHE Capitaliste 17800  6.8  77  61  12   9 1.5  17  14  41  6.6 3869378\n#&gt; 6  CSK  Socialiste  3200 13.9  71  74  14  12 2.0  24  11 128 15.6 4487005\n#&gt;         Y\n#&gt; 1 1684833\n#&gt; 2 2335579\n#&gt; 3 2667243\n#&gt; 4 1930219\n#&gt; 5 2243130\n#&gt; 6 2540281\n\n\n\n5.1.2 Choix des deux variables à analyser\nEn dehors de BLOC et PAYS, on ne garde que les deux variables PNB et TMI que l’on renomme X et Y avec colnames() et que l’on convertit en type numérique général. Il suffira par la suite de modifier le choix des variables X et Y pour faire d’autres analyses.\n\neur&lt;-don[,c(\"PAYS\",\"BLOC\",\"PNB\",\"TMI\")]\ncolnames(eur)&lt;-c(\"PAYS\",\"BLOC\",\"X\",\"Y\")\neur$X&lt;-as.numeric(eur$X)\neur$Y&lt;-as.numeric(eur$Y)\nhead(eur)\n#&gt;   PAYS        BLOC     X    Y\n#&gt; 1  ALB  Socialiste   600 43.0\n#&gt; 2  AUT Capitaliste 10000 10.3\n#&gt; 3  BEL Capitaliste  9200  9.7\n#&gt; 4  BGR  Socialiste  2000 14.5\n#&gt; 5  CHE Capitaliste 17800  6.8\n#&gt; 6  CSK  Socialiste  3200 13.9\n\nOn prépare les titres\n\n# Pour la version française\ntitre &lt;- \"Les pays européens en 1988\"\nnomX &lt;- \"Produit National brut ($/hab)\"\nnomY &lt;- \"Taux de mortalité infantile en p. 1000\"\nauteur &lt;- \"Claude Grasland, Université Paris Diderot, 2020\"\n\nComme on prévoit qu’il y aura des différences entre pays socialistes et capitalistes, on crée deux sous-tableaux\n\neur_soc&lt;-eur[eur$BLOC==\"Socialiste\",]\neur_cap&lt;-eur[eur$BLOC==\"Capitaliste\",]"
  },
  {
    "objectID": "12-Régression.html#forme-de-la-relation",
    "href": "12-Régression.html#forme-de-la-relation",
    "title": "5  Régression simple",
    "section": "5.2 Forme de la relation",
    "text": "5.2 Forme de la relation\n\n5.2.1 Vérification de la normalité de X et Y\nLa régression linéaire met en relation deux variables quantitatives X et Y dont on suppose que la distribution est normale (gaussienne) , c’est-à-dire unimodale et symérique.\n\n\n\n\n\nOn peut tester la normalité des disributions par inspection visuelle à l’aide de hist()\n\n\n\n\n\nLes fonctions qqnorm() et qqline() sont plus précises …\n\nqqnorm(eur$X, col=\"blue\",ylab=nomX)\nqqline(eur$X,col=\"red\")\n\n\n\n\nLes fonctions qqnorm() et qqline() sont plus précises …\n\nqqnorm(eur$Y, col=\"blue\",ylab=nomY)\nqqline(eur$Y,col=\"red\")\n\n\n\n\nMais la solution la plus précise est le test de Shapiro qui pose l’hypothèse H0 : la distribution est normale.\n\nshapiro.test(eur$X)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  eur$X\n#&gt; W = 0.9175, p-value = 0.04495\nshapiro.test(eur$Y)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  eur$Y\n#&gt; W = 0.72466, p-value = 0.00001594\n\n\n\n5.2.2 Visualisation de la forme de la relation\nOn peut faire un simple plot(X,Y). Mais on peut aussi créer pour cela une fonction personalisée adapté à ses préférences\n\nmonplot &lt;- function (varX , varY,  varN )\n{ \n  plot(varX,varY,\n     main = titre,      # titre\n     cex.main = 1,      # police du titre\n     cex = 0.6,         # taille des symboles\n     pch = 19,          # cercles pleins\n     col = \"red\")      # couleur des symboles\n  text(varX,varY,varN,cex=0.5,pos=3) # nom des élément\n  abline(v=mean(varX),lty=2,lwd=1,col=\"blue\") # moyenne X\n  abline(h=mean(varY),lty=2,lwd=1,col=\"blue\") # moyenne Y   \n  }\n\nJe peux désormais utiliser ma fonction monplot() !\n\nmonplot(varX = eur$X,varY = eur$Y, varN = eur$PAYS)\n\n\n\n\nJe peux décider de ne pas afficher le label des points.\n\nmonplot(varX = eur$X,varY = eur$Y, varN = NULL)\n\n\n\n\n\n\n5.2.3 Analyse de la corrélation\nJe commence par celuler le coefficient de corrélation linéaire (r) et le pouvoir explicatif de X par rapport à Y (r2)\n\ncor(eur$X,eur$Y)       # coefficient de corrélation (r)\n#&gt; [1] -0.6584308\n100*cor(eur$X,eur$Y)**2    # pouvoir explicatif (r2)\n#&gt; [1] 43.35312\n\nPuis, je teste la significativité de la corrélation linéaire …\n\ncor.test(eur$X,eur$Y)  # test de significativité (p-value)\n#&gt; \n#&gt;  Pearson's product-moment correlation\n#&gt; \n#&gt; data:  eur$X and eur$Y\n#&gt; t = -4.1955, df = 23, p-value = 0.0003459\n#&gt; alternative hypothesis: true correlation is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -0.8360497 -0.3558907\n#&gt; sample estimates:\n#&gt;        cor \n#&gt; -0.6584308\n\n… et je la compare à celle du coefficient de corrélation de rang de Spearman\n\ncor.test(eur$X,eur$Y, method=\"spearman\")  # test de significativité (p-value)\n#&gt; Warning in cor.test.default(eur$X, eur$Y, method = \"spearman\"): Cannot compute\n#&gt; exact p-value with ties\n#&gt; \n#&gt;  Spearman's rank correlation rho\n#&gt; \n#&gt; data:  eur$X and eur$Y\n#&gt; S = 4796.3, p-value = 0.0000001094\n#&gt; alternative hypothesis: true rho is not equal to 0\n#&gt; sample estimates:\n#&gt;        rho \n#&gt; -0.8447182\n\nOn peut conclure des analyses précédentes que :\n\nil existe une relation significative (p-value &lt; 0.05)\ncette relation est positive (r &gt; 0 )\ncette relation a un pouvoir explicatif moyen (r2 = 45%)\n\nMais …\n\nla relation est monotone mais non linéaire car le coefficient de Spearman (-0.90) est beaucoup plus fort que le coefficient de Pearson (-0.68) et également plus significatif"
  },
  {
    "objectID": "12-Régression.html#ajustement-du-modèle",
    "href": "12-Régression.html#ajustement-du-modèle",
    "title": "5  Régression simple",
    "section": "5.3 Ajustement du modèle",
    "text": "5.3 Ajustement du modèle\n\n5.3.1 Hypothèses statistiques\nConditions a priori\n\nX et Y sont deux variables normales (gaussienne)\nil existe une corrélation significative entre X et Y (p&lt; 0.05)\nX explique une part suffisamment forte de Y (r2 &gt; 20% )\nLe nuage de point affiche une forme linéaire\nles points sont répartis de façon régulière le long du nuage de points\nIl n’y a pas de valeurs exceptionnelles susceptibles de perturber le calcul.\n\nOn charge le package car (companion to applied regession).\n\nlibrary(car)\n#&gt; Loading required package: carData\n#&gt; \n#&gt; Attaching package: 'car'\n#&gt; The following object is masked from 'package:dplyr':\n#&gt; \n#&gt;     recode\n#&gt; The following object is masked from 'package:purrr':\n#&gt; \n#&gt;     some\n\nMéthode des moindres carrés ordinaire (MCO)\n\nLa droite \\(y_i = a.x_i + b + \\epsilon_i\\) qui minimise la somme des carrés des écarts entre les valeurs observées \\(y_i\\) et les valeurs estimées \\(\\hat{y_i}\\) a pour équation :\n\\(COV(X,Y) = \\sum_{i=1}^k \\sum_{j=1}^k (x_{i}-\\bar{x})^2.(y_{i}-\\bar{y})^2\\)\n\\(a = COV(X,Y) / (\\sigma_X)^2\\)\n\\(b = \\bar{y} - a.\\bar{x}\\)\n\nAnalyse de la variance\n\nLa somme des carré des écarts totale (\\(SCE_{tot}\\)) correspond à la variance de la variable à expliquer : \\(SCE_{tot} = \\sum_{i=1}^k (y_{i}-\\bar{y})^2\\)\nLa somme des carré des écarts résiduels (\\(SCE_{err}\\)) correspond à la somme des carrés des différences entre valeurs observées et estimées \\(SCE_{error} = \\sum_{i=1}^k (y_{i}-\\hat{y})^2\\)\nLe pouvoir explicatif d’un modèle de régression correspond à la part de la variance de Y expliquée par X.\n\\(Var. expliquée = (SCE_{tot}-SCE_{res}) / SCE_{tot} = r(X,Y)^{2}\\)\n\nVérifications a posteriori\nUn modèle de régression n’est valide que si les résidus de ce modèle \\(\\epsilon_i = (y_i - \\hat{y}_i)\\) remplissent les conditions suivantes :\n\nNormalité de la distribution des résidus\nAbsence d’autocorrélation des résidus\nHomogénéité de la variance des résidus\nAbsence de valeur à fort effet de levier\n\nSi ces quatre conditions ne sont pas remplies, les estimations de Y en fonction de X seront entâchées d’erreur et leur intervalle de confiance ne sera pas valable.\n\n\n5.3.2 La fonction lm()\nLa fonction lm() ou lm est l’abbréviation de linear model permet d’effectuer la plupart des modèles de régression linéaire basés sur la méthode des moindres carrés ordinaire. Sa syntaxe est a priori très simple et renvoie les coefficients b et a du modèle de régression.\n\nlm(eur$Y~eur$X)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = eur$Y ~ eur$X)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)        eur$X  \n#&gt;   20.890709    -0.001042\n\nMais en réalité lm() crée une liste de résultats que l’on a intérêt à stocker pour en examiner les composantes une à une.\n\nmonmodel&lt;-lm(eur$Y~eur$X)\nstr(monmodel)\n#&gt; List of 12\n#&gt;  $ coefficients : Named num [1:2] 20.89071 -0.00104\n#&gt;   ..- attr(*, \"names\")= chr [1:2] \"(Intercept)\" \"eur$X\"\n#&gt;  $ residuals    : Named num [1:25] 22.73 -0.17 -1.6 -4.31 4.46 ...\n#&gt;   ..- attr(*, \"names\")= chr [1:25] \"1\" \"2\" \"3\" \"4\" ...\n#&gt;  $ effects      : Named num [1:25] -64.96 26.96 -5.02 -8.69 2.2 ...\n#&gt;   ..- attr(*, \"names\")= chr [1:25] \"(Intercept)\" \"eur$X\" \"\" \"\" ...\n#&gt;  $ rank         : int 2\n#&gt;  $ fitted.values: Named num [1:25] 20.27 10.47 11.3 18.81 2.34 ...\n#&gt;   ..- attr(*, \"names\")= chr [1:25] \"1\" \"2\" \"3\" \"4\" ...\n#&gt;  $ assign       : int [1:2] 0 1\n#&gt;  $ qr           :List of 5\n#&gt;   ..$ qr   : num [1:25, 1:2] -5 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 ...\n#&gt;   .. ..- attr(*, \"dimnames\")=List of 2\n#&gt;   .. .. ..$ : chr [1:25] \"1\" \"2\" \"3\" \"4\" ...\n#&gt;   .. .. ..$ : chr [1:2] \"(Intercept)\" \"eur$X\"\n#&gt;   .. ..- attr(*, \"assign\")= int [1:2] 0 1\n#&gt;   ..$ qraux: num [1:2] 1.2 1.14\n#&gt;   ..$ pivot: int [1:2] 1 2\n#&gt;   ..$ tol  : num 0.0000001\n#&gt;   ..$ rank : int 2\n#&gt;   ..- attr(*, \"class\")= chr \"qr\"\n#&gt;  $ df.residual  : int 23\n#&gt;  $ xlevels      : Named list()\n#&gt;  $ call         : language lm(formula = eur$Y ~ eur$X)\n#&gt;  $ terms        :Classes 'terms', 'formula'  language eur$Y ~ eur$X\n#&gt;   .. ..- attr(*, \"variables\")= language list(eur$Y, eur$X)\n#&gt;   .. ..- attr(*, \"factors\")= int [1:2, 1] 0 1\n#&gt;   .. .. ..- attr(*, \"dimnames\")=List of 2\n#&gt;   .. .. .. ..$ : chr [1:2] \"eur$Y\" \"eur$X\"\n#&gt;   .. .. .. ..$ : chr \"eur$X\"\n#&gt;   .. ..- attr(*, \"term.labels\")= chr \"eur$X\"\n#&gt;   .. ..- attr(*, \"order\")= int 1\n#&gt;   .. ..- attr(*, \"intercept\")= int 1\n#&gt;   .. ..- attr(*, \"response\")= int 1\n#&gt;   .. ..- attr(*, \".Environment\")=&lt;environment: R_GlobalEnv&gt; \n#&gt;   .. ..- attr(*, \"predvars\")= language list(eur$Y, eur$X)\n#&gt;   .. ..- attr(*, \"dataClasses\")= Named chr [1:2] \"numeric\" \"numeric\"\n#&gt;   .. .. ..- attr(*, \"names\")= chr [1:2] \"eur$Y\" \"eur$X\"\n#&gt;  $ model        :'data.frame':   25 obs. of  2 variables:\n#&gt;   ..$ eur$Y: num [1:25] 43 10.3 9.7 14.5 6.8 13.9 9.2 8.6 8.4 9 ...\n#&gt;   ..$ eur$X: num [1:25] 600 10000 9200 2000 17800 3200 3700 12000 12600 4800 ...\n#&gt;   ..- attr(*, \"terms\")=Classes 'terms', 'formula'  language eur$Y ~ eur$X\n#&gt;   .. .. ..- attr(*, \"variables\")= language list(eur$Y, eur$X)\n#&gt;   .. .. ..- attr(*, \"factors\")= int [1:2, 1] 0 1\n#&gt;   .. .. .. ..- attr(*, \"dimnames\")=List of 2\n#&gt;   .. .. .. .. ..$ : chr [1:2] \"eur$Y\" \"eur$X\"\n#&gt;   .. .. .. .. ..$ : chr \"eur$X\"\n#&gt;   .. .. ..- attr(*, \"term.labels\")= chr \"eur$X\"\n#&gt;   .. .. ..- attr(*, \"order\")= int 1\n#&gt;   .. .. ..- attr(*, \"intercept\")= int 1\n#&gt;   .. .. ..- attr(*, \"response\")= int 1\n#&gt;   .. .. ..- attr(*, \".Environment\")=&lt;environment: R_GlobalEnv&gt; \n#&gt;   .. .. ..- attr(*, \"predvars\")= language list(eur$Y, eur$X)\n#&gt;   .. .. ..- attr(*, \"dataClasses\")= Named chr [1:2] \"numeric\" \"numeric\"\n#&gt;   .. .. .. ..- attr(*, \"names\")= chr [1:2] \"eur$Y\" \"eur$X\"\n#&gt;  - attr(*, \"class\")= chr \"lm\"\n\nUn résumé des résultats principaux est fourni avec summary() appliqué à l’objet créé par lm().\n\nsummary(monmodel)\n\nOn obtient ainsi :\n\nl’équation de la droite Y = a.X+b\nla significativité et l’intervalle de confiance de a et b\nle pouvoir explicatif du modèle \\(r(X,Y)^2\\)\n\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = eur$Y ~ eur$X)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -7.8351 -2.7982 -1.6039  0.6391 22.7345 \n#&gt; \n#&gt; Coefficients:\n#&gt;               Estimate Std. Error t value      Pr(&gt;|t|)    \n#&gt; (Intercept) 20.8907087  2.2796125   9.164 0.00000000386 ***\n#&gt; eur$X       -0.0010420  0.0002484  -4.196      0.000346 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 6.427 on 23 degrees of freedom\n#&gt; Multiple R-squared:  0.4335, Adjusted R-squared:  0.4089 \n#&gt; F-statistic:  17.6 on 1 and 23 DF,  p-value: 0.0003459\n\nOn peut également analyser plus en détail la variance en appliquant anova() à l’objet créé par lm() ce qui monte la quantité de variance expliquée par X et la quantité de variance résiduelle. Le test de Fisher (Pr&gt;F) détermine si le modèle est significatif et renvoie la même valeur que la p-value du coeff. de corrélation.\n\nanova(monmodel)\n#&gt; Analysis of Variance Table\n#&gt; \n#&gt; Response: eur$Y\n#&gt;           Df Sum Sq Mean Sq F value    Pr(&gt;F)    \n#&gt; eur$X      1 727.09  727.09  17.602 0.0003459 ***\n#&gt; Residuals 23 950.05   41.31                      \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nOn peut extraire de l’objet créé par lm() les valeurs estimées de Y et les résidus c’est-à-dire les erreurs d’estimation.\n\neur$Y_estim&lt;-monmodel$fitted.values\neur$Y_resid&lt;-monmodel$residuals\nhead(eur)\n#&gt;   PAYS        BLOC     X    Y  Y_estim    Y_resid\n#&gt; 1  ALB  Socialiste   600 43.0 20.26548 22.7345189\n#&gt; 2  AUT Capitaliste 10000 10.3 10.47025 -0.1702487\n#&gt; 3  BEL Capitaliste  9200  9.7 11.30389 -1.6038855\n#&gt; 4  BGR  Socialiste  2000 14.5 18.80662 -4.3066167\n#&gt; 5  CHE Capitaliste 17800  6.8  2.34229  4.4577101\n#&gt; 6  CSK  Socialiste  3200 13.9 17.55616 -3.6561615\n\nOn peut tracer la droite de régression avec abline()\n\nmonplot(eur$X,eur$Y,eur$PAYS)\nabline(monmodel, col=\"blue\",lwd=2)\n\n\n\n\nOn peut enfin analyser a posteriori la qualité de la régression avec plot().\n\npar(mfrow=c(2,2))\nplot(monmodel,labels.id = eur$PAYS)"
  },
  {
    "objectID": "12-Régression.html#diagnostics-du-modèle",
    "href": "12-Régression.html#diagnostics-du-modèle",
    "title": "5  Régression simple",
    "section": "5.4 Diagnostics du modèle",
    "text": "5.4 Diagnostics du modèle\n\n5.4.1 Diagnostic 1 : Indépendance des résidus ?\nL’objectif est de savoir si les résidus se répartissent régulièrement de part et d’autre de la droite de régression tout au long de celle-ci. Si c’est bien le cas le graphique residuals Vs Fitted généré par plot(monmodel,1) devrait donner une droite horizontale :\n\nplot(monmodel,1,labels.id = eur$PAYS)\n\n\n\n\nOn peut tester statistiquement l’indépendance des résidus à l’aide du test de Durbin-Watson qui mesure si deux valeurs successives ont des résidus proches. L’indépendance des résidus est rejetée si p-value &lt; 0.05\n\ndurbinWatsonTest(monmodel)\n#&gt;  lag Autocorrelation D-W Statistic p-value\n#&gt;    1     -0.03883526      1.455678    0.15\n#&gt;  Alternative hypothesis: rho != 0\n\nIci on trouve p-value &gt; 0.05 donc les résidus sont indépendants.\n\n\n5.4.2 Diagnostic 2 : Normalité des résidus ?\nL’objectif est de savoir si les résidus ont une distribution normale Si c’est bien le cas le graphique généré par plot(monmodel,2) devrait donner une droite oblique :\n\nplot(monmodel,2,labels.id = eur$PAYS)\n\n\n\n\nOn peut tester statistiquement la normalité des résidus à l’aide du test de Shapiro-Wilk. Les résidus sont normaux si p-value &gt; 0.05\n\nshapiro.test(monmodel$residuals)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  monmodel$residuals\n#&gt; W = 0.81605, p-value = 0.0004263\n\nIci on trouve une p-value très clairement inférieure à 0.05 donc la distribution des résidus n’est pas gaussienne.\n\n\n5.4.3 Diagnostic 3 : Homogénéité des résidus ?\nL’objectif est de savoir si la variance des résidus est constante, c’est-à-dire si il s’écarte environ de la même distance tout au long de la droite . Si c’est bien le cas le graphique généré par plot(monmodel,3) devrait donner une droite horizontale\n\nplot(monmodel,3,labels.id = eur$PAYS)\n\n\n\n\nOn peut tester statistiquement l’homogénéité des résidus à l’aide du test de Breush-Pagan. L’hypothèse d’homogénéité est rejetée si la p-value est inférieure à 0.05.\n\nncvTest(monmodel)\n#&gt; Non-constant Variance Score Test \n#&gt; Variance formula: ~ fitted.values \n#&gt; Chisquare = 9.429701, Df = 1, p = 0.002135\n\nIci, la p-value est inférieure à 0.05 donc les résidus ne sont pas homogènes.\n\n\n5.4.4 Diagnostic 4 : Absence de valeur exceptionnelles ?\nL’objectif est de savoir s’il existe des valeurs qui exercent une influence exceptionnelle sur les résultats de la régression. On peut reprérer ces valeurs de plusieurs manières, notamment à l’aide de la distance de Cook générée par plot(monmodel,4).O n repère le cas particulier de l’Albanie :\n\nplot(monmodel,4,labels.id = eur$PAYS)\n\n\n\n\nLe test statistique de Bonferroni permet de déterminer s’il existe des valeurs exceptionnelles avec une p-value &lt; 0.05.\n\noutlierTest(monmodel, labels = eur$PAYS)\n#&gt;     rstudent unadjusted p-value Bonferroni p\n#&gt; ALB 5.905381       0.0000060791   0.00015198\n\nIci, on doit conclure qu’il existe au moins une valeur exceptionnelle, l’Albanie, susceptible de fausser les conclusions du modèle de régression."
  },
  {
    "objectID": "12-Régression.html#améliorations-du-modèle",
    "href": "12-Régression.html#améliorations-du-modèle",
    "title": "5  Régression simple",
    "section": "5.5 Améliorations du modèle",
    "text": "5.5 Améliorations du modèle\n\n5.5.1 Modèle linéaire (R2 = 46%)\n\nscatterplot(eur$X,eur$Y, ellipse = T,smooth = F,pch=19)\ntext(eur$X,eur$Y, eur$PAYS, col=\"red\",pos=2,cex=0.6)\n\n\n\n\n\n\n5.5.2 Modèle linéaire sans l’Albanie (R2 = 53%)\n\neur2&lt;-eur[eur$PAYS !=\"ALB\",]\nscatterplot(eur2$X,eur2$Y, ellipse = T,smooth = F,pch=19)\ntext(eur2$X,eur2$Y, eur2$PAYS, col=\"red\",pos=2,cex=0.6)\n\n\n\n\n\n\n5.5.3 Modèle exponentiel (R2 = 63%)\n\nscatterplot(eur$X,log(eur$Y), ellipse = T,smooth = F,  pch=19)\ntext(eur$X,log(eur$Y), eur$PAYS, col=\"red\",pos=2,cex=0.6)\n\n\n\n\n\n\n5.5.4 Modèle puissance (R2 = 83%)\n\nscatterplot(log(eur$X),log(eur$Y), ellipse = T,smooth = F,  pch=19)\ntext(log(eur$X),log(eur$Y), eur$PAYS, col=\"red\",pos=2,cex=0.6)"
  },
  {
    "objectID": "13-Anova.html#préparation-des-données",
    "href": "13-Anova.html#préparation-des-données",
    "title": "6  Analyse de variance",
    "section": "6.1 Préparation des données",
    "text": "6.1 Préparation des données\n\n6.1.1 Chargement du fichier\nOn charge un fichier statistique appelé tips.csv où les séparateurs sont des points-virgules et les décimales des points.\n\ndon&lt;-read.table(file = \"resources/data/tips/tips.csv\",\n                sep = \";\",\n                header = T)\nhead(don)\n\n  IDEN TOTBILL  TIP SEX SMOKER DAY TIME SIZE\n1 R001   16.99 1.01   1      0   6    1    2\n2 R002   10.34 1.66   0      0   6    1    3\n3 R003   21.01 3.50   0      0   6    1    3\n4 R004   23.68 3.31   0      0   6    1    2\n5 R005   24.59 3.61   1      0   6    1    4\n6 R006   25.29 4.71   0      0   6    1    4\n\n\n\n\n6.1.2 Contenu du fichier\nCe dossier contient les pourboires (tips en anglais, d’où le nom du fichier) d’un serveur dans un restaurant américain aux débuts des années 1990. Le restaurant était dans un centre commercial. Il y avait une zone fumeurs et une zone non fumeurs.Les données indiquent le prix du repas, le pourboire, le sexe de la personne qui a payé et donné le pourboire, si c’était dans la zone fumeurs ou non, le jour où le repas a été pris, si c’était en journée ou en soirée et enfin, le nombre de convives.\nSources : Ces données sont disponibles dans le package R nommé rggobi et sont décrites dans l’ouvrage de Cook et Swayne intitulé Interactive and Dynamic Graphics for Data Analysis. Elles font partie des données d’exemple du livre de Bryant et Smith dont la première édition est parue en 1995 dont le titre est Practical Data Analysis: Case Studies in Business Statistics.\n\n\n6.1.3 Dictionaire des variables\n\nIDEN : identifiant du repas\nTOTBILL : prix du repas (en dollars des années 1990)\nTIP : pourboire (en dollars des années 1990)\nSEX : sexe de la personne qui a payé (0 = Homme, 1 = Femme)\nSMOKER : la personne qui a payé est non-fumeur (O) ou fumeur (1)\nDAY : jour de la semaine (1 = dimanche, 2 = lundi, 3 = mardi, …)\nTIME : repas pris en journée (0) ou le soir (1)\nSIZE : nombre de convives\n\n\n\n6.1.4 Recodage des variables\nLe type de plusieurs variables est incorrect. On transforme les codes numériques en facteur et on recode les niveaux en français :\n\ndon$IDEN&lt;-as.character(don$IDEN)\ndon$SEX&lt;-as.factor(don$SEX)\nlevels(don$SEX)&lt;-c(\"Homme\",\"Femme\")\ndon$SMOKER&lt;-as.factor(don$SMOKER)\nlevels(don$SMOKER)&lt;-c(\"Non fumeur\", \"Fumeur\")\ndon$DAY&lt;-as.factor(don$DAY)\nlevels(don$DAY)&lt;-c(\"Mercredi\",\"Jeudi\",\"Vendredi\",\"Samedi\")\ndon$TIME&lt;-as.factor(don$TIME)\nlevels(don$TIME)&lt;-c(\"Journée\",\"Soirée\")\n\n\n\n6.1.5 Ajout d’une nouvelle variable\nOn crée la variable PCT qui est le rapport entre le pourboire (TIP) et le prix total (TOTBILL) du repas exprimé en pourcentage.\n\ndon$PCT&lt;-100*don$TIP/don$TOTBILL\n\n\n\n6.1.6 Résumé de l’ensemble du tableau\n\nsummary(don)\n\n     IDEN              TOTBILL           TIP            SEX     \n Length:244         Min.   : 3.07   Min.   : 1.000   Homme:157  \n Class :character   1st Qu.:13.35   1st Qu.: 2.000   Femme: 87  \n Mode  :character   Median :17.80   Median : 2.900              \n                    Mean   :19.79   Mean   : 2.998              \n                    3rd Qu.:24.13   3rd Qu.: 3.562              \n                    Max.   :50.81   Max.   :10.000              \n        SMOKER          DAY          TIME          SIZE           PCT        \n Non fumeur:151   Mercredi:62   Journée: 68   Min.   :1.00   Min.   : 3.564  \n Fumeur    : 93   Jeudi   :19   Soirée :176   1st Qu.:2.00   1st Qu.:12.913  \n                  Vendredi:87                 Median :2.00   Median :15.477  \n                  Samedi  :76                 Mean   :2.57   Mean   :16.080  \n                                              3rd Qu.:3.00   3rd Qu.:19.148  \n                                              Max.   :6.00   Max.   :71.034"
  },
  {
    "objectID": "13-Anova.html#rappels-sur-la-régression",
    "href": "13-Anova.html#rappels-sur-la-régression",
    "title": "6  Analyse de variance",
    "section": "6.2 Rappels sur la régression",
    "text": "6.2 Rappels sur la régression\n\n6.2.1 La distribution de PCT est-elle normale ?\n\nhist(don$PCT, breaks = 10,col=\"lightyellow\",probability = TRUE)\nlines(density(don$PCT,bw=3),col=\"red\",lwd=1)\n\n\n\n\nLa distribution semble normale . Mais est-ce l’avis du test de Shapiro ?\n\nshapiro.test(don$PCT)\n\n\n    Shapiro-Wilk normality test\n\ndata:  don$PCT\nW = 0.79943, p-value &lt; 2.2e-16\n\n\nQue nous apprend la boxplot ?\n\nboxplot(don$PCT, col=\"lightyellow\",horizontal = T)\n\n\n\n\nLa distribution devient presque parfaitement gaussienne si on retire les 4 valeurs exceptionnelles !\n\ndon2&lt;-don[don$PCT&lt;30,]\nshapiro.test(don2$PCT)\n\n\n    Shapiro-Wilk normality test\n\ndata:  don2$PCT\nW = 0.99435, p-value = 0.5066\n\n\n\nhist(don2$PCT, breaks = 10,col=\"lightyellow\",probability = TRUE)\nlines(density(don2$PCT,bw=3),col=\"red\",lwd=1)\n\n\n\n\n\n\n6.2.2 Y-a-t-il une relation entre le prix du repas et le pourboire ?\nOn fait le graphique …\n\nplot(don2$TOTBILL,don2$TIP)\n\n\n\n\nPuis on teste le coefficient de Pearson et celui de Sperman\n\ncor.test(don2$TIP,don2$TOTBILL)\n\n\n    Pearson's product-moment correlation\n\ndata:  don2$TIP and don2$TOTBILL\nt = 14.906, df = 239, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.6223204 0.7543075\nsample estimates:\n      cor \n0.6941023 \n\ncor.test(don2$TIP,don2$TOTBILL, method=\"spearman\")\n\nWarning in cor.test.default(don2$TIP, don2$TOTBILL, method = \"spearman\"):\nCannot compute exact p-value with ties\n\n\n\n    Spearman's rank correlation rho\n\ndata:  don2$TIP and don2$TOTBILL\nS = 688482, p-value &lt; 2.2e-16\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.7048791 \n\n\n\n\n6.2.3 Modèle de régression\nOn calcule le modèle de régression\n\nmareg&lt;-lm(don2$TIP~don2$TOTBILL)\n\n\nplot(don2$TOTBILL,don2$TIP, xlab=\"Repas ($)\",ylab = \"Pourboire ($)\",pch=19,cex=0.5)\nabline(mareg,col=\"red\",lwd=1)"
  },
  {
    "objectID": "13-Anova.html#test-dégalité-des-moyennes",
    "href": "13-Anova.html#test-dégalité-des-moyennes",
    "title": "6  Analyse de variance",
    "section": "6.3 Test d’égalité des moyennes",
    "text": "6.3 Test d’égalité des moyennes\n\n6.3.1 Hypothèses\nOn considère une variable Y quantitative continue définie sur une population de réféence P et une variable X qualitative à deux modalités divisant P en deux sous population P1 et P2.\nSoit par exemple la variable Y = PCT et la variable X = SEX. On peut se demander si les femmes sont plus généreuses que les hommes, les hommes sont plus généreux que les femmes, les hommes sont différents des femmes, etc…\n\nY&lt;-don2$PCT\nnomY &lt;-\"Pourboire relatif (%)\"\n\nX&lt;-don2$SEX\nnomX &lt;- \"Sexe du client\"\n\n#X&lt;-don2$SMOKER\n#nomX&lt;- \"Tabagisme\"\n\n#X&lt;-don2$TIME\n#nomX&lt;- \"Moment de la journée\"\n\n\n\n6.3.2 Visualisations\nLe plus simple est d’utiliser boxplot() en version de base …\n\nboxplot(Y~X)\n\n\n\n\n… ou améliorée\n\nboxplot(Y~X,horizontal=T, xlab = nomY, ylab=nomX, col=\"gray80\")\n\n\n\n\nOn peut aussi utiliser le package beanplot() en version simple …\n\nlibrary(beanplot)\nbeanplot(Y~X)\n\n\n\n\n… ou améliorée :\n\nlibrary(beanplot)\nbeanplot(Y~X,horizontal=T, xlab = nomY, ylab=nomX,col = \"gray80\")\n\n\n\n\n\n\n6.3.3 Paramètres principaux\nOn détermine la moyenne et l’écart-type de chaque échantillon avec la fonction tapply() couplée avec les fonctions mean(), sd() ou summary()\n\ntapply(Y,X, mean)\n\n   Homme    Femme \n15.41076 16.16741 \n\ntapply(Y,X,sd)\n\n   Homme    Femme \n4.732686 4.329426 \n\ntapply(Y,X, summary)\n\n$Homme\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  3.564  12.136  15.325  15.411  18.622  29.199 \n\n$Femme\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  5.643  13.999  15.522  16.167  19.284  27.952 \n\n\n\n\n6.3.4 Test d’égalité des moyennes\nSi la distribution est gaussienne on utilise le test de Student :\n\nt.test(Y~X)\n\n\n    Welch Two Sample t-test\n\ndata:  Y by X\nt = -1.254, df = 186.21, p-value = 0.2114\nalternative hypothesis: true difference in means between group Homme and group Femme is not equal to 0\n95 percent confidence interval:\n -1.9470273  0.4337437\nsample estimates:\nmean in group Homme mean in group Femme \n           15.41076            16.16741 \n\n\nSi ce n’est pas le cas et s’il y a des valeurs exceptionnelles on préfèrera le test de Wilcoxon basé sur les rangs des valeurs (comme le coefficient de corrélation de Spearman)\n\nwilcox.test(Y~X)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  Y by X\nW = 5953, p-value = 0.1908\nalternative hypothesis: true location shift is not equal to 0\n\n\nLorsque les deux tests divergent dans leur conclusions, il y a certainement un problème de violation de l’hypothèse gaussienne. Dans ce cas, il faut sans doute transformer Y ou retirer des valeurs exceptionnelles (Cf.cours sur la corrélation et la régression)"
  },
  {
    "objectID": "13-Anova.html#analyse-de-variance",
    "href": "13-Anova.html#analyse-de-variance",
    "title": "6  Analyse de variance",
    "section": "6.4 Analyse de variance",
    "text": "6.4 Analyse de variance\n\n6.4.1 Hypothèses\nOn considère une variable Y quantitative continue définie sur une population de réféence P et une variable X qualitative à k modalités divisant P en k sous population P1…Pk.\nSoit par exemple la variable Y = PCT et la variable X = DAY. On peut se demander si la générosité des pourboires varie en fonction des jours de la semaine (mercredi, jeudi, vendredi ou samedi). On fera toutefois attention au fait que l’échantillon n’est pas très équilibré\n\ntable(don2$DAY)\n\n\nMercredi    Jeudi Vendredi   Samedi \n      62       19       86       74 \n\n\n\n\n6.4.2 Calcul des paramètres principaux\nOn va calculer les paramètres principaux de chacune des quatre sous population à l’aide de la superfonction tapply() dont la syntaxe est la suivante\ntapply(variable à analyser, variable de partition , function)\nLa fonction tapply() s’applique sur les tableaux (data.frame). Il y a des fonctions équvalentes pour les listes, les matrices, etc…\n\nmoy&lt;-tapply(X = don2$PCT, INDEX = don2$DAY, FUN = mean)\nmoy\n\nMercredi    Jeudi Vendredi   Samedi \n16.12756 16.99130 15.11450 15.61781 \n\nect&lt;-tapply(don2$PCT, don2$DAY, sd)\nect\n\nMercredi    Jeudi Vendredi   Samedi \n3.865182 4.766531 4.803544 4.858665 \n\n100*ect/moy\n\nMercredi    Jeudi Vendredi   Samedi \n23.96631 28.05277 31.78104 31.10976 \n\n\n\ntapply(don2$PCT, don2$DAY, summary)\n\n$Mercredi\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  7.296  13.821  15.385  16.128  19.269  26.631 \n\n$Jeudi\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  10.36   13.37   15.56   16.99   19.66   26.35 \n\n$Vendredi\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  3.564  12.373  15.099  15.114  18.767  29.199 \n\n$Samedi\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  5.945  11.737  15.965  15.618  18.494  28.054 \n\n\n\n\n6.4.3 Visualisation\nOn utilise comme précédemment boxplot() :\n\nboxplot(don2$PCT~don2$DAY, col=\"gray80\")\n\n\n\n\nOu bien beanplot() :\n\nlibrary(beanplot)\nbeanplot(don2$PCT~don2$DAY,col = \"gray80\")\n\n\n\n\n\n\n6.4.4 Modélisation simple\nLa solution la plus simple est d’utiliser la fonction lm() que l’on a déjà vu pour la régression.\n\nmonmodel&lt;-lm(don2$PCT~don2$DAY)\nsummary(monmodel)\n\n\nCall:\nlm(formula = don2$PCT ~ don2$DAY)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.5507  -2.7549  -0.1519   3.2335  14.0845 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       16.1276     0.5836  27.634   &lt;2e-16 ***\ndon2$DAYJeudi      0.8637     1.2050   0.717    0.474    \ndon2$DAYVendredi  -1.0131     0.7656  -1.323    0.187    \ndon2$DAYSamedi    -0.5097     0.7912  -0.644    0.520    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.595 on 237 degrees of freedom\nMultiple R-squared:  0.01435,   Adjusted R-squared:  0.001876 \nF-statistic:  1.15 on 3 and 237 DF,  p-value: 0.3295\n\n\nOn peut ensuite appliquer une analyse de variance avec anova() sur le modèle pour mesurer la variance totale et la variance résiduelle ainsi que la significativité de la relation.\n\nanova(monmodel)\n\nAnalysis of Variance Table\n\nResponse: don2$PCT\n           Df Sum Sq Mean Sq F value Pr(&gt;F)\ndon2$DAY    3   72.9  24.293  1.1503 0.3295\nResiduals 237 5004.9  21.117               \n\n\nEt on peut effectuer quelques diagnostics sur les résidus :\n\npar(mfrow = c(2,2))\nplot(monmodel,c(1,2,3,4))\n\n\n\n\n\n\n6.4.5 Modélisation avancée\nD’un point de vue statistique, l’analyse de variance à un facteur fait appel à des modèles et des hhypothèses plus sophistiqués que le modèle de base présenté ici et comporte de nombreux tests. On se reportera donc ave profit aux trois cours en lignes de Claire Della Vedova pour une approche plus poussée\nhttps://statistique-et-logiciel-r.com/anova-a-un-facteur-partie-1/\nhttps://statistique-et-logiciel-r.com/anova-a-un-facteur-partie-2-la-pratique/\nhttps://statistique-et-logiciel-r.com/anova-a-un-facteur-quand-les-hypotheses-ne-sont-pas-satisfaites/"
  },
  {
    "objectID": "13-Anova.html#annexe-les-variables-hybrides",
    "href": "13-Anova.html#annexe-les-variables-hybrides",
    "title": "6  Analyse de variance",
    "section": "6.5 Annexe : les variables hybrides",
    "text": "6.5 Annexe : les variables hybrides\nLe nombre de convives (SIZE) n’est ni une variable quantitative continue, ni une variable qualitative de type catégorielle. On peut donc l’appréhender de deux points de vue différents sur le plan statistique\n\nvariable quantitative discrète : ce qui permet d’utiliser un modèle de régression linéaire.\nvariable qualitative ordinale : ce qui permet d’utiliser un modèle d’analyse de variance.\n\n\n6.5.1 SIZE = quantitative discrète\n\nhist(don$SIZE, breaks=6, col=\"gray80\")\n\n\n\n\n\nmodreg&lt;-lm(don2$PCT~don2$SIZE)\nsummary(modreg)\n\n\nCall:\nlm(formula = don2$PCT ~ don2$SIZE)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12.4591  -2.9738  -0.2625   3.4693  13.2193 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  17.2116     0.8545  20.143   &lt;2e-16 ***\ndon2$SIZE    -0.5944     0.3108  -1.913    0.057 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.574 on 239 degrees of freedom\nMultiple R-squared:  0.01507,   Adjusted R-squared:  0.01095 \nF-statistic: 3.658 on 1 and 239 DF,  p-value: 0.057\n\n\n\nplot(don2$SIZE,don2$PCT, col=\"blue\", pch=19, cex=0.7)\nabline(modreg, col=\"red\")\n\n\n\n\n\n\n6.5.2 SIZE = qualitative ordinale\nOn recode les catégories trop rares …\n\ndon2$SIZE2&lt;-as.factor(don2$SIZE)\nlevels(don2$SIZE2)&lt;-c(\"1-2\",\"1-2\",\"3+\",\"3+\",\"3+\",\"3+\")\nsummary(don2$SIZE2)\n\n1-2  3+ \n157  84 \n\nplot(don2$SIZE2)\n\n\n\n\n\ntapply(don2$PCT, don2$SIZE2, mean)\n\n     1-2       3+ \n16.09466 14.89818 \n\ntapply(don2$PCT, don2$SIZE2, sd)\n\n     1-2       3+ \n4.626275 4.472961 \n\n\n\nbeanplot(don2$PCT~don2$SIZE2)\n\n\n\n\n\nmodvar&lt;-lm(don2$PCT~don2$SIZE2)\nsummary(modvar)\n\n\nCall:\nlm(formula = don2$PCT ~ don2$SIZE2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12.5308  -2.7696  -0.3176   3.4082  13.1553 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   16.0947     0.3650  44.093   &lt;2e-16 ***\ndon2$SIZE23+  -1.1965     0.6183  -1.935   0.0541 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.574 on 239 degrees of freedom\nMultiple R-squared:  0.01543,   Adjusted R-squared:  0.01131 \nF-statistic: 3.745 on 1 and 239 DF,  p-value: 0.05414"
  },
  {
    "objectID": "21-Tabcont.html#introduction",
    "href": "21-Tabcont.html#introduction",
    "title": "7  Tableau de contingence",
    "section": "7.1 Introduction",
    "text": "7.1 Introduction\nOn propose ici une démarche simplifiée de l’analyse d’enquête utilisant les fonctions R-base et quelques fonctions supplémentaires issues du package questionR qui permettent de simplifier l’écriture des programmes. Les explications détaillées se trouvent dans le très beau site web analyse-R auquel ont notamment contribué Julien Barnier et Joseph Larmarange.\nhttps://larmarange.github.io/analyse-R/\nce programme suffit pour des analyses simples de questionnaires. Mais pour des analyses plus avancées, il faudra utiliser des packages plus avancés comme survey."
  },
  {
    "objectID": "21-Tabcont.html#préparation-des-données",
    "href": "21-Tabcont.html#préparation-des-données",
    "title": "7  Tableau de contingence",
    "section": "7.2 Préparation des données",
    "text": "7.2 Préparation des données\n\n7.2.1 Importation du fichier au format .RDS\n\ndon&lt;-readRDS(\"resources/data/pew/Pew_2007_2017.Rdata\")\nstr(don)\n\ntibble [62,060 × 10] (S3: tbl_df/tbl/data.frame)\n $ survey      : Factor w/ 2 levels \"Spring2007\",\"Spring2017\": 1 1 1 1 1 1 1 1 1 1 ...\n $ country     : Factor w/ 30 levels \"Argentina\",\"Brazil\",..: 5 5 5 5 5 5 5 5 5 5 ...\n $ sex         : Factor w/ 2 levels \"Male\",\"Female\": 1 2 1 1 2 1 1 1 1 2 ...\n $ age         : num [1:62060] 50 79 43 74 78 36 42 61 21 41 ...\n $ today       : Factor w/ 5 levels \"1.Typical\",\"2.Particularly good\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ use_internet: Factor w/ 4 levels \"1.Yes\",\"2.No\",..: 1 2 1 2 2 1 1 2 1 1 ...\n $ opi_USA     : Factor w/ 6 levels \"1.Very favorable\",..: 3 2 3 1 2 1 2 2 2 2 ...\n $ opi_CHN     : Factor w/ 6 levels \"1.Very favorable\",..: 3 2 3 3 3 2 2 3 2 2 ...\n $ opi_RUS     : Factor w/ 6 levels \"1.Very favorable\",..: 3 2 2 3 3 2 2 3 3 2 ...\n $ weight      : num [1:62060] 1.009 0.954 0.996 0.989 0.982 ...\n  ..- attr(*, \"label\")= chr \"Weighting factor\"\n  ..- attr(*, \"format.spss\")= chr \"F9.6\"\n  ..- attr(*, \"display_width\")= int 10\n\n\n\n\n7.2.2 (simplifiée) des variables\nLes données sont issues de deux vagues de la Global attitude Survey réalisée par le Pew Research Center en 2007 et 2017. Nous avons conservé uniquement des variables communes aux deux enquêtes et posées de façon identique.\n\nsurvey : date d’enquête (2007 ou 2017)\ncountry : lieu d’enquête (pays présents aux deux dates)\nsex : sexe de l’individu\nage : âge de l’individu\n\ntoday : état d’esprit du jour (typique, très bon, très mauvais)\nuse_internet: usage d’internet\nopi_USA : opinion sur les USA\nopi_CHN : opinion sur la Chine\nopi_RUS : opinion sur la Russie\nweight : poids de l’individu pour les redressements\n\n\n\n7.2.3 Résumé des variables (tri à plat)\n\nsummary(don)\n\n        survey               country          sex             age       \n Spring2007:28061   India        : 4499   Male  :30125   Min.   :18.00  \n Spring2017:33999   United States: 3472   Female:31935   1st Qu.:28.00  \n                    Lebanon      : 2552                  Median :40.00  \n                    Jordan       : 2548                  Mean   :42.59  \n                    South Africa : 2295                  3rd Qu.:55.00  \n                    Nigeria      : 2202                  Max.   :97.00  \n                    (Other)      :44492                                 \n                 today             use_internet  \n 1.Typical          :36554   1.Yes       :32385  \n 2.Particularly good:20216   2.No        :25892  \n 3.Particularly bad : 4775   3.Don't know:  232  \n 4.Don't know       :  419   4.Refused   :   69  \n 5.Refused          :   96   NA's        : 3482  \n                                                 \n                                                 \n                   opi_USA                        opi_CHN     \n 1.Very favorable      :10081   1.Very favorable      : 8002  \n 2.Somewhat favorable  :21725   2.Somewhat favorable  :21860  \n 3.Somewhat unfavorable:14502   3.Somewhat unfavorable:15097  \n 4.Very unfavorable    :10629   4.Very unfavorable    : 8402  \n 5.Don't know          : 4718   5.Don't know          : 8183  \n 6.Refused             :  405   6.Refused             :  516  \n                                                              \n                   opi_RUS          weight        \n 1.Very favorable      : 5650   Min.   : 0.02301  \n 2.Somewhat favorable  :18105   1st Qu.: 0.65138  \n 3.Somewhat unfavorable:16806   Median : 1.00000  \n 4.Very unfavorable    :10144   Mean   : 1.00032  \n 5.Don't know          :10719   3rd Qu.: 1.11834  \n 6.Refused             :  636   Max.   :18.74950  \n                                                  \n\n\n\n\n7.2.4 Tailles des échantillons par pays et par date\nOn examine la taille des échantillons collectés dans les différents pays\n\ntable(don$country,don$survey)\n\n                \n                 Spring2007 Spring2017\n  Argentina             800       1012\n  Brazil               1000       1007\n  Canada                982       1000\n  Chile                 800        987\n  France               1004        996\n  Germany              1000        995\n  Ghana                 707       1129\n  India                2040       2459\n  Indonesia             995        996\n  Israel                887       1050\n  Italy                 501        899\n  Japan                 762       1009\n  Jordan               1000       1548\n  Kenya                 997       1117\n  Lebanon              1000       1552\n  Mexico                828       1000\n  Nigeria              1092       1110\n  Peru                  800        998\n  Poland                504       1142\n  Russia                991       1002\n  Senegal               700       1083\n  South Africa         1000       1295\n  South Korea           718       1010\n  Spain                 500        995\n  Sweden                996        996\n  Tanzania              702       1061\n  Turkey                971       1050\n  United Kingdom        982       1028\n  United States        1999       1473\n  Venezuela             803       1000\n\n\n\n\n7.2.5 Sélection d’un échantillon\nOn décide par exemple d’analyser l’échantillon des réponses françaises en 2017 :\n\nfra17&lt;-don[don$country ==\"France\" & don$survey==\"Spring2017\",]\nsource &lt;- \"Source : Pew Research Center, Global Attitude Survey, 2017, France\"\nsummary(fra17)\n\n        survey         country        sex           age       \n Spring2007:  0   France   :996   Male  :502   Min.   :18.00  \n Spring2017:996   Argentina:  0   Female:494   1st Qu.:40.00  \n                  Brazil   :  0                Median :54.00  \n                  Canada   :  0                Mean   :52.55  \n                  Chile    :  0                3rd Qu.:66.00  \n                  Germany  :  0                Max.   :94.00  \n                  (Other)  :  0                               \n                 today           use_internet                   opi_USA   \n 1.Typical          :685   1.Yes       :868   1.Very favorable      : 45  \n 2.Particularly good:245   2.No        :127   2.Somewhat favorable  :383  \n 3.Particularly bad : 54   3.Don't know:  1   3.Somewhat unfavorable:353  \n 4.Don't know       : 12   4.Refused   :  0   4.Very unfavorable    :190  \n 5.Refused          :  0                      5.Don't know          : 25  \n                                              6.Refused             :  0  \n                                                                          \n                   opi_CHN                      opi_RUS        weight      \n 1.Very favorable      : 47   1.Very favorable      : 40   Min.   :0.1830  \n 2.Somewhat favorable  :360   2.Somewhat favorable  :309   1st Qu.:0.3459  \n 3.Somewhat unfavorable:381   3.Somewhat unfavorable:385   Median :0.6281  \n 4.Very unfavorable    :168   4.Very unfavorable    :241   Mean   :0.9987  \n 5.Don't know          : 40   5.Don't know          : 21   3rd Qu.:1.1900  \n 6.Refused             :  0   6.Refused             :  0   Max.   :4.1079  \n                                                                           \n\n\n\n\n7.2.6 Recodage des modalités\nSi l’on souhaite rendre un rapport en français, on va recoder les modalités des variables qui nous intéressent et en profiter pour déclarer manquantes les valeurs correspondant à des non-réponses ou des refus de répondre.\n\nlevels(fra17$sex)&lt;-c(\"Homme\",\"Femme\")\nlevels(fra17$today)&lt;-c(\"Typique\",\"Très Bon\",\"Très Mauvais\",NA,NA)\nlevels(fra17$use_internet)&lt;-c(\"Oui\",\"Non\",NA,NA)\nlevels(fra17$opi_USA)&lt;-c(\"Trés Fav.\",\"Fav.\",\"Défav.\",\"Très Déf.\",NA,NA)\nlevels(fra17$opi_RUS)&lt;-c(\"Trés Fav.\",\"Fav.\",\"Défav.\",\"Très Déf.\",NA,NA)\nlevels(fra17$opi_CHN)&lt;-c(\"Trés Fav.\",\"Fav.\",\"Défav.\",\"Très Déf.\",NA,NA)\n\n\n\n7.2.7 Découpage de variables quantitatives en classes\nOn peut transformer la variable quantitative âge en variable qualitative (factor) à l’aide de la fonction cut(). La question va évidemment être de décider :\n\ncombien on fait de classes ?\nselon quels seuils ?\navec quels noms ?\n\nOn peut décider de créer cinq classesd’âge à l’aide des quintiles de la distribution :\n\nfra17$age5&lt;-cut(fra17$age, breaks = quantile(fra17$age,c(0,0.2,0.4,0.6,0.8, 1)), include.lowest = T)\nlevels(fra17$age5) &lt;-c(\"18-36 ans\",\"37-49 ans\",\"50-59 ans\",\"60-68 ans\",\"69-94-ans\")\n\nMais on peut aussi décider qu’on veut travailler sur les générations en choisissant les dates de 1949, 1969 et 1989\n\nfra17$gen&lt;-2017-fra17$age\nfra17$gen4&lt;-cut(fra17$gen, breaks=c(min(fra17$gen), 1949, 1969, 1989, max(fra17$gen)), include.lowest = T)\nlevels(fra17$gen4)&lt;-c(\" 1950&lt; \",\"1950-69\",\"1970-89\",\"&gt; 1990\")\n\n\n\n7.2.8 Sélection\nOn ne garde que les variable qui nous intéressent pour l’analyse.\n\nsel&lt;-fra17[,c(\"sex\",\"age5\",\"gen4\",\"opi_USA\",\"weight\")]\nsummary(sel)\n\n    sex             age5          gen4          opi_USA        weight      \n Homme:502   18-36 ans:212    1950&lt; :218   Trés Fav.: 45   Min.   :0.1830  \n Femme:494   37-49 ans:187   1950-69:407   Fav.     :383   1st Qu.:0.3459  \n             50-59 ans:199   1970-89:264   Défav.   :353   Median :0.6281  \n             60-68 ans:203   &gt; 1990 :107   Très Déf.:190   Mean   :0.9987  \n             69-94-ans:195                 NA's     : 25   3rd Qu.:1.1900  \n                                                           Max.   :4.1079"
  },
  {
    "objectID": "21-Tabcont.html#opinion-usa",
    "href": "21-Tabcont.html#opinion-usa",
    "title": "7  Tableau de contingence",
    "section": "7.3 Opinion USA",
    "text": "7.3 Opinion USA\n\n7.3.1 la fonction table()\nLe dénombrement des modalités d’une variable se fait généralement avec la fonction table() qui permet de croiser une ou plusieurs variables. Ci-dessous on donne des exemples de croisement à une, deux ou trois variables\n\nt1&lt;-table(sel$opi_USA)\nkable(t1)\n\n\n\n\nVar1\nFreq\n\n\n\n\nTrés Fav.\n45\n\n\nFav.\n383\n\n\nDéfav.\n353\n\n\nTrès Déf.\n190\n\n\n\n\nt2&lt;-table(sel$opi_USA,sel$sex)\nkable(t2)\n\n\n\n\n\nHomme\nFemme\n\n\n\n\nTrés Fav.\n27\n18\n\n\nFav.\n204\n179\n\n\nDéfav.\n164\n189\n\n\nTrès Déf.\n97\n93\n\n\n\n\nt3&lt;-table(sel$opi_USA,sel$sex,sel$gen4)\nkable(t3)\n\n\n\n\nVar1\nVar2\nVar3\nFreq\n\n\n\n\nTrés Fav.\nHomme\n1950&lt;\n5\n\n\nFav.\nHomme\n1950&lt;\n39\n\n\nDéfav.\nHomme\n1950&lt;\n37\n\n\nTrès Déf.\nHomme\n1950&lt;\n31\n\n\nTrés Fav.\nFemme\n1950&lt;\n2\n\n\nFav.\nFemme\n1950&lt;\n26\n\n\nDéfav.\nFemme\n1950&lt;\n41\n\n\nTrès Déf.\nFemme\n1950&lt;\n31\n\n\nTrés Fav.\nHomme\n1950-69\n9\n\n\nFav.\nHomme\n1950-69\n78\n\n\nDéfav.\nHomme\n1950-69\n71\n\n\nTrès Déf.\nHomme\n1950-69\n33\n\n\nTrés Fav.\nFemme\n1950-69\n7\n\n\nFav.\nFemme\n1950-69\n73\n\n\nDéfav.\nFemme\n1950-69\n82\n\n\nTrès Déf.\nFemme\n1950-69\n43\n\n\nTrés Fav.\nHomme\n1970-89\n7\n\n\nFav.\nHomme\n1970-89\n57\n\n\nDéfav.\nHomme\n1970-89\n40\n\n\nTrès Déf.\nHomme\n1970-89\n25\n\n\nTrés Fav.\nFemme\n1970-89\n6\n\n\nFav.\nFemme\n1970-89\n51\n\n\nDéfav.\nFemme\n1970-89\n55\n\n\nTrès Déf.\nFemme\n1970-89\n15\n\n\nTrés Fav.\nHomme\n&gt; 1990\n6\n\n\nFav.\nHomme\n&gt; 1990\n30\n\n\nDéfav.\nHomme\n&gt; 1990\n16\n\n\nTrès Déf.\nHomme\n&gt; 1990\n8\n\n\nTrés Fav.\nFemme\n&gt; 1990\n3\n\n\nFav.\nFemme\n&gt; 1990\n29\n\n\nDéfav.\nFemme\n&gt; 1990\n11\n\n\nTrès Déf.\nFemme\n&gt; 1990\n4\n\n\n\n\n\n\n\n7.3.2 Visualisation avec plot ou barplot\nLes objets de type table à une ou deux dimensions s’affichent facilement avec barplot()\n\nbarplot(t1, main=\"Opinion sur les USA\")\n\n\n\nbarplot(t2, main = \"Opinion sur les USA et Sexe\")\n\n\n\n\n\n\n7.3.3 Recodage\nOn peut regrouper des modalités entre elle en leur donnant le même nom et en éliminer d’autres en leur donnant la modalité NA.\n\nsel$opi_USA2&lt;-sel$opi_USA\nlevels(sel$opi_USA2)\n\n[1] \"Trés Fav.\" \"Fav.\"      \"Défav.\"    \"Très Déf.\"\n\nlevels(sel$opi_USA2)&lt;-c(\"Favorable\",\"Favorable\",\"Défavorable\",\"Défavorable\",NA,NA)\n\nt&lt;-table(sel$opi_USA2)\nt\n\n\n  Favorable Défavorable \n        428         543 \n\nprop.table(t)\n\n\n  Favorable Défavorable \n  0.4407827   0.5592173 \n\nbarplot(100*t/sum(t))\n\n\n\n\nA ce stade, on a certes établi le fait qu’il y a une proportion plus grande d’opinion défavorables (56%) que favorables (44%) mais il faut établir un intervalle de confiance pour savoir si cela est simplement dû au biais d’écdhantillonage.\n\n\n7.3.4 Calcul de l’intervalle de confiance\nOn va conduire un test pour trancher entre trois possibilités :\n\nopinion majoritairement favorable aux USA\nopinion majoritairement défavorable aux USA\nopinion partagée sans majorité claire\n\nOn se fixe un intervalle de confiance de 95% (risque d’erreur de 5%)\nOn se reportera pour plus de détails à :\nhttps://larmarange.github.io/analyse-R/intervalles-de-confiance.html\n\nprop.test(t)\n\n\n    1-sample proportions test with continuity correction\n\ndata:  t, null probability 0.5\nX-squared = 13.384, df = 1, p-value = 0.0002538\nalternative hypothesis: true p is not equal to 0.5\n95 percent confidence interval:\n 0.4093399 0.4726998\nsample estimates:\n        p \n0.4407827 \n\n\nIl semble donc que l’on puisse conclure que les français sont majoritairement défavorables aux USA puisque la proportion d’opinion favorbales est de 44% avec un intervalle de confiance compris entre 40.9 et 47.3 d’opinion favorable (pour un risque d’erreur p&lt;0.05)\n\n\n7.3.5 Prise en compte de la variable de redressement.\nOn a toutefois oublié de tenir compte de la variable de redressement (poids) qui tient compte du fit que l’échantillonage obtenu comportait des sur et sous-représentations de certaines cétégories de population. Du coup, il faut réécrire l’ensemble du programme en utilisant l’instruction wtd.table du package questionr.\n\nt&lt;-wtd.table(sel$opi_USA2, weights=sel$weight)\nt\n\n  Favorable Défavorable \n   462.4494    510.0442 \n\nprop.table(t)\n\n  Favorable Défavorable \n  0.4755295   0.5244705 \n\nprop.test(t)\n\n\n    1-sample proportions test with continuity correction\n\ndata:  t, null probability 0.5\nX-squared = 2.2325, df = 1, p-value = 0.1351\nalternative hypothesis: true p is not equal to 0.5\n95 percent confidence interval:\n 0.4437896 0.5074651\nsample estimates:\n        p \n0.4755295 \n\n\nOn voit que la proportion d’opinion favorable est plus élevée après redressement (47.6%) ce qui du coup modifie l’intervalle de confiance (44.4% à 50.7%) et ne permet plus d’exclure l’hypothèse que l’opinion favorable soit en fait majoritaire. On concluera donc que L’opinion des français sur les USA en 2017 est partagée."
  },
  {
    "objectID": "21-Tabcont.html#opinion-usa-sexe",
    "href": "21-Tabcont.html#opinion-usa-sexe",
    "title": "7  Tableau de contingence",
    "section": "7.4 Opinion USA / Sexe",
    "text": "7.4 Opinion USA / Sexe\nOn choisit d’analyser la relation entre l’avis sur les USA et le sexe et on pose H0 : il n’y a pas de relation entre les deux variables.\n\n7.4.1 tableau de contingence\nOn commence par recoder les deux variables puis par créer le tableau de contingence pondéré par la variable de pondération. On l’affiche en ajoutant les sommes en ligne et en colonnes avec addmargins()\n\nlevels(sel$sex) &lt;- c(\"Homme\",\"Femme\")\ntabcont&lt;-wtd.table(sel$sex,sel$opi_USA2, weights = sel$weight)\ntabcont\n\n      Favorable Défavorable\nHomme  238.0424    231.8120\nFemme  224.4070    278.2321\n\naddmargins(tabcont)\n\n      Favorable Défavorable      Sum\nHomme  238.0424    231.8120 469.8544\nFemme  224.4070    278.2321 502.6391\nSum    462.4494    510.0442 972.4936\n\n\n\n\n7.4.2 Pourcentages\nOn peut calculer trois tableaux de pourcentage différents à l’aide des fonctions lprop, cprop et prop du package questionr. On se contentera d’afficher le tableau des % en lignes pusique c’est celui qui donne la répartition des avis défavorables eyt favorables pour chaque sexe.\n\nlprop(tabcont)\n\n      Favorable Défavorable Total\nHomme  50.7      49.3       100.0\nFemme  44.6      55.4       100.0\nAll    47.6      52.4       100.0\n\n\n\nCommentaire : On constate que les femmes sont a priori moins favorables aux USA (44.6%) que les hommes (50.7%) mais il est difficile d’affirmer à ce stade que la relation est significative.\n\n\n\n7.4.3 Première visualisation\nOnpeut visualiser notre table avec plot()\n\nplot(tabcont, col=c(\"lightyellow\",\"lightblue\"), \n #    main=titre, \n     sub=source, \n     )\n\n\n\n\n\n\n7.4.4 test du chi-2\nOn réalise le test du chi-2 avec la fonction chisq.test() qui crée un objet complexe qui rappelle celui qui est créé par lm() pour la régression.\n\ntoto&lt;-chisq.test(tabcont)\ntoto\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  tabcont\nX-squared = 3.2885, df = 1, p-value = 0.06977\n\n\nIci, la relation est presque significative (p = 0.07). On ne peut pas rejeter H0 avec un risque d’erreur inférerieur à 5% mais on pourrait le faire pour un risque d’erreur de 10%.\n\n\n7.4.5 Analyse des résidus\nLorsque la relation est significative, l’analyse des résidus permet de voir quelles sont les cases présentent des anomalies significatives. On peut pour cela imprimer quatre tableaux correspondant aux valeurs observées, aux valeurs attendues, aux écarts entre les deux (résidus bruts) et à un test sur les écarts les plus significatifs (résidus standardisés).\nce que l’on peut aussi faire graphiquement\n\nkable(toto$observed,caption = \"Valeurs observées\")\n\n\nValeurs observées\n\n\n\nFavorable\nDéfavorable\n\n\n\n\nHomme\n238.0424\n231.8120\n\n\nFemme\n224.4070\n278.2321\n\n\n\n\nkable(toto$expected,  caption = \"Valeurs attendues\")\n\n\nValeurs attendues\n\n\n\nFavorable\nDéfavorable\n\n\n\n\nHomme\n223.4296\n246.4248\n\n\nFemme\n239.0198\n263.6194\n\n\n\n\nkable(tabcont-toto$expected, caption = \"Résidus bruts\")\n\n\nRésidus bruts\n\n\n\nFavorable\nDéfavorable\n\n\n\n\nHomme\n14.61274\n-14.61274\n\n\nFemme\n-14.61274\n14.61274\n\n\n\n\nkable(toto$stdres, caption= \"Résidus standardisés\")\n\n\nRésidus standardisés\n\n\n\nFavorable\nDéfavorable\n\n\n\n\nHomme\n1.877656\n-1.877656\n\n\nFemme\n-1.877656\n1.877656\n\n\n\n\n\nOn peut aussi visualiser graphiquement les résidus standardisés avec avec mosaicplot() et l’option shade=T. Seules les cases ayant des résidus standardisés supérieures à +2 ou inférieurs à -2 seront colorées, ce qui revient à visualiser uniquement les anomalies significatives avec un risque d’erreur p&lt; 0.05.\n\nmosaicplot(tabcont,shade=T)"
  },
  {
    "objectID": "21-Tabcont.html#opinion-usa-âge",
    "href": "21-Tabcont.html#opinion-usa-âge",
    "title": "7  Tableau de contingence",
    "section": "7.5 Opinion USA / Âge",
    "text": "7.5 Opinion USA / Âge\nSupposons qu’on veuille analyser la relation entre l’opinion sur les USA et l’effet des classes d’âge ou des génération. Les deux variables age5 et gen4 sont issuesde la même variable mais elle n’ont pas le même sens d’un point de vue thématique\n\n7.5.1 Effet de génération\n\ntabcont&lt;-wtd.table(sel$gen4,sel$opi_USA2, weights=sel$poids)\n\nWarning: Unknown or uninitialised column: `poids`.\n\n\nWarning in wtd.table(sel$gen4, sel$opi_USA2, weights = sel$poids): no weights\nargument given, using uniform weights of 1\n\nround(addmargins(tabcont),1)\n\n        Favorable Défavorable Sum\n 1950&lt;         72         140 212\n1950-69       167         229 396\n1970-89       121         135 256\n&gt; 1990         68          39 107\nSum           428         543 971\n\nlprop(tabcont)\n\n        Favorable Défavorable Total\n 1950&lt;   34.0      66.0       100.0\n1950-69  42.2      57.8       100.0\n1970-89  47.3      52.7       100.0\n&gt; 1990   63.6      36.4       100.0\nAll      44.1      55.9       100.0\n\nplot(tabcont, col=c(\"lightyellow\",\"lightblue\"), \n     main=\"Opinion sur les USA selon la génération\", \n     sub=source, \n     )\n\n\n\n\nOn remarque que l’opinion sur les USA semble de plus en plus positive au fur et à mesure des générations. Mais il faut tester pour voir si cet effet est significatif.\n\ntiti&lt;-chisq.test(tabcont)\ntiti\n\n\n    Pearson's Chi-squared test\n\ndata:  tabcont\nX-squared = 26.901, df = 3, p-value = 6.175e-06\n\n\nOn obtient donc une relation très significative (Chi-2 = 26.9 , degrés de liberté =3, p &lt; 0.001) entre la génération des personnes et leur opinion sur les USA. L’étude des résidus standardisés montre que cette relation est liée au fait que les générations récentes sont beaucoup plus favorables aux USA que les générations anciennes. On peut visualiser la relation avec la fonction mosaicplot(shaded=T)\n\nmosaicplot(tabcont, shade = T)\n\n\n\n\n\n\n7.5.2 Effet d’âge\nAurions nous tiré les mêmes conclusions en prenant un âge en 5 classes ?\n\ntabcont&lt;-wtd.table(sel$age5,sel$opi_USA2, weights=sel$poids)\n\nWarning: Unknown or uninitialised column: `poids`.\n\n\nWarning in wtd.table(sel$age5, sel$opi_USA2, weights = sel$poids): no weights\nargument given, using uniform weights of 1\n\nround(addmargins(tabcont),1)\n\n          Favorable Défavorable Sum\n18-36 ans       123          87 210\n37-49 ans        80         101 181\n50-59 ans        84         109 193\n60-68 ans        75         120 195\n69-94-ans        66         126 192\nSum             428         543 971\n\nlprop(tabcont)\n\n          Favorable Défavorable Total\n18-36 ans  58.6      41.4       100.0\n37-49 ans  44.2      55.8       100.0\n50-59 ans  43.5      56.5       100.0\n60-68 ans  38.5      61.5       100.0\n69-94-ans  34.4      65.6       100.0\nAll        44.1      55.9       100.0\n\nplot(tabcont, col=c(\"lightyellow\",\"lightblue\"), \n     main=\"Opinion sur les USA selon l'âge\", \n     sub=source, \n     )\n\n\n\n\n\ntiti&lt;-chisq.test(tabcont)\ntiti\n\n\n    Pearson's Chi-squared test\n\ndata:  tabcont\nX-squared = 27.75, df = 4, p-value = 1.402e-05\n\n\nOn voit que la relation serait tout aussi significative et montrerait une variation continue de l’avius sur les USA avec l’âge, mais avec une opposition particulière des moins de 36 ans et des plus de 68 ans.\n\nmosaicplot(tabcont, shade = T)"
  },
  {
    "objectID": "21-Tabcont.html#opinion-usa-age-sexe",
    "href": "21-Tabcont.html#opinion-usa-age-sexe",
    "title": "7  Tableau de contingence",
    "section": "7.6 Opinion USA / Age & Sexe",
    "text": "7.6 Opinion USA / Age & Sexe\nOn va se limiter au cas où l’on veut étudier la relation entre X et Y toutes choses égales quant à l’effet d’une troisième variable Z qui sert de variable de contrôle.\nPar exemple, on veut savoir s’il existe un lien entre l’âge (X) et l’avis sur les USA (Y) demeure valable aussi bien pour les hommes que pour les femmes (Z).\n\n7.6.1 Sous-échantillon des hommes\n\nhom&lt;-sel[sel$sex==\"Homme\",]\ntabcont&lt;-wtd.table(hom$age5,hom$opi_USA2)\n\nWarning in wtd.table(hom$age5, hom$opi_USA2): no weights argument given, using\nuniform weights of 1\n\nround(addmargins(tabcont),0)\n\n          Favorable Défavorable Sum\n18-36 ans        65          49 114\n37-49 ans        46          49  95\n50-59 ans        39          46  85\n60-68 ans        40          58  98\n69-94-ans        41          59 100\nSum             231         261 492\n\nlprop(tabcont)\n\n          Favorable Défavorable Total\n18-36 ans  57.0      43.0       100.0\n37-49 ans  48.4      51.6       100.0\n50-59 ans  45.9      54.1       100.0\n60-68 ans  40.8      59.2       100.0\n69-94-ans  41.0      59.0       100.0\nAll        47.0      53.0       100.0\n\nchisq.test(tabcont)\n\n\n    Pearson's Chi-squared test\n\ndata:  tabcont\nX-squared = 7.6622, df = 4, p-value = 0.1048\n\n\nDans le sous échantillon des 492 hommes, on n’observe pas de relation significative entre l’avis sur les USA et l’âge (Chi-2 = 7.6 pour 4 degré de liberté, p &gt; 0.10)\n\n\n7.6.2 Sous-échantillon des femmes\n\nfem&lt;-sel[sel$sex==\"Femme\",]\ntabcont&lt;-wtd.table(fem$age5,fem$opi_USA2)\n\nWarning in wtd.table(fem$age5, fem$opi_USA2): no weights argument given, using\nuniform weights of 1\n\nround(addmargins(tabcont),0)\n\n          Favorable Défavorable Sum\n18-36 ans        58          38  96\n37-49 ans        34          52  86\n50-59 ans        45          63 108\n60-68 ans        35          62  97\n69-94-ans        25          67  92\nSum             197         282 479\n\nlprop(tabcont)\n\n          Favorable Défavorable Total\n18-36 ans  60.4      39.6       100.0\n37-49 ans  39.5      60.5       100.0\n50-59 ans  41.7      58.3       100.0\n60-68 ans  36.1      63.9       100.0\n69-94-ans  27.2      72.8       100.0\nAll        41.1      58.9       100.0\n\nchisq.test(tabcont)\n\n\n    Pearson's Chi-squared test\n\ndata:  tabcont\nX-squared = 23.273, df = 4, p-value = 0.0001117\n\n\nDans le sous échantillon des 479 femmes, on observe en revanche une relation très significative entre l’avis sur les USA et l’âge (Chi-2 = 23.3 pour 4 degré de liberté, p &lt; 0.001)\n\n\n7.6.3 Régression logistique\nLa suite logique des analyses bivariées de variables qualitatives est la régression logistique qui permet de modéliser une variable qualitative binaire (Y) par un ensemble dr’autres variables qualitatives ou quantitatives (X1, X2, X3, …). Par exemple, on peut se demander si le fait d’être favorable ou très favorable aux USA (Y) dépend simultanément du sexe (X1) et de l’âge (X2).\n\nsel$opi_USA_fav&lt;-sel$opi_USA2==\"Favorable\"\ntoto&lt;-glm(sel$opi_USA_fav ~  sel$sex + sel$age5 , family = \"binomial\")\nanova(toto,test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel: binomial, link: logit\n\nResponse: sel$opi_USA_fav\n\nTerms added sequentially (first to last)\n\n         Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    \nNULL                       970     1332.4              \nsel$sex   1   3.3421       969     1329.1   0.06753 .  \nsel$age5  4  27.4485       965     1301.7 1.613e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(toto)\n\n\nCall:\nglm(formula = sel$opi_USA_fav ~ sel$sex + sel$age5, family = \"binomial\")\n\nCoefficients:\n                  Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)         0.4517     0.1532   2.949  0.00319 ** \nsel$sexFemme       -0.2281     0.1317  -1.732  0.08328 .  \nsel$age537-49 ans  -0.5771     0.2053  -2.811  0.00494 ** \nsel$age550-59 ans  -0.5853     0.2024  -2.892  0.00383 ** \nsel$age560-68 ans  -0.8097     0.2035  -3.978 6.94e-05 ***\nsel$age569-94-ans  -0.9910     0.2070  -4.788 1.69e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1332.4  on 970  degrees of freedom\nResidual deviance: 1301.6  on 965  degrees of freedom\n  (25 observations deleted due to missingness)\nAIC: 1313.6\n\nNumber of Fisher Scoring iterations: 4\n\n\nAu bout du compte, l’effet principal demeure bien celui de l’âge. L’effet du sexe devient non significatif lorsque l’onb contrôle l’âge (p&gt;0.05). Les femmes sont moins favorables aux USA mais cet effet s’explique en partie au moins par leur plus grande longévité."
  },
  {
    "objectID": "31-GraphBase.html#introduction",
    "href": "31-GraphBase.html#introduction",
    "title": "8  Graphiques avec R-Base",
    "section": "8.1 Introduction",
    "text": "8.1 Introduction\n\n8.1.1 Pourquoi s’em…bêter à utiliser les fonctions primitives de R pour faire des graphiques ?\nOn peut se demander si cela vaut la peine d’utiliser R-base pour faire des graphiques. En effet R propose maintenant des packages produisant facilement de très jolis graphiques statiques (ggplot2) ou dynamiques (plotly). La réponse est cependant oui car :\n\nil faut pouvoir relire et améliorer des programmes anciens\nles primitives graphiques de R permettent de créer ses propres applications\nles packages ggplot2 et plotly reprennent des concepts de R-base\n\nEt la plus raison la plus importante :\n\nc’est l’occasion d’apprendre à créer ses propres fonctions et ainsi de meiiux apprécier les qualités et les défauts de celles que l’on trouve dans les packages qu’on utilise.\n\n\n\n8.1.2 Trois étapes pour créer un graphique\nComme indiqué par Sophie Baillargeon dans son excellent cours de R de l’Université de Laval (Québec) , un programme pour créer un graphique avec le système graphique de base en R se décompose typiquement en 3 étapes utilisant des fonctions différentes :\n\nEtape 1 : La configuration des paramètres graphiques généraux (facultatif) :\n\nénoncé par ou layout.\n\nEtape 2 : L’initialisation d’un graphique (obligatoire) :\n\nfonction de base : plot (choisit un graphique pertinent à produire selon ce qu’elle reçoit en entrée),\nou fonction pour un type spécifique graphiques : pairs, matplot, pie, barplot, dotchart, mosaicplot, hist, boxplot, qqnorm, qqplot, curve, etc.\n\nEtape 3. L’ajout séquentiel d’éléments au graphique (facultatif) :\n\nfonctions d’ajouts à un graphique déjà initialisé :\n\npoints, matpoints, lines, matlines, abline, segments, arrows, rect, polygon, legend, text, mtext, title, axis, box, qqline, etc.;\nmatplot, barplot, hist, boxplot, curve avec l’argument add = TRUE."
  },
  {
    "objectID": "31-GraphBase.html#préparation-des-données",
    "href": "31-GraphBase.html#préparation-des-données",
    "title": "8  Graphiques avec R-Base",
    "section": "8.2 Préparation des données",
    "text": "8.2 Préparation des données\n\n8.2.1 Chargement du fichier\nOn charge un fichier statistique appelé tips.csv où les séparateurs sont des points-virgules et les décimales des points.\n\ndon&lt;-read.table(file = \"resources/data/tips/tips.csv\",\n                sep = \";\",\n                header = T)\nhead(don)\n\n  IDEN TOTBILL  TIP SEX SMOKER DAY TIME SIZE\n1 R001   16.99 1.01   1      0   6    1    2\n2 R002   10.34 1.66   0      0   6    1    3\n3 R003   21.01 3.50   0      0   6    1    3\n4 R004   23.68 3.31   0      0   6    1    2\n5 R005   24.59 3.61   1      0   6    1    4\n6 R006   25.29 4.71   0      0   6    1    4\n\n\n\n\n8.2.2 Contenu du fichier\nCe dossier contient les pourboires (tips en anglais, d’où le nom du fichier) d’un serveur dans un restaurant américain aux débuts des années 1990. Le restaurant était dans un centre commercial. Il y avait une zone fumeurs et une zone non fumeurs.Les données indiquent le prix du repas, le pourboire, le sexe de la personne qui a payé et donné le pourboire, si c’était dans la zone fumeurs ou non, le jour où le repas a été pris, si c’était en journée ou en soirée et enfin, le nombre de convives.\nSources : Ces données sont disponibles dans le package R nommé rggobi et sont décrites dans l’ouvrage de Cook et Swayne intitulé Interactive and Dynamic Graphics for Data Analysis. Elles font partie des données d’exemple du livre de Bryant et Smith dont la première édition est parue en 1995 dont le titre est Practical Data Analysis: Case Studies in Business Statistics.\n\n\n8.2.3 Dictionaire des variables\n\nIDEN : identifiant du repas\nTOTBILL : prix du repas (en dollars des années 1990)\nTIP : pourboire (en dollars des années 1990)\nSEX : sexe de la personne qui a payé (0 = Homme, 1 = Femme)\nSMOKER : la personne qui a payé est non-fumeur (O) ou fumeur (1)\nDAY : jour de la semaine (1 = dimanche, 2 = lundi, 3 = mardi, …)\nTIME : repas pris en journée (0) ou le soir (1)\nSIZE : nombre de convives\n\n\n\n8.2.4 Recodage des variables\nLe type de plusieurs variables est incorrect. On transforme les codes numériques en facteur et on recode les niveaux en français :\n\ndon$IDEN&lt;-as.character(don$IDEN)\ndon$SEX&lt;-as.factor(don$SEX)\nlevels(don$SEX)&lt;-c(\"Homme\",\"Femme\")\ndon$SMOKER&lt;-as.factor(don$SMOKER)\nlevels(don$SMOKER)&lt;-c(\"Non fumeur\", \"Fumeur\")\ndon$DAY&lt;-as.factor(don$DAY)\nlevels(don$DAY)&lt;-c(\"Mercredi\",\"Jeudi\",\"Vendredi\",\"Samedi\")\ndon$TIME&lt;-as.factor(don$TIME)\nlevels(don$TIME)&lt;-c(\"Journée\",\"Soirée\")\n\n\n\n8.2.5 Ajout d’une nouvelle variable\nOn crée la variable PCT qui est le rapport entre le pourboire (TIP) et le prix total (TOTBILL) du repas exprimé en pourcentage.\n\ndon$PCT&lt;-100*don$TIP/don$TOTBILL\n\n\n\n8.2.6 Résumé de l’ensemble du tableau\n\nsummary(don)\n\n     IDEN              TOTBILL           TIP            SEX     \n Length:244         Min.   : 3.07   Min.   : 1.000   Homme:157  \n Class :character   1st Qu.:13.35   1st Qu.: 2.000   Femme: 87  \n Mode  :character   Median :17.80   Median : 2.900              \n                    Mean   :19.79   Mean   : 2.998              \n                    3rd Qu.:24.13   3rd Qu.: 3.562              \n                    Max.   :50.81   Max.   :10.000              \n        SMOKER          DAY          TIME          SIZE           PCT        \n Non fumeur:151   Mercredi:62   Journée: 68   Min.   :1.00   Min.   : 3.564  \n Fumeur    : 93   Jeudi   :19   Soirée :176   1st Qu.:2.00   1st Qu.:12.913  \n                  Vendredi:87                 Median :2.00   Median :15.477  \n                  Samedi  :76                 Mean   :2.57   Mean   :16.080  \n                                              3rd Qu.:3.00   3rd Qu.:19.148  \n                                              Max.   :6.00   Max.   :71.034  \n\n\n##.Paramètres généraux et disposition des graphiques\n\n\n8.2.7 La fonction par()\nLa fonction par() ne produit pas directement de graphique mais permet de :\n\ndéfinir la disposition de plusieurs graphiques\nspécifier la largeur des marges\ndéfinir des paramètres généraux valables pour tous les graphiques\n\nElle se comporte donc comme une feuille de style ou un CSS. Il est de ce fait prudent de stocker les paramètres d’origine avant de les modifier.\nIl y a 66 paramètres différents … Il est prudent de les stocker dans leur configuration d’origine avant de les modifier.\n\n# Stockage des paramètres d'origine\nold&lt;- par()\n# Affichage des paramètres d'origine\nhead(old)\n\n$xlog\n[1] FALSE\n\n$ylog\n[1] FALSE\n\n$adj\n[1] 0.5\n\n$ann\n[1] TRUE\n\n$ask\n[1] FALSE\n\n$bg\n[1] \"white\"\n\n\n\n\n8.2.8 fonction par() + mfrow\nSupposons que l’on veuille disposer verticalement une boxplot et un histogramme de la variable PCT. On va utiliser l’instruction mfrow=c(2,1) pour placerles deux figures suivantes sur des lignes séparées :\n\npar(mfrow=c(2,1))\nhist(don$PCT, main=\"Histogramme\", xlab=\"Pourboires (%)\")\nboxplot(don$PCT, horizontal=T, main=\"Boxplot\", xlab = \"Pourboires (%)\")\n\n\n\n\nSi l’on préfère une disposition horizontale on modifie le paramètre mfrow :\n\npar(mfrow=c(1,2))\nhist(don$PCT, main=\"Histogramme\", xlab=\"Pourboires (%)\")\nboxplot(don$PCT, horizontal=T, main=\"Boxplot\", xlab = \"Pourboires (%)\")\n\n\n\n\n\n\n8.2.9 Autres paramètres de par()\nOn peut ajouter toute une série d’autres paramètres par défaut. Par exemple, pour faire un graphique sur fonds noir (bg) à traits blancs (fg), puis régler la taille (cex) et la couleur (col) des différents textes.\n\npar(mfrow = c(1,2),\n    bg=\"black\", fg=\"white\",\n    cex.main = 1, col.main = \"gray80\",\n    cex.lab =  0.8, col.lab = \"orange\",\n    cex.axis = 0.6, col.axis = \"red\"\n    )\nhist(don$PCT, main=\"Histogramme\", xlab=\"Pourboires (%)\",col=\"lightyellow\")\nboxplot(don$PCT, horizontal=T, main=\"Boxplot\", xlab = \"Pourboires (%)\",col=\"lightyellow\")\n\n\n\n\n\n\n8.2.10 La fonction layout()\nLa fonction layout() permet une gestion plus précise de la disposition de différents graphiques sur une même fenêtre que la fonction par(). Sa syntaxe semble difficile mais elle est plus simple si on crée la matrice d’allocation des figures avec rbind() ce qui permet de visualiser la position de chaque figure facilement\n\n## Divise la figure en 2 lignes et 2 colonnes\n## alloue la figure 1 à toute la première ligne \n## alloue les figures 2 et 3 à la deuxième ligne\nmat&lt;-rbind(c(1,1),\n           c(2,3))\nlayout(mat)\nboxplot(don$PCT~don$SEX, horizontal=T) # Figure 1\nhist(don$PCT)                          # Figure 2\nplot(don$SEX)                          # Figure 3\n\n\n\n\nOn peut préciser la longueur et la largeur des différentes lignes et colonnes avec widths et heights . On peut visualiser le résultat de la mise en page avec layout.show()\n\nmat&lt;-rbind(c(1,2),\n           c(0,3))\nnf &lt;- layout(mat, widths = c(1,4), heights = c(4,1), respect=T)\nlayout.show(nf)\n\n\n\n\nOn peut ensuite remplir le layout avec des figures, par exemple un plot et deux boxplots\n\nmat&lt;-rbind(c(1,2),\n           c(0,3))\npar(mar=c(2,2,0,0))\nlayout(mat, widths = c(1,4), heights = c(4,1), respect=TRUE)\nboxplot(don$PCT,ann = F)\nplot(don$TOTBILL,don$PCT,pch=19,col=\"red\",cex=0.6,xlab=\"Prix du repas\",ylab=\"Pourboire\")\nboxplot(don$TOTBILL, horizontal=T)"
  },
  {
    "objectID": "31-GraphBase.html#la-fonction-génératrice-plot",
    "href": "31-GraphBase.html#la-fonction-génératrice-plot",
    "title": "8  Graphiques avec R-Base",
    "section": "8.3 La fonction génératrice plot()",
    "text": "8.3 La fonction génératrice plot()\n\n8.3.1 Une super-fonction\nL’instruction plot() n’est pas une fonction graphique comme les autres car elle va renvoyer des résultats différents selon les circonstances. En d’autres termes c’est un outil de programmation orienté objet qui va adapter le résultat à la nature des variables et plus généralement des objets qui lui sont fournis en entrée.\n\nPar exemple, un plot() d’une variable de type factor va donner le même résultat que barplot() appliqué à la table de dénombrement de cette variable\nAutre exemple, la fonction lm() génère un objet complexe (modèle de régression linéaire). Lorsque l’on effectue un plot de cet objet, on utilise en fait une fonction plot.lm() qui fournit les diagnostics de la régression.\n\n\n\n8.3.2 plot(X) / X de type factor\nLa fonction plot() est pratique pour visualiser une variable de type factor à l’aide d’un barplot().\n\npar(mfrow=c(1,2))\nX&lt;-don$SEX\nplot(X, main=\"plot(x=factor)\")\nbarplot(table(X), main=\"barplot(table(x=factor))\")\n\n\n\n\n\n\n8.3.3 plot(X) / X de type numeric\nMais elle est sans intérêt pour une variable de type numérique, sauf si on la trie avec sort()\n\npar(mfrow=c(1,2))\nplot(don$TIP, main=\"Sans intérêt ...\")\nplot(sort(don$TIP),main=\"Un peu mieux...\")\n\n\n\n\n\n\n8.3.4 plot(X,Y) / X et Y de type factor\nPlot renvoie un graphique de type mosaicplot()\n\npar(mfrow=c(1,2),mar=c(2,2,0,2))\nplot(don$SEX,don$TIME)\nplot(don$TIME,don$SEX)\n\n\n\n\n\n\n8.3.5 plot(X,Y) / X et Y de type numerique\nPlot renvoie un graphique de type scatterplot()\n\npar(mfrow=c(1,1))\nplot(don$TOTBILL,don$TIP)\n\n\n\n\n\n\n8.3.6 plot(X,Y) / X de type factor et Y de type numerique\nPlot renvoie un graphique de type boxplot() si le factor est en premier,\n\npar(mfrow=c(1,1))\nplot(don$SEX,don$TIP, horizontal=T)\n\n\n\n\n\n\n8.3.7 plot(X,Y) / X de type factor et Y de type numerique\nPlot renvoie un diagramme de faible intérêt si la variable factor est en second. Il s’agit en termes statistiques d’un ensemble de diagrammes de distribution .\n\nplot(don$TIP,don$SEX)\n\n\n\n\n\n\n8.3.8 plot(model) / model = lm(Y~X)\nL’appplication de plot à un modèle linéaire issu de lm() permet de générer 6 graphiques différents (Cf. cours sur la régression). Par défaut, R affiche les graphiques n° 1,2,3,5 (mais je préfère le n°4 …)\n\npar(mfrow=c(2,2))\nmodel&lt;-lm(don$PCT~don$TOTBILL)\nplot(model)\n\n\n\n\nLe graphique n°1 vérifie si les résidus sont réguliers\n\nplot(model,1, main= \"Absence d'autocorrélation ?\",labels.id = don$IDEN)\n\n\n\n\nLe graphique n°2 vérifie si les résidus sont distribués de façon gaussienne\n\nplot(model,2, main= \"Normalité ?\",labels.id = don$IDEN)\n\n\n\n\nLe graphique n°3 vérifie si la variance des résidus est constante\n\nplot(model,3, main= \"Homogénéité ?\",labels.id = don$IDEN)\n\n\n\n\nLe graphique n°4 vérifie si des valeurs exceptionnelles existent à l’aide de la distance de Cook.\n\nplot(model,4, main= \"Valeurs exceptionnelles ?\",labels.id = don$IDEN)"
  },
  {
    "objectID": "31-GraphBase.html#les-autres-fonctions-génératrice",
    "href": "31-GraphBase.html#les-autres-fonctions-génératrice",
    "title": "8  Graphiques avec R-Base",
    "section": "8.4 Les autres fonctions génératrice",
    "text": "8.4 Les autres fonctions génératrice\nOn peut créer un graphque avec plot() mais aussi avec d’autres fonctions dont le nom se termine en général par —plot pour bien rappeler leur rôle de création du graphique.\n\nbarplot\nboxplot\nhist\ndensity\npie\nmatplot\npairs\nmosaicplot\ncurve\n…\n\n\n8.4.1 La fonction barplot()\nLa fonction barplot() permett de créer des diagrammes en barres qui résultent en général du dénombrement d’une ou deux variable qualitative à l’aide des fonctions table() ou xtabs().\n\nmytable &lt;- table(don$DAY)\nmytable\n\n\nMercredi    Jeudi Vendredi   Samedi \n      62       19       87       76 \n\nmyxtabs &lt;- xtabs(~don$DAY)\nmyxtabs\n\ndon$DAY\nMercredi    Jeudi Vendredi   Samedi \n      62       19       87       76 \n\n\nCas d’une table à une seule variable :\n\nbarplot(height = table(don$DAY), \n        xlab = \"fréquence\", ylab = \"jour de la semaine\")\n\n\n\n\nCas d’une table à une deux variables :\n\nbarplot(height = table(don$DAY,don$SEX), \n        xlab = \"fréquence\",  ylab = \"jour de la semaine\")\n\n\n\n\nExemple de figure complète avec toute une série de paramètres optionnels placés soit dans barplot(), soit dans par()\n\npar(cex.main = 1, cex.lab = 0.8, cex.axis =0.8, cex.sub=0.6)\nbarplot(height = table(don$DAY,don$SEX),\n        horiz = TRUE,\n        col = rainbow(n=4,alpha = 0.5),\n        legend=TRUE,\n        ylab = \"fréquence\", \n        xlab = \"jour de la semaine\", \n        main = \"Qui paye le repas ?\", \n        sub =  \"Source : Pourboires de 244 repas dans un restaurant américains au début des années 1990 (Bryant & Smith, 1995)\")\n\n\n\n\nOn remarque que les hommes paient plus souvent le repas que les femmes le vendredi et surtout le samedi …\n\n\n8.4.2 Les fonctions hist() et density()\nOn présente ensemble ces trois fonctions qui sont très complémentaires puisqu’elles permettent l’une et l’autre de créer un histogramme hist() et de lui adjoindre avec lines() une courbe lissée générée par density(). La syntaxe minimale est la suivante :\n\nhist(don$PCT, probability = TRUE)\nlines(density(don$PCT))\n\n\n\n\nOn peut ensuite préciser les paramètres des trois fonctions façon plus ou moins complexes\n\npar(cex.main = 1, cex.lab = 0.8, cex.axis =0.8, cex.sub=0.6,\n    bg=\"black\",fg=\"white\",col.lab=\"white\",col.axis=\"white\",col.main=\"white\")\nhist(don$PCT, \n     probability = TRUE, \n     breaks = quantile(don$PCT,c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1)), \n     col=terrain.colors(n=10,alpha=0.8), \n     xlab = \"Pourboires en %\", \n     ylab = \"Densité de probabilité\",\n     main = \"Histogramme des pourboires par déciles\",\n     sub =  \"Source : Pourboires de 244 repas dans un restaurant américains au début des années 1990 (Bryant & Smith, 1995)\",\n     xlim =c(0,30)\n     )\nlines(density(don$PCT,bw=2), col=\"red\",lwd=2)\n\n\n\n\nEt si on doit faire plusieurs figures, on peut créer sa fonction :\n\nmonhist&lt;-function(var, nomvar=\"variable\") \n  {\n  par(cex.main = 1, cex.lab = 0.8, cex.axis =0.8, cex.sub=0.6,\n    bg=\"black\",fg=\"white\",col.lab=\"white\",col.axis=\"white\",\n    col.main=\"white\", col.sub=\"white\")\nhist(var, \n     probability = TRUE, \n     breaks = unique(quantile(var,c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1))), \n     col=terrain.colors(n=10,alpha=0.8), \n     xlab = nomvar, \n     ylab = \"Densité de probabilité\",\n     main= \"Mon bel histogramme par déciles ...\"\n     )\nlines(density(var), col=\"red\",lwd=2)\n}\n\nApplication de la fonction au prix du repas\n\nmonhist(don$TOTBILL,\"Prix du repas (en $)\")\n\n\n\n\nApplication de la fonction aumontant du pourboire\n\nmonhist(don$TIP,\"Montant du pourboire (en $)\")"
  },
  {
    "objectID": "31-GraphBase.html#les-fonctions-complémentaires",
    "href": "31-GraphBase.html#les-fonctions-complémentaires",
    "title": "8  Graphiques avec R-Base",
    "section": "8.5 Les fonctions complémentaires",
    "text": "8.5 Les fonctions complémentaires\nIl s’agit de fonctions qui ne peuvent pas s’executer seules mais ne peuvent être lancées qu’après l’execution d’une fonction graphique principale comme plot(), barplot(), hist(), …\nNous en avons déjà vu un exemple avec la fonction lines() qui s’execute après la fonction hist() mais ne peut fonctionner seule. Le programme ci-dessous renverra un message d’erreur\n\nlines(density(don$PCT), col=\"red\",lwd=2) # ne marchera pas\n\nError in plot.xy(xy.coords(x, y), type = type, …) : plot.new has not been called yet\n\n8.5.1 Exemple d’un nuage de points (X,Y)\nOn va prendre comme exemple l’ajout de fonctions graphiques complémentaires à un nuage de point :\n\nplot(don$TOTBILL,don$TIP, xlab = \"Prix du repas\",ylab=\"Pourboire\")\n\n\n\n\nOn neutralise l’affichage des points générés par plot() et on les trace avec la fonction points() en précisant leur taille (nombre de repas) et leur couleur (hommes ou femmes) et en ajoutant une légende avec legend()\n\nplot(don$TOTBILL,don$TIP, cex=0,xlab = \"Prix du repas\",ylab=\"Pourboire\")\npoints(don$TOTBILL,don$TIP, cex=sqrt(don$SIZE)/2, col=don$SEX, pch=19)\nlegend(\"topleft\", c(\"Hommes\",\"Femmes\"), col=c(\"black\",\"red\"), pch=19, cex=1)\n\n\n\n\nOn ajoute ensuite une grille avec grid() et des droites correspondant à la moyenne de X et à celle de Y avec abline(v= …) et abline(h= …)\n\nplot(don$TOTBILL,don$TIP, cex=0,xlab = \"Prix du repas\",ylab=\"Pourboire\")\npoints(don$TOTBILL,don$TIP, cex=sqrt(don$SIZE)/2, col=don$SEX, pch=19)\nlegend(\"topleft\", c(\"Hommes\",\"Femmes\"), col=c(\"black\",\"red\"), pch=19, cex=1)\ngrid()\nabline(v=mean(don$TOTBILL), lty=2,lwd=2,col=\"blue\")\nabline(h=mean(don$TIP), lty=2,lwd=2,col=\"blue\")\n\n\n\n\nOn ajoute ensuite une droite de régression avec abline(model)\n`\n\nplot(don$TOTBILL,don$TIP, cex=0,xlab = \"Prix du repas\",ylab=\"Pourboire\")\npoints(don$TOTBILL,don$TIP, cex=sqrt(don$SIZE)/2, col=don$SEX, pch=19)\nlegend(\"topleft\", c(\"Hommes\",\"Femmes\"), col=c(\"black\",\"red\"), pch=19, cex=1)\ngrid()\nabline(v=mean(don$TOTBILL), lty=2,lwd=2,col=\"blue\")\nabline(h=mean(don$TIP), lty=2,lwd=2,col=\"blue\")\nmaregression &lt;- lm(don$TIP~don$TOTBILL)\nabline(maregression,lty=1,lwd=3,col=\"brown\")\n\n\n\n\nOn peut aussi ajouter un texte à l’emplacement de son choix avec text(). Par exemple, repérer les individus à très forts résidus\n\nplot(don$TOTBILL,don$TIP, cex=0,xlab = \"Prix du repas\",ylab=\"Pourboire\")\npoints(don$TOTBILL,don$TIP, cex=sqrt(don$SIZE)/2, col=don$SEX, pch=19)\nlegend(\"topleft\", c(\"Hommes\",\"Femmes\"), col=c(\"black\",\"red\"), pch=19, cex=1)\ngrid()\nabline(v=mean(don$TOTBILL), lty=2,lwd=2,col=\"blue\")\nabline(h=mean(don$TIP), lty=2,lwd=2,col=\"blue\")\nmaregression &lt;- lm(don$TIP~don$TOTBILL)\nabline(maregression,lty=1,lwd=3,col=\"brown\")\ndon2&lt;-don[abs(maregression$residuals)&gt;2,]\ntext(don2$TOTBILL,don2$TIP,don2$IDEN,cex = 0.5, pos = 1, col=\"gray30\")"
  },
  {
    "objectID": "31-GraphBase.html#conclusion",
    "href": "31-GraphBase.html#conclusion",
    "title": "8  Graphiques avec R-Base",
    "section": "8.6 Conclusion",
    "text": "8.6 Conclusion\n\n8.6.1 On peut faire de beaux graphiques avec R-Base …\nPour cela il faut bien comprendre les trois étapes :\n\nFixer les paramètres graphiques généraux avec par() ou layout()\nUtiliser une fonction génératrice comme plot(), barplot(), ou hist()\nAjouter des fonctions complémentaires comme lines(), points(), text(), abline(), …\n\nEt si on ne veut pas refaire toujours les mêmes codes :\n\ncréer ses propres fonctions en suivant l’exemple de monhist()\n\n\n\n8.6.2 On peut utiliser des packages spécialisés\nPlusieurs packages réalisées à partir des primitives graphiques de R-Base sont spécialisés dans la réalisation d’analyses bivariées et adaptés au type des variables.\n\ncar : pour croiser deux variables quantitatives\n\n\nlibrary(car)\n\nLoading required package: carData\n\nscatterplot(don$TOTBILL,don$TIP)\n\n\n\n\n\nvcd : pour croiser deux variables qualitatives\n\n\nlibrary(vcd)\n\nLoading required package: grid\n\nmosaicplot(don$SEX~don$DAY,shade=T)\n\n\n\n\n\nbeanplot : pour croiser une variable qualitative et une variable quantitative\n\n\nlibrary(beanplot)\nbeanplot(don$PCT~don$DAY,shade=T)\n\nlog=\"y\" selected\n\n\n\n\n\n\n\n8.6.3 ggally : un package spécialisé dans la statistique bivariée\nLe récent package ggally est spécialisé dans l’analyse des relations statistiques entre deux variables. Il reprend plusieurs autres packages (notamment ggplot2) pour offrir une solution intégrée avec une syntaxe simple et intuitive.\n\n\n8.6.4 ggplot2 : un package graphique universel ?\nFruit des travaux d’Hadley Wickham et de l’équipe de développement de R-Studio, le package ggplot2 est un élément central de l’univers tidyverse, au point de faire désormais partie des “standards” de l’apprentissage de R.\nMais sa connaissance approfondie est longue et pas toujours intuitive malgré les efforts de ses auteurs. A la longue, les paramètres de base des graphiques ggplot2 peuvent apparaître lassants et il faut donc bien approfondir sa connaissance pour réaliser des figures originales au niveau du style. Sinon c’est un peu le “fast food” de la visualisation : universel mais manquant de goût et d’originalité…"
  },
  {
    "objectID": "32-Ggplot2.html#introduction",
    "href": "32-Ggplot2.html#introduction",
    "title": "9  Graphiques avec ggplot2",
    "section": "9.1 Introduction",
    "text": "9.1 Introduction\n\n9.1.1 ggplot2 et tydiverse\n\nggplot2 est un package de visualisation graphique qui s’incrit dans l’écosystème plus général du tydiverse mis au point par Hadley Wickham, l’un des grands prêtres de R, responsable scientifique en chef de Rstudio.\n\nhttp://hadley.nz/\n\nggplot2 est considéré actuellement comme la référence mondiale en matière de visualisation de données statistiques sous R en raison de sa puissance et de sa polyvalence.\nmais son usage avancé n’est pas très facile même si les principes de base sont (relativement) simples.\nggplot2 peut fonctionner sans tidyverse mais il est probablement plus efficace lorsque l’on l’utilise à l’intérieur de son écosystème. En d’autres termes, l’apprentissage de ggplot2 est souvent couplé avec celui de tidyverse. Voir par exemple l’excellent cours de J. Barnier.\n\n\n\n\n9.1.2 ggplot2 cheatsheet\n\nIl est recommandé d’imprimer et d’avoir toujours avec soi la ggplot2 cheatsheet qui est disponible en français."
  },
  {
    "objectID": "32-Ggplot2.html#préparation-des-données",
    "href": "32-Ggplot2.html#préparation-des-données",
    "title": "9  Graphiques avec ggplot2",
    "section": "9.2 préparation des données",
    "text": "9.2 préparation des données\n\n9.2.1 Chargement du fichier\nOn charge un fichier statistique appelé tips.csv où les séparateurs sont des points-virgules et les décimales des points.\n\ndon&lt;-read.table(file = \"resources/data/tips/tips.csv\",\n                sep = \";\",\n                header = T)\nhead(don)\n\n  IDEN TOTBILL  TIP SEX SMOKER DAY TIME SIZE\n1 R001   16.99 1.01   1      0   6    1    2\n2 R002   10.34 1.66   0      0   6    1    3\n3 R003   21.01 3.50   0      0   6    1    3\n4 R004   23.68 3.31   0      0   6    1    2\n5 R005   24.59 3.61   1      0   6    1    4\n6 R006   25.29 4.71   0      0   6    1    4\n\n\n\n\n9.2.2 Contenu du fichier\nCe dossier contient les pourboires (tips en anglais, d’où le nom du fichier) d’un serveur dans un restaurant américain aux débuts des années 1990. Le restaurant était dans un centre commercial. Il y avait une zone fumeurs et une zone non fumeurs.Les données indiquent le prix du repas, le pourboire, le sexe de la personne qui a payé et donné le pourboire, si c’était dans la zone fumeurs ou non, le jour où le repas a été pris, si c’était en journée ou en soirée et enfin, le nombre de convives.\nSources : Ces données sont disponibles dans le package R nommé rggobi et sont décrites dans l’ouvrage de Cook et Swayne intitulé Interactive and Dynamic Graphics for Data Analysis. Elles font partie des données d’exemple du livre de Bryant et Smith dont la première édition est parue en 1995 dont le titre est Practical Data Analysis: Case Studies in Business Statistics.\n\n\n9.2.3 Dictionaire des variables\n\nIDEN : identifiant du repas\nTOTBILL : prix du repas (en dollars des années 1990)\nTIP : pourboire (en dollars des années 1990)\nSEX : sexe de la personne qui a payé (0 = Homme, 1 = Femme)\nSMOKER : la personne qui a payé est non-fumeur (O) ou fumeur (1)\nDAY : jour de la semaine (1 = dimanche, 2 = lundi, 3 = mardi, …)\nTIME : repas pris en journée (0) ou le soir (1)\nSIZE : nombre de convives\n\n\n\n\n9.2.4 Recodage des variables\nLe type de plusieurs variables est incorrect. On transforme les codes numériques en facteur et on recode les niveaux en français :\n\ndon$IDEN&lt;-as.character(don$IDEN)\ndon$SEX&lt;-as.factor(don$SEX)\nlevels(don$SEX)&lt;-c(\"Homme\",\"Femme\")\ndon$SMOKER&lt;-as.factor(don$SMOKER)\nlevels(don$SMOKER)&lt;-c(\"Non fumeur\", \"Fumeur\")\ndon$DAY&lt;-as.factor(don$DAY)\nlevels(don$DAY)&lt;-c(\"Mercredi\",\"Jeudi\",\"Vendredi\",\"Samedi\")\ndon$TIME&lt;-as.factor(don$TIME)\nlevels(don$TIME)&lt;-c(\"Journée\",\"Soirée\")\ndon$PCT&lt;-100*don$TIP/don$TOTBILL\n\n\n\n9.2.5 Résumé de l’ensemble du tableau\n\nsummary(don)\n\n     IDEN              TOTBILL           TIP            SEX     \n Length:244         Min.   : 3.07   Min.   : 1.000   Homme:157  \n Class :character   1st Qu.:13.35   1st Qu.: 2.000   Femme: 87  \n Mode  :character   Median :17.80   Median : 2.900              \n                    Mean   :19.79   Mean   : 2.998              \n                    3rd Qu.:24.13   3rd Qu.: 3.562              \n                    Max.   :50.81   Max.   :10.000              \n        SMOKER          DAY          TIME          SIZE           PCT        \n Non fumeur:151   Mercredi:62   Journée: 68   Min.   :1.00   Min.   : 3.564  \n Fumeur    : 93   Jeudi   :19   Soirée :176   1st Qu.:2.00   1st Qu.:12.913  \n                  Vendredi:87                 Median :2.00   Median :15.477  \n                  Samedi  :76                 Mean   :2.57   Mean   :16.080  \n                                              3rd Qu.:3.00   3rd Qu.:19.148  \n                                              Max.   :6.00   Max.   :71.034"
  },
  {
    "objectID": "32-Ggplot2.html#principes-généraux",
    "href": "32-Ggplot2.html#principes-généraux",
    "title": "9  Graphiques avec ggplot2",
    "section": "9.3 Principes généraux",
    "text": "9.3 Principes généraux\nOn commence par charger le package ggplot2 qui est une partie de l’univers tidyverse mais que l’on peut utiliser indépendamment du reste de l’empire d’Hadley Wickham…\n\nlibrary(ggplot2)\n\n\n9.3.1 Les différentes étapes\n\nla commande ggplot(data) initie la création du graphique.\nla commande aes() qui est l’abrévation de aesthetics définit les paramètres généraux de l’ensemble du graphique et comporte en général\n\nx = variable liée à l’axe horizontal\ny= variable liée à l’axe vertical\ncolour= : variable définissant des groupes / couleur\nshape= : variable définissant des groupes / forme\n\nla commande geom_xxx crée un graphique de type xxx\nles commandes additionnelles scale_xxx précisent les axes\nla commande additionelle facet_xxx partitionne la figure en plusieurs\nla commande theme_xxx retouche l’ensemble des paramètres de couleur, police, épaisseur\n\nN.B. Toutes les étapes ci-dessus ne sont pas obligatoires.\n\n\n9.3.2 La figure à réaliser\nComment réaliser la figure ci-dessous ?\n\n\n\n\n\n\n\n9.3.3 La construction pas à pas\nOn définit le tableau de données avec ggplot() et les variables principales avec aes()\n\n  ggplot(don) +\n  aes(x = TOTBILL) +\n  aes(y = TIP) \n\n\n\n\nOn ajoute le type principal du graphique avec la commande geom_point()\n\n  ggplot(don) +\n  aes(x = TOTBILL) +\n  aes(y = TIP) +\n  geom_point() \n\n\n\n\nOn retouche les axes horizontaux et verticaux en les passant en logarithme et en leur donnant un titre.\n\n  ggplot(don) +\n  aes(x = TOTBILL) +\n  aes(y = TIP) +\n  geom_point() +\n  scale_x_log10(name=\"Prix du repas en $\")+\n  scale_y_log10(name=\"Montant du pourboire en $\")\n\n\n\n\nOn segmente le graphique en facettes selon une ou plusieurs variables avec facet_wrap(). Du coup, on retire ces variables de l’esthétique générale :\n\n  ggplot(don) +\n  aes(x = TOTBILL) +\n  aes(y = TIP) +\n  geom_point() +\n  scale_x_log10(name=\"Prix du repas en $\")+\n  scale_y_log10(name=\"Montant du pourboire en $\")+\n  facet_wrap(vars(SEX,SMOKER))\n\n\n\n\nOn ajoute dans chaque facette une droite de tendance et son intervalle de confiance avec geom_smooth(). On précise method=“lm” pour avoir une droite et non pas une courbe\n\n  ggplot(don) +\n  aes(x = TOTBILL) +\n  aes(y = TIP) +\n  geom_point() +\n  scale_x_log10(name=\"Prix du repas en $\")+\n  scale_y_log10(name=\"Montant du pourboire en $\")+\n  facet_wrap(vars(SEX,SMOKER))+\n  geom_smooth(method=\"lm\") \n\n\n\n\nOnajoute un titre principal avec ggtitle() et on retouche l’ensemble de l’apparence avec theme_light().\n\n  ggplot(don) +\n  aes(x = TOTBILL) +\n  aes(y = TIP) +\n  geom_point() +\n  scale_x_log10(name=\"Prix du repas en $\")+\n  scale_y_log10(name=\"Montant du pourboire en $\")+\n  facet_wrap(vars(SEX,SMOKER))+\n  geom_smooth(method=\"lm\") +\n  ggtitle(label = \"Relation entre prix du repas et pourboire / sexe et tabagisme\",\n          subtitle = \"Source : Briant & Smith 1995 \") +\n  theme_light()\n\n\n\n\n\n\n9.3.4 Comparaison avec R-Base\n\nLa principale différence réside dans la construction séquentielle de la figure avec l’opérateur +. A tout moment on peut sauvegarder la figure au cours d’une des étapes décrites dans l’exemple. On parle de pipeline pour ce type de programme que l’on retrouve dans la manipulation de données avec tidyverse et dplyr.\nLa seconde différence réside dans la production rapide d’une figure de qualité graphique acceptable sans avoir besoin de spécifier les paramètres par() de R-Base.\nAu total, ggplot2 s’impose actuellement comme un standard mondial autour duquel se greffent d’autres applications. Par exemple, on peut rendre interactif un graphique ggplot() en le couplant avec plotly().\nMais … ggplot2 est beaucoup moins simple qu’il n’y paraît de prime abord. Et on peut facilement s’arracher les cheveux sur certaines commandes !\n\n\n\n9.3.5 Attention ! Paramètres aes() locaux et globaux\nUne des plus grandes difficultés que l’on rencontre dans ggplot() est la manipulation du paramètre aes() qui peut renvoyer :\n\nsoit à des paramètres globaux s’ils apparaissent dans le ggplot initial ou dans des lignes de codes isolées\nsoit à des paramètres locaux, s’ils apparaissent à l’intérieur d’une fonction geom().\n\nDeux exemples rapides pour bien comprendre\n\nSEX est un paramètre global : dans ce cas il s’applique à toutes les commandes qui suivent. Il y aura donc deux droites de régression générées par geom_smooth\n\n\nggplot(don, aes(x = TOTBILL, y = TIP, color = SEX)) +\ngeom_point() +\ngeom_smooth(method=\"lm\")\n\n\n\n\n\nSEX est un paramètre local de geom_point() : dans ce cas il n’aura pas d’effet sur geom_smooth() qui va générer une seule droite de régression.\n\n\nggplot(don, aes(x = TOTBILL, y = TIP)) +\ngeom_point(aes(color=SEX)) +\ngeom_smooth(method=\"lm\")"
  },
  {
    "objectID": "32-Ggplot2.html#x-discrète",
    "href": "32-Ggplot2.html#x-discrète",
    "title": "9  Graphiques avec ggplot2",
    "section": "9.4 X discrète",
    "text": "9.4 X discrète\n\n9.4.1 barplot (R-base)\n\nbarplot(table(don$SMOKER), col = c(\"blue\", \"red\"),\n        xlab=\"Salle de repas\", ylab = \"effectif\")\n\n\n\n\n\n\n9.4.2 geom_bar (ggplot2)\n\n# ggplot\nggplot(don) +\n  aes(x =SMOKER) +\n  geom_bar(fill = c(\"blue\",\"red\"))+\n  scale_x_discrete(name=\"Salle de repas\")+\n  scale_y_continuous(name=\"effectif\")"
  },
  {
    "objectID": "32-Ggplot2.html#x-quantitative-continue",
    "href": "32-Ggplot2.html#x-quantitative-continue",
    "title": "9  Graphiques avec ggplot2",
    "section": "9.5 X quantitative continue",
    "text": "9.5 X quantitative continue\n\n9.5.1 hist (R-base)\n\ndon2&lt;-don[don$PCT&lt;30,]\nhist(don2$PCT,breaks = 15,\n     col = \"lightyellow\",\n     border = \"blue\",\n     xlab=\"Pourboire (%)\",\n     ylab = \"Nombre de clients\",\n     main = \"Les clients sont-ils généreux ?\")\n\n\n\n\n\n\n9.5.2 geom_histogram (ggplot2)\n\n# On démarre par une ligne de tidyverse ...\ndon %&gt;%  filter(PCT&lt;30) %&gt;%\n#  ... en on embraye sur ggplot2 \n  ggplot() +\n  aes(x =PCT) + \n# Appel de la fonction principale  \n  geom_histogram( bins = 15,     \n                 fill=\"lightyellow\",\n                 col=\"blue\" \n                 ) +   \n# Retouche de l'échelle\n scale_x_continuous( name = \"Pourboires en %\") + \n scale_y_continuous(name = \"Nombre de clients\")+\n# Ajout du titre \n ggtitle(\"Les clients sont-ils généreux ?\")"
  },
  {
    "objectID": "32-Ggplot2.html#x-et-y-quantitatives-continues",
    "href": "32-Ggplot2.html#x-et-y-quantitatives-continues",
    "title": "9  Graphiques avec ggplot2",
    "section": "9.6 X et Y quantitatives continues",
    "text": "9.6 X et Y quantitatives continues\n\n9.6.1 plot (R-base)\n\ndon2&lt;-don[don$PCT&lt;30,]\nplot(x = don2$TOTBILL,\n     y = don2$PCT, \n     cex=0, \n     xlab=\"Prix du repas\",\n     ylab=\"Pourboire (%)\",\n     main= \"Plus c'est cher moins on est généreux !\")\npoints(x=don2$TOTBILL, \n       y=don2$PCT, \n       col=don2$SEX, \n       cex=sqrt(don2$SIZE), \n       pch=19)\nabline(lm(don2$PCT~don2$TOTBILL), \n       col=\"blue\",\n       lwd=3)\n\n\n\n\n\n\n9.6.2 geom_point (ggplot2)\n\n# On filtre avec tidyverse ...\ndon %&gt;%  filter(PCT&lt;30) %&gt;%\n  \n#  On définit les paramètres globaux \n  ggplot(aes(x =TOTBILL, y=PCT)) +\n  \n# On trace les points avec \n# des paramètres locaux\n  geom_point(aes(color=SEX, \n                 size = SIZE)) +\n  \n# On ajoute la droite de régression\n  geom_smooth(method = \"lm\") +\n  \n# On ajoute les titres\n  scale_x_continuous(name=\"Prix du repas\") +\n  scale_y_continuous(name=\"Pourboire en %\") +\n  ggtitle(\"Plus c'est cher moins on est généreux !\")"
  },
  {
    "objectID": "32-Ggplot2.html#x-quantitative-continue-et-y-discrète",
    "href": "32-Ggplot2.html#x-quantitative-continue-et-y-discrète",
    "title": "9  Graphiques avec ggplot2",
    "section": "9.7 X quantitative continue et Y discrète",
    "text": "9.7 X quantitative continue et Y discrète\n\n9.7.1 6.1 boxplot (R-base)\n\ndon2&lt;-don[(don$PCT &lt; 30),]\ndon2$SIZE&lt;-as.factor(don2$SIZE)\n#levels(don2$SIZE)&lt;-c(\"1 ou 2\", \"1 ou 2\", \"3 ou 4\", \"3 ou 4\", \"5 ou 6\", \"5 ou 6\")\nboxplot(don2$PCT~don2$SIZE, \n      col=rainbow(n=12, alpha=0.5),\n       xlab=\"Nombre de personnes\",\n       ylab=\"Pourboire (%)\",\n      main= \"Plus on est de fous, moins on est généreux !\",)\n\n\n\n\n\n\n9.7.2 geom_boxplot (ggplot2)\n\n# On filtre le tableau et on change SIZE en factor\ndon %&gt;%  filter(PCT &lt; 30) %&gt;% \n         mutate(SIZE = as.factor(SIZE)) %&gt;%\n  \n# On définit les paramètres principaux\nggplot(aes(x= SIZE,y = PCT)) +\n  \n# On ajoute la boxplot\ngeom_boxplot(aes(fill= SIZE)) +\n  \n  \n# On ajoute les titres\n  scale_x_discrete(name=\"Nombre de personnes\") +\n  scale_y_continuous(name=\"Pourboire en %\") +\n  ggtitle(\"Plus on est de fous, moins on est généreux !\")\n\n\n\n\n\n\n9.7.3 beanplot (R-base + package beanplot)\n\npar(bg=\"black\",fg=\"white\",col.lab =\"white\", col.axis =\"white\",col.main=\"white\" )\ndon2&lt;-don[(don$PCT &lt; 30),]\ndon2$SIZE&lt;-as.factor(don2$SIZE)\n#levels(don2$SIZE)&lt;-c(\"1 ou 2\", \"1 ou 2\", \"3 ou 4\", \"3 ou 4\", \"5 ou 6\", \"5 ou 6\")\nlibrary(beanplot)\nbeanplot(don2$PCT~don2$SIZE, \n         col=c(\"lightyellow\",\"red\"),\n       xlab=\"Nombre de personnes\",\n       ylab=\"Pourboire (%)\", \n      main= \"Plus on est de fous, moins on est généreux !\")\n\n\n\n\n\n\n9.7.4 geom_violin (ggplot2)\n\n# On filtre le tableau et on change SIZE en factor\ndon %&gt;%  filter(PCT &lt; 30) %&gt;% \n         mutate(SIZE = as.factor(SIZE)) %&gt;%\n  \n# On définit les paramètres principaux\nggplot(aes(x= SIZE,y = PCT)) +\n  \n# On ajoute la géométrie \ngeom_violin(aes(fill= SIZE)) +\n  \n  \n# On ajoute les titres\n  scale_x_discrete(name=\"Nombre de personnes\") +\n  scale_y_continuous(name=\"Pourboire en %\") +\n  ggtitle(\"Plus on est de fous, moins on est généreux !\")+\n\n# On passe en thème \"dark\"\n  theme_dark()"
  },
  {
    "objectID": "32-Ggplot2.html#deux-variables-x-et-y-discrètes",
    "href": "32-Ggplot2.html#deux-variables-x-et-y-discrètes",
    "title": "9  Graphiques avec ggplot2",
    "section": "9.8 Deux variables X et Y discrètes",
    "text": "9.8 Deux variables X et Y discrètes\n\n9.8.1 mosaicplot (R-base)\n\ndon$SIZE&lt;-as.factor(don$SIZE)\nmosaicplot(don$SEX~don$SIZE, \n      col=terrain.colors(n=7, alpha=0.5),\n       xlab=\"Genre de la personne qui a payé\",\n       ylab=\"Nombre de convives\",\n      main= \"Plus il y a de monde, plus ce sont les hommes qui payent\")\n\n\n\n\n\n\n9.8.2 geom_bar (ggplot2)\nSolution simple mais pas terrible !\n\n# On filtre le tableau et on change SIZE en factor\ndon %&gt;% mutate(SIZE = as.factor(SIZE)) %&gt;%\n  \n# On définit les paramètres principaux\nggplot(aes(x= SEX, fill = SIZE)) +\n  \n\n# On ajoute geom_bar\ngeom_bar() +\n\n  \n# On ajoute les titres\n  scale_x_discrete(name=\"Genre de la personne qui a payé\") +\n  ggtitle(\"Plus il y a de monde, plus ce sont les hommes qui payent\")\n\n\n\n\nsolution juste … mais très complexe\n\n# On crée un tableau de contingence \n# avec pourcentages en colonne avec\n# du code tidyverse\ndon %&gt;% mutate(SIZE = as.factor(SIZE)) %&gt;%\n        group_by(SEX, SIZE) %&gt;%\n          summarise(count = n()) %&gt;%\n          mutate(cut.count = sum(count),\n          prop = count/sum(count)) %&gt;%\n        ungroup() %&gt;%\n  \n# On définit les paramètres principaux\nggplot(aes(x = SEX, \n           y = prop,\n           width = cut.count,\n           fill = SIZE)) +\n  \n# On lance le geom_bar avec plein d'options\n  geom_bar(stat = \"identity\",\n           position = \"fill\", \n           colour = \"black\") +\n  facet_grid(~SEX, \n             scales = \"free_x\", \n             space = \"free_x\") +\n  scale_fill_brewer(palette = \"RdYlGn\",\n                    direction=-1) +\n  theme_void() +\n  \n# On ajoute les titres\n  scale_x_discrete(name=\"Genre de la personne qui a payé\") +\n  ggtitle(\"Plus il y a de monde, plus ce sont les hommes qui payent\")\n\n\n\n# OUF !!! (R-base est + simple !)"
  },
  {
    "objectID": "32-Ggplot2.html#conclusion",
    "href": "32-Ggplot2.html#conclusion",
    "title": "9  Graphiques avec ggplot2",
    "section": "9.9 Conclusion",
    "text": "9.9 Conclusion\n\n9.9.1 R-base\n\nsimple d’utilisation\npeut être amélioré par des packages spécialisés\npermet de créer ses propres fonctions\nn’impose pas d’apprendre tidyverse\n\n\n\n9.9.2 ggplot2\n\nstandard mondial du graphisme … actuellement\ncompatible avec la religion du tidyverse\nrédaction séquentielle très efficace\nmais apprentissage difficile (plusieurs semaines …)\n\n\n\n9.9.3 Le meilleur des deux mondes ?\n\nne pas hésiter à combiner les deux\nexportation facile des résultats dans les deux cas (pdf, jpeg, png, …)\n\n\n\n9.9.4 plotly, un challenger sérieux de ggplot pour le web\n\nplotly crée des graphiques interactifs au format .html\nplotly peut convertir des documents ggplot\nplotly a une syntaxe proche de ggplot mais avec des fonctionnalités en plus\nplotly est multilangage (R, Python, …)\n\n\n# création et sockage de la figure ggplot\n  toto &lt;- ggplot(don, aes(x = TOTBILL, y = TIP) )+\n          geom_point (aes(colour = SEX, shape = SMOKER)) +\n          scale_x_log10(name=\"Prix du repas en $\") +\n          scale_y_log10(name=\"Montant du pourboire en $\") +\n          geom_smooth(method=\"lm\") \n\n  # conversion en plotly\nlibrary(plotly)\n   titi &lt;-ggplotly(toto)\n\n   \n# affichage\n   titi"
  }
]